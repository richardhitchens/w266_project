{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More work evaluating quality of topics and identifying potential sources of errors and possible avenues for improvement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import zipfile\n",
    "import shutil\n",
    "import re\n",
    "import string\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import scipy.stats as stats\n",
    "import datetime\n",
    "import pylab as pl\n",
    "import math\n",
    "import codecs\n",
    "import nltk\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "import time\n",
    "import json\n",
    "import gensim\n",
    "from gensim import corpora, models\n",
    "from gensim.matutils import hellinger\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "import logging\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set all important file paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'/Users/seddont/Dropbox/Tom/MIDS/W266_work/w266_project'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Richard path specs\n",
    "\n",
    "# # At work:\n",
    "# TEXT_PATH = \"T:/Quant/TextAnalysis/Transcripts/SP100/Text/\"\n",
    "# PDF_PATH = \"T:/Quant/TextAnalysis/Transcripts/SP100/PDF/\"\n",
    "# LIBRARY_PATH = \"T:/Quant/TextAnalysis/Transcripts/SP100/Libraries/\"\n",
    "\n",
    "# # At home:\n",
    "# dict_path = '/Users/Richard/Desktop/Berkeley/w266/'\n",
    "# input_path = '/Users/Richard/Desktop/Berkeley/w266/repo/w266_project/'\n",
    "# output_path = '/Users/Richard/Desktop/Berkeley/w266/'\n",
    "\n",
    "# LIBRARY_PATH = '/Users/Richard/Desktop/Berkeley/w266/repo/w266_project/'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Tom path specs\n",
    "\n",
    "# Tom machine:\n",
    "TEXT_DIR_LIST = [\"T1\", \"T2\", \"T3\", \"T4\"]\n",
    "# PDF_PATH = \"T:/Quant/TextAnalysis/Transcripts/SP100/PDF/\"\n",
    "LIBRARY_PATH = \"/Users/seddont/Dropbox/Tom/MIDS/W266_work/w266_project/\"\n",
    "\n",
    "# On Tom's google cloud instance\n",
    "# LIBRARY_PATH = \"/home/seddon/w266_project/\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_spec = {\"model_directory\": \"saved_models/topic20_minlength20_base\",\n",
    "              \"qa_pair_directory\": \"saved_models/standard_preproc\",\n",
    "              \"preprocessing_function\": \"testLDA_pre_process_document\",\n",
    "              \"min_sequence_length\": 20,\n",
    "              \"num_topics\": 20,\n",
    "              \"description\": \"test model\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Saved_state():\n",
    "    '''Represents a saved state that includes an LDA model and the data used to create it.\n",
    "    \n",
    "       Instantiated with a model_spec dictionary that locates the files to \n",
    "       recreate the saved state and includes a description.\n",
    "       \n",
    "       Dictionary needs to contain:\n",
    "       \n",
    "       model_files\n",
    "       qa_pairs_file\n",
    "       raw_qa_text_file\n",
    "       corpus_file\n",
    "       hellinger_file\n",
    "       '''\n",
    "    def __init__(self, model_spec):\n",
    "        \n",
    "        model_dir = LIBRARY_PATH+model_spec[\"model_directory\"]\n",
    "        qa_dir = LIBRARY_PATH+model_spec[\"qa_pair_directory\"]\n",
    "        \n",
    "        self.ldamodel = gensim.models.ldamodel.LdaModel.load(model_dir+\"/full_model\")\n",
    "        \n",
    "        self.dictionary = gensim.corpora.dictionary.Dictionary.load(model_dir+\"/dictionary.txt\")\n",
    "        \n",
    "        with open(qa_dir+\"/qa_pairs.txt\", \"r\") as f:\n",
    "            self.qa_pairs = json.loads(f.read())\n",
    "            \n",
    "        with open(LIBRARY_PATH + \"/raw_qa_data.txt\", \"r\") as f:\n",
    "            self.raw_qa_text = json.loads(f.read())\n",
    "            \n",
    "        with open(model_dir+\"/corpus.txt\", \"r\") as f:\n",
    "            self.corpus = json.loads(f.read())\n",
    "            \n",
    "        with open(model_dir+\"/hell_sims.txt\", \"r\") as f:\n",
    "            self.hellinger_sims = json.loads(f.read())\n",
    "            \n",
    "        with open(model_dir+\"/model_runtime.txt\", \"r\") as f:\n",
    "            self.model_runtime = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "saved = Saved_state(model_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restored test model originally run at 2017-12-09 22:12:32.176898\n"
     ]
    }
   ],
   "source": [
    "# Restoring saved state\n",
    "\n",
    "ldamodel = saved.ldamodel\n",
    "qa_pairs= saved.qa_pairs\n",
    "raw_qa_text = saved.raw_qa_text\n",
    "corpus = saved.corpus\n",
    "hellinger_sims = saved.hellinger_sims\n",
    "dictionary = saved.dictionary\n",
    "model_runtime = saved.model_runtime\n",
    "\n",
    "print \"Restored\", model_spec[\"description\"], \"originally run at\", model_runtime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looking at words that appear in multiple topics\n",
    "\n",
    "Inspecting our topics, we have a number of words that appear in multiple topics, like 'think'.  These may not be helping with the distinctiveness of each topic, and may be getting learned because of our short document lengths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_topic_counts(model_spec, topn):\n",
    "    '''Retrieves saved model from a model spec.  Returns a dict containing\n",
    "       how many of the topics each word that is in the top n of at least one topic\n",
    "       shows up in the top n for a topic.\n",
    "       \n",
    "       Helps identify words that may be uninformative for topic modelling.'''\n",
    "    \n",
    "    topic_words = dict()\n",
    "    topic_count = defaultdict(int)\n",
    "    \n",
    "    saved = Saved_state(model_spec)\n",
    "\n",
    "    ldamodel = saved.ldamodel\n",
    "\n",
    "    for n in range(model_spec[\"num_topics\"]):\n",
    "        \n",
    "        topic_words[n] = ldamodel.show_topic(n, topn = topn)\n",
    "\n",
    "    for topic in topic_words:\n",
    "        for w in topic_words[topic]:\n",
    "            topic_count[w[0]] += 1\n",
    "            \n",
    "    return topic_count\n",
    "#     return topic_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "word_counts = get_topic_counts(model_spec, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'see', 12),\n",
       " (u'look', 11),\n",
       " (u'go', 10),\n",
       " (u'new', 10),\n",
       " (u'think', 10),\n",
       " (u'come', 10),\n",
       " (u'one', 9),\n",
       " (u'us', 9),\n",
       " (u'well', 8),\n",
       " (u'want', 7),\n",
       " (u'realli', 7),\n",
       " (u'year', 7),\n",
       " (u'take', 7),\n",
       " (u'busi', 7),\n",
       " (u'get', 7),\n",
       " (u'product', 7),\n",
       " (u'actual', 7),\n",
       " (u'good', 6),\n",
       " (u'term', 6),\n",
       " (u'continu', 6),\n",
       " (u'expect', 6),\n",
       " (u'first', 6),\n",
       " (u'point', 6),\n",
       " (u'like', 6),\n",
       " (u'rate', 5),\n",
       " (u'two', 5),\n",
       " (u'move', 5),\n",
       " (u'side', 5),\n",
       " (u'NUM', 5),\n",
       " (u'lot', 5),\n",
       " (u'plan', 5),\n",
       " (u'impact', 5),\n",
       " (u'make', 5),\n",
       " (u'also', 5),\n",
       " (u'know', 5),\n",
       " (u'back', 5),\n",
       " (u'growth', 5),\n",
       " (u'question', 5),\n",
       " (u'way', 5),\n",
       " (u'time', 5),\n",
       " (u'consum', 4),\n",
       " (u'higher', 4),\n",
       " (u'work', 4),\n",
       " (u'basi', 4),\n",
       " (u'talk', 4),\n",
       " (u'increas', 4),\n",
       " (u'said', 4),\n",
       " (u'last', 4),\n",
       " (u'improv', 4),\n",
       " (u'much', 4),\n",
       " (u'right', 4),\n",
       " (u'market', 4),\n",
       " (u'opportun', 4),\n",
       " (u'start', 4),\n",
       " (u'level', 3),\n",
       " (u'cost', 3),\n",
       " (u'gener', 3),\n",
       " (u'great', 3),\n",
       " (u'chang', 3),\n",
       " (u'use', 3),\n",
       " (u'obvious', 3),\n",
       " (u'give', 3),\n",
       " (u'end', 3),\n",
       " (u'grow', 3),\n",
       " (u'order', 3),\n",
       " (u'still', 3),\n",
       " (u'day', 3),\n",
       " (u'quarter', 3),\n",
       " (u'got', 3),\n",
       " (u'base', 3),\n",
       " (u'thing', 3),\n",
       " (u'oper', 3),\n",
       " (u'number', 3),\n",
       " (u'differ', 3),\n",
       " (u'kind', 3),\n",
       " (u'say', 3),\n",
       " (u'mix', 3),\n",
       " (u'revenu', 3),\n",
       " (u'interest', 3),\n",
       " (u'commerci', 3),\n",
       " (u'perform', 3),\n",
       " (u'lower', 3),\n",
       " (u'expens', 3),\n",
       " (u'less', 3),\n",
       " (u'custom', 3),\n",
       " (u'sale', 3),\n",
       " (u'invest', 3),\n",
       " (u'u', 3),\n",
       " (u'ga', 2),\n",
       " (u'categori', 2),\n",
       " (u'digit', 2),\n",
       " (u'trend', 2),\n",
       " (u'valu', 2),\n",
       " (u'next', 2),\n",
       " (u'asset', 2),\n",
       " (u'sort', 2),\n",
       " (u'capit', 2),\n",
       " (u'peopl', 2),\n",
       " (u'compani', 2),\n",
       " (u'account', 2),\n",
       " (u'hous', 2),\n",
       " (u'share', 2),\n",
       " (u'incom', 2),\n",
       " (u'environ', 2),\n",
       " (u'okay', 2),\n",
       " (u'data', 2),\n",
       " (u'help', 2),\n",
       " (u'trade', 2),\n",
       " (u'thank', 2),\n",
       " (u'better', 2),\n",
       " (u'platform', 2),\n",
       " (u'might', 2),\n",
       " (u'mention', 2),\n",
       " (u'half', 2),\n",
       " (u'bank', 2),\n",
       " (u'mean', 2),\n",
       " (u'network', 2),\n",
       " (u'guess', 2),\n",
       " (u'capac', 2),\n",
       " (u'part', 2),\n",
       " (u'balanc', 2),\n",
       " (u'posit', 2),\n",
       " (u'seen', 2),\n",
       " (u'seem', 2),\n",
       " (u'america', 2),\n",
       " (u'portfolio', 2),\n",
       " (u'ratio', 2),\n",
       " (u'pretti', 2),\n",
       " (u'activ', 2),\n",
       " (u'earn', 2),\n",
       " (u'yield', 2),\n",
       " (u'volatil', 2),\n",
       " (u'across', 2),\n",
       " (u'debt', 2),\n",
       " (u'ramp', 2),\n",
       " (u'comment', 2),\n",
       " (u'color', 2),\n",
       " (u'demand', 2),\n",
       " (u'servic', 2),\n",
       " (u'earli', 2),\n",
       " (u'thought', 2),\n",
       " (u'tax', 2),\n",
       " (u'around', 2),\n",
       " (u'mayb', 2),\n",
       " (u'big', 2),\n",
       " (u'world', 2),\n",
       " (u'channel', 2),\n",
       " (u'manag', 2),\n",
       " (u'deal', 2),\n",
       " (u'intern', 2),\n",
       " (u'larg', 2),\n",
       " (u'offset', 2),\n",
       " (u'area', 2),\n",
       " (u'long', 2),\n",
       " (u'low', 2),\n",
       " (u'buy', 2),\n",
       " (u'north', 2),\n",
       " (u'yeah', 2),\n",
       " (u'probabl', 2),\n",
       " (u'guidanc', 2),\n",
       " (u'potenti', 2)]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_counts = [(w, word_counts[w]) for w in word_counts if word_counts[w] > 1]\n",
    "sorted_multi_counts = sorted(multi_counts, key = lambda w: w[1], reverse = True)\n",
    "sorted_multi_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating topic distributions\n",
    "\n",
    "LDA should be concentrating topic probabilities for each document into a relatively small number of topics.  Want to inspect to see how true that is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_topic_dists(model_spec):\n",
    "    '''Perform inference to calc topic distibutions for a model\n",
    "       on our dataset.\n",
    "       \n",
    "       Return a dictionary of topic distributions, keyed by (file_id, qnum, q/a)\n",
    "       tuples.'''\n",
    "\n",
    "    topic_dists = defaultdict(dict)\n",
    "    \n",
    "    model_dir = LIBRARY_PATH+model_spec[\"model_directory\"]\n",
    "    qa_dir = LIBRARY_PATH+model_spec[\"qa_pair_directory\"]\n",
    "    \n",
    "    with open(qa_dir+\"/qa_pairs.txt\", \"r\") as f:\n",
    "        qa_pairs = json.loads(f.read())\n",
    "        \n",
    "    ldamodel = gensim.models.ldamodel.LdaModel.load(model_dir+\"/full_model\")\n",
    "    dictionary = gensim.corpora.dictionary.Dictionary.load(model_dir+\"/dictionary.txt\")\n",
    "    \n",
    "    \n",
    "    print \"starting\"\n",
    "    start_time = time.time()\n",
    "    i = 0\n",
    "    report_every = 10000\n",
    "    \n",
    "    min_sequence_length = model_spec[\"min_sequence_length\"]\n",
    "\n",
    "    for file_id in qa_pairs:\n",
    "        for q_number in qa_pairs[file_id]:\n",
    "            question, answer = qa_pairs[file_id][q_number]\n",
    "            if (len(question) > min_sequence_length and\n",
    "                len(answer) > min_sequence_length):\n",
    "                q_bow = dictionary.doc2bow(question)\n",
    "                a_bow = dictionary.doc2bow(answer)\n",
    "                topic_dists[(file_id,q_number,\"q\")] = ldamodel[q_bow]\n",
    "                topic_dists[(file_id,q_number,\"a\")] = ldamodel[a_bow]             \n",
    "            i += 1\n",
    "            if i % report_every == 0:\n",
    "                print \"Processed \", i, \"pairs in\", time.time() - start_time\n",
    "    print \"Finished in\", time.time() - start_time\n",
    "    \n",
    "#     # Store the results to file for recreating later if wanted\n",
    "#     with open(model_dir+\"/topic_dists.txt\", \"w\") as f:\n",
    "#         f.write(json.dumps(topic_dists))\n",
    "        \n",
    "    return topic_dists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting\n",
      "Processed  10000 pairs in 11.6608200073\n",
      "Processed  20000 pairs in 23.8628001213\n",
      "Processed  30000 pairs in 36.1894099712\n",
      "Processed  40000 pairs in 49.9212801456\n",
      "Processed  50000 pairs in 63.1103920937\n",
      "Processed  60000 pairs in 75.1242649555\n",
      "Processed  70000 pairs in 87.2788529396\n",
      "Processed  80000 pairs in 99.4468200207\n",
      "Finished in 104.995733976\n"
     ]
    }
   ],
   "source": [
    "topic_dists = get_topic_dists(model_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(2, 0.096762045012519809), (3, 0.15208877193526946), (6, 0.21923988730145816), (12, 0.20457402816166612), (14, 0.079455212086838437), (17, 0.20639154992819525), (19, 0.030655172097030881)]\n",
      "0.989166666523\n",
      "[(1, 0.24508400269286673), (3, 0.31195125850352845), (9, 0.29759346645410323), (11, 0.026068670528806487), (12, 0.067185914280934442), (19, 0.040641277533406898)]\n",
      "0.988524589994\n",
      "[(4, 0.093323795281222185), (6, 0.4683069243408749), (7, 0.087304707104613244), (10, 0.026278074243636432), (13, 0.20441949528508718), (19, 0.10194595088786072)]\n",
      "0.981578947143\n",
      "[(1, 0.026150436063369635), (5, 0.039286616484566807), (6, 0.62770808909889153), (7, 0.02362858017966598), (12, 0.038148621440563316), (14, 0.063139062244211425), (16, 0.089040698378027833), (17, 0.083220476599624379)]\n",
      "0.990322580489\n",
      "[(2, 0.20270759961612131), (5, 0.056978566810328417), (6, 0.11799794448351997), (9, 0.13845986831232374), (18, 0.050412865445777548), (19, 0.41971766497326557)]\n",
      "0.986274509641\n"
     ]
    }
   ],
   "source": [
    "topic_dists.keys()[:5]\n",
    "for t in topic_dists.keys()[:5]:\n",
    "    print topic_dists[t]\n",
    "    total_score = 0\n",
    "    for topic_score in topic_dists[t]:\n",
    "        total_score += topic_score[1]\n",
    "    print total_score"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [py27]",
   "language": "python",
   "name": "Python [py27]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
