{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import zipfile\n",
    "import shutil\n",
    "import re\n",
    "import string\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import scipy.stats as stats\n",
    "import datetime\n",
    "import pylab as pl\n",
    "import math\n",
    "import codecs\n",
    "import nltk\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "import time\n",
    "import json\n",
    "import gensim\n",
    "from gensim import corpora, models\n",
    "from gensim.matutils import hellinger\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "import logging\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set all important file paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'/Users/seddont/Dropbox/Tom/MIDS/W266_work/w266_project'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Richard path specs\n",
    "\n",
    "# # At work:\n",
    "# TEXT_PATH = \"T:/Quant/TextAnalysis/Transcripts/SP100/Text/\"\n",
    "# PDF_PATH = \"T:/Quant/TextAnalysis/Transcripts/SP100/PDF/\"\n",
    "# LIBRARY_PATH = \"T:/Quant/TextAnalysis/Transcripts/SP100/Libraries/\"\n",
    "\n",
    "# # At home:\n",
    "# dict_path = '/Users/Richard/Desktop/Berkeley/w266/'\n",
    "# input_path = '/Users/Richard/Desktop/Berkeley/w266/repo/w266_project/'\n",
    "# output_path = '/Users/Richard/Desktop/Berkeley/w266/'\n",
    "\n",
    "# LIBRARY_PATH = '/Users/Richard/Desktop/Berkeley/w266/repo/w266_project/'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Tom path specs\n",
    "\n",
    "# Tom machine:\n",
    "TEXT_DIR_LIST = [\"T1\", \"T2\", \"T3\", \"T4\"]\n",
    "# PDF_PATH = \"T:/Quant/TextAnalysis/Transcripts/SP100/PDF/\"\n",
    "LIBRARY_PATH = \"/Users/seddont/Dropbox/Tom/MIDS/W266_work/w266_project/\"\n",
    "\n",
    "# On Tom's google cloud instance\n",
    "# LIBRARY_PATH = \"/home/seddon/w266_project/\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import a dictionary\n",
    "\n",
    "Import a bag of words style dictionary for word counting analyses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_dictionary(file_path, file_name):\n",
    "    \"\"\"Read a standard word list dictionary text file into a list\"\"\"\n",
    "    with open(file_path + file_name, \"r\") as file:\n",
    "#         words = [word.lower().rstrip('\\n') for word in file]\n",
    "        words = [word.lower().rstrip() for word in file] # had to strip \\r as well on my machine\n",
    "    return words\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a list of files that have valid Q&A sections we want to use\n",
    "\n",
    "This section reviews all the files and rejects any that do not meet our criteria for use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Different possible section headers\n",
    "CO_PART_HEADERS = ['Company Participants']\n",
    "OTH_PART_HEADERS = ['Other Participants']\n",
    "MD_SECTION_HEADERS = ['MANAGEMENT DISCUSSION SECTION', 'Presentation']\n",
    "QA_SECTION_HEADERS = ['Q&A', 'Questions And Answers', 'QUESTION AND ANSWER SECTION',\n",
    "                      'QUESTION AND ANSWER SESSION', 'QUESTION-AND-ANSWER SECTION']\n",
    "DISCLAIMER = ['This transcript may not be 100 percent accurate ']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# New text file format has headers\n",
    "def remove_header_footers(ts):\n",
    "    i = 0\n",
    "    header_footer = []\n",
    "    # Add all the lines before the first 'Page 1 of n' line\n",
    "    while ts[i].find('Page') == -1:\n",
    "#         if ts[i].find('Fixed') != -1:\n",
    "#             print (ts[1], ts[2])\n",
    "        header_footer.append(ts[i])\n",
    "        i += 1\n",
    "    # Extract the total page number and add lines to strip for all the \n",
    "    # 'Page x of n' line\n",
    "    pages = ts[i]\n",
    "    pages = pages.split(' ')\n",
    "    page_num = int(pages[-1])\n",
    "    for i in range(1, page_num + 1):\n",
    "        header_footer.append('Page ' + str(i) + ' of ' + str(page_num))\n",
    "    ts = [line for line in ts if line not in header_footer]\n",
    "    return ts\n",
    "\n",
    "\n",
    "def read_transcript(file_path):\n",
    "    # read in all lines of the transcript\n",
    "    with open(file_path, \"r\") as file:\n",
    "        ts = file.readlines()\n",
    "        ts = [str(unicode(line, errors = 'ignore')) for line in ts]\n",
    "        ts = [line.rstrip() for line in ts]\n",
    "        ts = remove_header_footers(ts)\n",
    "    return ts\n",
    "\n",
    "\n",
    "# Find the index value of a full string from a list of possible strings\n",
    "def find_full_string_index(ts, string_list):\n",
    "    result = -1\n",
    "    for i in range(len(string_list)):\n",
    "        if string_list[i] in ts:\n",
    "            result = ts.index(string_list[i])\n",
    "    return result\n",
    "\n",
    "# Find the index of the disclaimer\n",
    "def find_disclaimer_index(ts, string_list):\n",
    "    result = -1\n",
    "    k = len(ts) - 1\n",
    "    while True:\n",
    "        for my_str in string_list:\n",
    "            if ts[k].find(my_str) != -1:\n",
    "                result = k\n",
    "                break\n",
    "        k -= 1\n",
    "        if k < 0:\n",
    "            break\n",
    "    return result\n",
    "\n",
    "# Get transcript list indices from a single transcript\n",
    "def get_basic_parameters(ts):\n",
    "    call_type = ts[0]\n",
    "    # check call type\n",
    "    if call_type.find(\"Earnings Call\") == -1:\n",
    "        call_type = -1\n",
    "    else:\n",
    "        if call_type.find(\"Fixed\") != -1:  # don't want Fixed Income calls\n",
    "            call_type = -1\n",
    "            \n",
    "    co_parts = find_full_string_index(ts,CO_PART_HEADERS)\n",
    "    oth_parts = find_full_string_index(ts,OTH_PART_HEADERS)\n",
    "    md = find_full_string_index(ts,MD_SECTION_HEADERS)\n",
    "    qa = find_full_string_index(ts,QA_SECTION_HEADERS)\n",
    "    disc = find_disclaimer_index(ts,DISCLAIMER)\n",
    "    return [call_type, co_parts, oth_parts, md, qa, disc]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid Files found:  3245\n",
      "\n",
      "Files rejected: 103\n",
      "\n",
      "Number of files with each type of error (file can have >1 error):\n",
      "no Q&A section 42\n",
      "Files are:\n",
      "/Users/seddont/Dropbox/Tom/MIDS/W266_work/w266_project/T1/20100806_1_AIG.txt\n",
      "/Users/seddont/Dropbox/Tom/MIDS/W266_work/w266_project/T1/20100817_1_WMT.txt\n",
      "/Users/seddont/Dropbox/Tom/MIDS/W266_work/w266_project/T1/20101105_1_AIG.txt\n",
      "/Users/seddont/Dropbox/Tom/MIDS/W266_work/w266_project/T1/20101110_1_GM.txt\n",
      "/Users/seddont/Dropbox/Tom/MIDS/W266_work/w266_project/T1/20101116_1_WMT.txt\n",
      "/Users/seddont/Dropbox/Tom/MIDS/W266_work/w266_project/T1/20110517_1_WMT.txt\n",
      "/Users/seddont/Dropbox/Tom/MIDS/W266_work/w266_project/T1/20110816_1_WMT.txt\n",
      "/Users/seddont/Dropbox/Tom/MIDS/W266_work/w266_project/T1/20111115_1_WMT.txt\n",
      "/Users/seddont/Dropbox/Tom/MIDS/W266_work/w266_project/T1/20120221_1_WMT.txt\n",
      "/Users/seddont/Dropbox/Tom/MIDS/W266_work/w266_project/T1/20120517_1_WMT.txt\n",
      "/Users/seddont/Dropbox/Tom/MIDS/W266_work/w266_project/T1/20120816_1_WMT.txt\n",
      "/Users/seddont/Dropbox/Tom/MIDS/W266_work/w266_project/T1/20121115_1_WMT.txt\n",
      "/Users/seddont/Dropbox/Tom/MIDS/W266_work/w266_project/T2/20130221_1_WMT.txt\n",
      "/Users/seddont/Dropbox/Tom/MIDS/W266_work/w266_project/T2/20130730_1_NYX.txt\n",
      "/Users/seddont/Dropbox/Tom/MIDS/W266_work/w266_project/T2/20130815_1_WMT.txt\n",
      "/Users/seddont/Dropbox/Tom/MIDS/W266_work/w266_project/T2/20130911_1_WMT.txt\n",
      "/Users/seddont/Dropbox/Tom/MIDS/W266_work/w266_project/T2/20130923_1_HNZ.txt\n",
      "/Users/seddont/Dropbox/Tom/MIDS/W266_work/w266_project/T2/20131114_1_WMT.txt\n",
      "/Users/seddont/Dropbox/Tom/MIDS/W266_work/w266_project/T2/20131220_1_HNZ.txt\n",
      "/Users/seddont/Dropbox/Tom/MIDS/W266_work/w266_project/T2/20140220_1_WMT.txt\n",
      "/Users/seddont/Dropbox/Tom/MIDS/W266_work/w266_project/T2/20140320_1_HNZ.txt\n",
      "/Users/seddont/Dropbox/Tom/MIDS/W266_work/w266_project/T2/20140515_1_WMT.txt\n",
      "/Users/seddont/Dropbox/Tom/MIDS/W266_work/w266_project/T2/20140522_1_HNZ.txt\n",
      "/Users/seddont/Dropbox/Tom/MIDS/W266_work/w266_project/T2/20140725_1_ABBV.txt\n",
      "/Users/seddont/Dropbox/Tom/MIDS/W266_work/w266_project/T2/20140814_1_WMT.txt\n",
      "/Users/seddont/Dropbox/Tom/MIDS/W266_work/w266_project/T2/20140820_1_HNZ.txt\n",
      "/Users/seddont/Dropbox/Tom/MIDS/W266_work/w266_project/T2/20141113_1_WMT.txt\n",
      "/Users/seddont/Dropbox/Tom/MIDS/W266_work/w266_project/T2/20141119_1_HNZ.txt\n",
      "/Users/seddont/Dropbox/Tom/MIDS/W266_work/w266_project/T3/20150219_1_WMT.txt\n",
      "/Users/seddont/Dropbox/Tom/MIDS/W266_work/w266_project/T3/20150313_1_HNZ.txt\n",
      "/Users/seddont/Dropbox/Tom/MIDS/W266_work/w266_project/T3/20150515_1_HNZ.txt\n",
      "/Users/seddont/Dropbox/Tom/MIDS/W266_work/w266_project/T3/20150519_1_WMT.txt\n",
      "/Users/seddont/Dropbox/Tom/MIDS/W266_work/w266_project/T3/20150814_1_HNZ.txt\n",
      "/Users/seddont/Dropbox/Tom/MIDS/W266_work/w266_project/T3/20150814_1_KHC.txt\n",
      "/Users/seddont/Dropbox/Tom/MIDS/W266_work/w266_project/T3/20150818_1_WMT.txt\n",
      "/Users/seddont/Dropbox/Tom/MIDS/W266_work/w266_project/T3/20151117_1_WMT.txt\n",
      "/Users/seddont/Dropbox/Tom/MIDS/W266_work/w266_project/T3/20160218_1_WMT.txt\n",
      "/Users/seddont/Dropbox/Tom/MIDS/W266_work/w266_project/T3/20160519_1_WMT.txt\n",
      "/Users/seddont/Dropbox/Tom/MIDS/W266_work/w266_project/T3/20160818_1_WMT.txt\n",
      "/Users/seddont/Dropbox/Tom/MIDS/W266_work/w266_project/T3/20161117_1_WMT.txt\n",
      "/Users/seddont/Dropbox/Tom/MIDS/W266_work/w266_project/T4/20110222_1_WMT.txt\n",
      "/Users/seddont/Dropbox/Tom/MIDS/W266_work/w266_project/T4/20170221_1_WMT.txt\n",
      "not equity earnings call 59\n",
      "Files are:\n",
      "/Users/seddont/Dropbox/Tom/MIDS/W266_work/w266_project/T1/20101019_1_AEP.txt\n",
      "/Users/seddont/Dropbox/Tom/MIDS/W266_work/w266_project/T1/20101022_1_C.txt\n",
      "/Users/seddont/Dropbox/Tom/MIDS/W266_work/w266_project/T1/20101026_1_F.txt\n",
      "/Users/seddont/Dropbox/Tom/MIDS/W266_work/w266_project/T1/20110121_1_C.txt\n",
      "/Users/seddont/Dropbox/Tom/MIDS/W266_work/w266_project/T1/20110426_1_F.txt\n",
      "/Users/seddont/Dropbox/Tom/MIDS/W266_work/w266_project/T1/20110427_1_C.txt\n",
      "/Users/seddont/Dropbox/Tom/MIDS/W266_work/w266_project/T1/20110721_1_C.txt\n",
      "/Users/seddont/Dropbox/Tom/MIDS/W266_work/w266_project/T1/20110728_1_AXP.txt\n",
      "/Users/seddont/Dropbox/Tom/MIDS/W266_work/w266_project/T1/20111020_1_C.txt\n",
      "/Users/seddont/Dropbox/Tom/MIDS/W266_work/w266_project/T1/20120124_1_C.txt\n",
      "/Users/seddont/Dropbox/Tom/MIDS/W266_work/w266_project/T1/20120425_1_C.txt\n",
      "/Users/seddont/Dropbox/Tom/MIDS/W266_work/w266_project/T1/20120427_1_F.txt\n",
      "/Users/seddont/Dropbox/Tom/MIDS/W266_work/w266_project/T1/20120719_1_AXP.txt\n",
      "/Users/seddont/Dropbox/Tom/MIDS/W266_work/w266_project/T1/20120720_1_C.txt\n",
      "/Users/seddont/Dropbox/Tom/MIDS/W266_work/w266_project/T1/20120724_1_GS.txt\n",
      "/Users/seddont/Dropbox/Tom/MIDS/W266_work/w266_project/T1/20120725_1_F.txt\n",
      "/Users/seddont/Dropbox/Tom/MIDS/W266_work/w266_project/T1/20121024_1_C.txt\n",
      "/Users/seddont/Dropbox/Tom/MIDS/W266_work/w266_project/T1/20121030_1_F.txt\n",
      "/Users/seddont/Dropbox/Tom/MIDS/W266_work/w266_project/T2/20130123_1_GS.txt\n",
      "/Users/seddont/Dropbox/Tom/MIDS/W266_work/w266_project/T2/20130125_1_C.txt\n",
      "/Users/seddont/Dropbox/Tom/MIDS/W266_work/w266_project/T2/20130129_1_F.txt\n",
      "/Users/seddont/Dropbox/Tom/MIDS/W266_work/w266_project/T2/20130422_1_C.txt\n",
      "/Users/seddont/Dropbox/Tom/MIDS/W266_work/w266_project/T2/20130424_1_F.txt\n",
      "/Users/seddont/Dropbox/Tom/MIDS/W266_work/w266_project/T2/20130718_1_AXP.txt\n",
      "/Users/seddont/Dropbox/Tom/MIDS/W266_work/w266_project/T2/20130719_1_C.txt\n",
      "/Users/seddont/Dropbox/Tom/MIDS/W266_work/w266_project/T2/20130724_1_F.txt\n",
      "/Users/seddont/Dropbox/Tom/MIDS/W266_work/w266_project/T2/20130909_1_F.txt\n",
      "/Users/seddont/Dropbox/Tom/MIDS/W266_work/w266_project/T2/20131023_1_C.txt\n",
      "/Users/seddont/Dropbox/Tom/MIDS/W266_work/w266_project/T2/20131024_1_F.txt\n",
      "/Users/seddont/Dropbox/Tom/MIDS/W266_work/w266_project/T2/20131106_1_GS.txt\n",
      "/Users/seddont/Dropbox/Tom/MIDS/W266_work/w266_project/T2/20140123_1_C.txt\n",
      "/Users/seddont/Dropbox/Tom/MIDS/W266_work/w266_project/T2/20140128_1_F.txt\n",
      "/Users/seddont/Dropbox/Tom/MIDS/W266_work/w266_project/T2/20140417_1_C.txt\n",
      "/Users/seddont/Dropbox/Tom/MIDS/W266_work/w266_project/T2/20140501_1_GS.txt\n",
      "/Users/seddont/Dropbox/Tom/MIDS/W266_work/w266_project/T2/20140718_1_C.txt\n",
      "/Users/seddont/Dropbox/Tom/MIDS/W266_work/w266_project/T2/20140724_1_F.txt\n",
      "/Users/seddont/Dropbox/Tom/MIDS/W266_work/w266_project/T2/20141017_1_C.txt\n",
      "/Users/seddont/Dropbox/Tom/MIDS/W266_work/w266_project/T2/20141024_1_F.txt\n",
      "/Users/seddont/Dropbox/Tom/MIDS/W266_work/w266_project/T2/20150123_1_C.txt\n",
      "/Users/seddont/Dropbox/Tom/MIDS/W266_work/w266_project/T3/20150129_1_GS.txt\n",
      "/Users/seddont/Dropbox/Tom/MIDS/W266_work/w266_project/T3/20150423_1_C.txt\n",
      "/Users/seddont/Dropbox/Tom/MIDS/W266_work/w266_project/T3/20150428_1_F.txt\n",
      "/Users/seddont/Dropbox/Tom/MIDS/W266_work/w266_project/T3/20150721_1_C.txt\n",
      "/Users/seddont/Dropbox/Tom/MIDS/W266_work/w266_project/T3/20150728_1_AXP.txt\n",
      "/Users/seddont/Dropbox/Tom/MIDS/W266_work/w266_project/T3/20150728_1_F.txt\n",
      "/Users/seddont/Dropbox/Tom/MIDS/W266_work/w266_project/T3/20150804_1_GS.txt\n",
      "/Users/seddont/Dropbox/Tom/MIDS/W266_work/w266_project/T3/20151027_1_F.txt\n",
      "/Users/seddont/Dropbox/Tom/MIDS/W266_work/w266_project/T3/20151029_1_C.txt\n",
      "/Users/seddont/Dropbox/Tom/MIDS/W266_work/w266_project/T3/20160121_1_C.txt\n",
      "/Users/seddont/Dropbox/Tom/MIDS/W266_work/w266_project/T3/20160128_1_F.txt\n",
      "/Users/seddont/Dropbox/Tom/MIDS/W266_work/w266_project/T3/20160421_1_C.txt\n",
      "/Users/seddont/Dropbox/Tom/MIDS/W266_work/w266_project/T3/20160721_1_AXP.txt\n",
      "/Users/seddont/Dropbox/Tom/MIDS/W266_work/w266_project/T3/20160721_1_C.txt\n",
      "/Users/seddont/Dropbox/Tom/MIDS/W266_work/w266_project/T3/20160802_1_GS.txt\n",
      "/Users/seddont/Dropbox/Tom/MIDS/W266_work/w266_project/T3/20161026_1_C.txt\n",
      "/Users/seddont/Dropbox/Tom/MIDS/W266_work/w266_project/T3/20170126_1_C.txt\n",
      "/Users/seddont/Dropbox/Tom/MIDS/W266_work/w266_project/T4/20110128_1_F.txt\n",
      "/Users/seddont/Dropbox/Tom/MIDS/W266_work/w266_project/T4/20170420_1_C.txt\n",
      "/Users/seddont/Dropbox/Tom/MIDS/W266_work/w266_project/T4/20170720_1_C.txt\n",
      "no other participants 48\n",
      "Files are:\n",
      "/Users/seddont/Dropbox/Tom/MIDS/W266_work/w266_project/T1/20100806_1_AIG.txt\n",
      "/Users/seddont/Dropbox/Tom/MIDS/W266_work/w266_project/T1/20100817_1_WMT.txt\n",
      "/Users/seddont/Dropbox/Tom/MIDS/W266_work/w266_project/T1/20101019_1_AEP.txt\n",
      "/Users/seddont/Dropbox/Tom/MIDS/W266_work/w266_project/T1/20101105_1_AIG.txt\n",
      "/Users/seddont/Dropbox/Tom/MIDS/W266_work/w266_project/T1/20101110_1_GM.txt\n",
      "/Users/seddont/Dropbox/Tom/MIDS/W266_work/w266_project/T1/20101116_1_WMT.txt\n",
      "/Users/seddont/Dropbox/Tom/MIDS/W266_work/w266_project/T1/20110517_1_WMT.txt\n",
      "/Users/seddont/Dropbox/Tom/MIDS/W266_work/w266_project/T1/20110728_1_AXP.txt\n",
      "/Users/seddont/Dropbox/Tom/MIDS/W266_work/w266_project/T1/20110816_1_WMT.txt\n",
      "/Users/seddont/Dropbox/Tom/MIDS/W266_work/w266_project/T1/20111115_1_WMT.txt\n",
      "/Users/seddont/Dropbox/Tom/MIDS/W266_work/w266_project/T1/20120221_1_WMT.txt\n",
      "/Users/seddont/Dropbox/Tom/MIDS/W266_work/w266_project/T1/20120517_1_WMT.txt\n",
      "/Users/seddont/Dropbox/Tom/MIDS/W266_work/w266_project/T1/20120816_1_WMT.txt\n",
      "/Users/seddont/Dropbox/Tom/MIDS/W266_work/w266_project/T1/20121115_1_WMT.txt\n",
      "/Users/seddont/Dropbox/Tom/MIDS/W266_work/w266_project/T2/20130221_1_WMT.txt\n",
      "/Users/seddont/Dropbox/Tom/MIDS/W266_work/w266_project/T2/20130718_1_AXP.txt\n",
      "/Users/seddont/Dropbox/Tom/MIDS/W266_work/w266_project/T2/20130730_1_NYX.txt\n",
      "/Users/seddont/Dropbox/Tom/MIDS/W266_work/w266_project/T2/20130815_1_WMT.txt\n",
      "/Users/seddont/Dropbox/Tom/MIDS/W266_work/w266_project/T2/20130911_1_WMT.txt\n",
      "/Users/seddont/Dropbox/Tom/MIDS/W266_work/w266_project/T2/20130923_1_HNZ.txt\n",
      "/Users/seddont/Dropbox/Tom/MIDS/W266_work/w266_project/T2/20131114_1_WMT.txt\n",
      "/Users/seddont/Dropbox/Tom/MIDS/W266_work/w266_project/T2/20131220_1_HNZ.txt\n",
      "/Users/seddont/Dropbox/Tom/MIDS/W266_work/w266_project/T2/20140220_1_WMT.txt\n",
      "/Users/seddont/Dropbox/Tom/MIDS/W266_work/w266_project/T2/20140320_1_HNZ.txt\n",
      "/Users/seddont/Dropbox/Tom/MIDS/W266_work/w266_project/T2/20140515_1_WMT.txt\n",
      "/Users/seddont/Dropbox/Tom/MIDS/W266_work/w266_project/T2/20140522_1_HNZ.txt\n",
      "/Users/seddont/Dropbox/Tom/MIDS/W266_work/w266_project/T2/20140725_1_ABBV.txt\n",
      "/Users/seddont/Dropbox/Tom/MIDS/W266_work/w266_project/T2/20140814_1_WMT.txt\n",
      "/Users/seddont/Dropbox/Tom/MIDS/W266_work/w266_project/T2/20140820_1_HNZ.txt\n",
      "/Users/seddont/Dropbox/Tom/MIDS/W266_work/w266_project/T2/20141113_1_WMT.txt\n",
      "/Users/seddont/Dropbox/Tom/MIDS/W266_work/w266_project/T2/20141119_1_HNZ.txt\n",
      "/Users/seddont/Dropbox/Tom/MIDS/W266_work/w266_project/T3/20150219_1_WMT.txt\n",
      "/Users/seddont/Dropbox/Tom/MIDS/W266_work/w266_project/T3/20150313_1_HNZ.txt\n",
      "/Users/seddont/Dropbox/Tom/MIDS/W266_work/w266_project/T3/20150515_1_HNZ.txt\n",
      "/Users/seddont/Dropbox/Tom/MIDS/W266_work/w266_project/T3/20150519_1_WMT.txt\n",
      "/Users/seddont/Dropbox/Tom/MIDS/W266_work/w266_project/T3/20150814_1_HNZ.txt\n",
      "/Users/seddont/Dropbox/Tom/MIDS/W266_work/w266_project/T3/20150814_1_KHC.txt\n",
      "/Users/seddont/Dropbox/Tom/MIDS/W266_work/w266_project/T3/20150818_1_WMT.txt\n",
      "/Users/seddont/Dropbox/Tom/MIDS/W266_work/w266_project/T3/20151117_1_WMT.txt\n",
      "/Users/seddont/Dropbox/Tom/MIDS/W266_work/w266_project/T3/20160218_1_WMT.txt\n",
      "/Users/seddont/Dropbox/Tom/MIDS/W266_work/w266_project/T3/20160519_1_WMT.txt\n",
      "/Users/seddont/Dropbox/Tom/MIDS/W266_work/w266_project/T3/20160721_1_AXP.txt\n",
      "/Users/seddont/Dropbox/Tom/MIDS/W266_work/w266_project/T3/20160818_1_WMT.txt\n",
      "/Users/seddont/Dropbox/Tom/MIDS/W266_work/w266_project/T3/20161117_1_WMT.txt\n",
      "/Users/seddont/Dropbox/Tom/MIDS/W266_work/w266_project/T4/20110222_1_WMT.txt\n",
      "/Users/seddont/Dropbox/Tom/MIDS/W266_work/w266_project/T4/20170221_1_WMT.txt\n",
      "/Users/seddont/Dropbox/Tom/MIDS/W266_work/w266_project/T4/20170620_1_FDX.txt\n",
      "/Users/seddont/Dropbox/Tom/MIDS/W266_work/w266_project/T4/20170919_1_FDX.txt\n"
     ]
    }
   ],
   "source": [
    "# Get the file paths to all files of a specified file type from a given directory\n",
    "def get_files(file_path, file_type):\n",
    "    file_list = glob.glob(file_path + \"*.\" + file_type)\n",
    "    return file_list\n",
    "\n",
    "def get_files_from_dirs(directory_list, file_type):\n",
    "    # Read in all the files from subdirectories into a master list\n",
    "    \n",
    "    matchfiles = []\n",
    "    for d in directory_list:\n",
    "        matchfiles.extend(get_files(LIBRARY_PATH+d+\"/\",'txt'))    \n",
    "    return matchfiles\n",
    "\n",
    "def find_valid_files(file_list):\n",
    "    '''Scans all the files in the file list and returns a list of those which\n",
    "       pass all QA checks, and a list of those that do not, with reason why'''\n",
    "    \n",
    "    good_files = []\n",
    "    problems = []\n",
    "\n",
    "    for path in file_list:\n",
    "        ts = read_transcript(path)\n",
    "        params = get_basic_parameters(ts)\n",
    "        \n",
    "        errs = [\"not equity earnings call\",\n",
    "                \"no co participants\",\n",
    "                \"no other participants\",\n",
    "                \"no mgmt discussion section\",\n",
    "                \"no Q&A section\",\n",
    "                \"no disclaimer\"\n",
    "                ]\n",
    "        \n",
    "        errs_found = []\n",
    "        for i, err in enumerate(errs):\n",
    "            if params[i] == -1:\n",
    "                errs_found.append(err)\n",
    "        \n",
    "        if len(errs_found) == 0:\n",
    "            good_files.append(path)\n",
    "        else:\n",
    "            problems.append((errs_found, path, params))\n",
    "\n",
    "    return good_files, problems\n",
    "\n",
    "\n",
    "files_to_check = get_files_from_dirs(TEXT_DIR_LIST, \"txt\")\n",
    "TextFiles, error_files = find_valid_files(files_to_check)\n",
    "\n",
    "print \"Valid Files found: \", len(TextFiles)\n",
    "print\n",
    "print \"Files rejected:\", len(error_files)\n",
    "print\n",
    "err_counts = defaultdict(int)\n",
    "err_lists = defaultdict(list)\n",
    "for f in error_files:\n",
    "    for err in f[0]:\n",
    "        err_counts[err] += 1\n",
    "        err_lists[err].append(f[1])\n",
    "\n",
    "print \"Number of files with each type of error (file can have >1 error):\"\n",
    "for err in err_counts:\n",
    "    print err, err_counts[err]\n",
    "    print \"Files are:\"\n",
    "    for f in err_lists[err]:\n",
    "        print f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/seddont/Dropbox/Tom/MIDS/W266_work/w266_project/T1/20100730_1_AEP.txt',\n",
       " '/Users/seddont/Dropbox/Tom/MIDS/W266_work/w266_project/T1/20100730_1_CVX.txt',\n",
       " '/Users/seddont/Dropbox/Tom/MIDS/W266_work/w266_project/T1/20100730_1_MET.txt',\n",
       " '/Users/seddont/Dropbox/Tom/MIDS/W266_work/w266_project/T1/20100730_1_MRK.txt',\n",
       " '/Users/seddont/Dropbox/Tom/MIDS/W266_work/w266_project/T1/20100730_1_SPG.txt']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TextFiles[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-processing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_square_brackets(my_str):\n",
    "    return re.sub(r'\\[.+?\\]', '', my_str)\n",
    "\n",
    "def remove_square_brackets_transcript(ts):\n",
    "    return list(map(lambda line: remove_square_brackets(line), ts))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Find participants on the call\n",
    "def get_parts(ts, start_index, end_index):\n",
    "    result = [name[re.search(\"[a-z]\", name.lower()).start():] for name in ts[start_index+1:end_index] if len(name) >= 3]\n",
    "    # Check for problematic names\n",
    "    extra_names = []\n",
    "    for name in result:\n",
    "        # Find any title after name and remove it\n",
    "        if name.find(',') != -1:\n",
    "            name_only = name[:name.find(',')]\n",
    "            extra_names.append(name_only)\n",
    "        # Find names with middle initials and remove them\n",
    "        elif name.find('.') != -1:\n",
    "            name_only = remove_middle_initials(name)\n",
    "            if name_only != name:\n",
    "                extra_names.append(name_only)\n",
    "    # Find names in extra names with middle initials and remove them\n",
    "    for name in extra_names:\n",
    "        if name.find('.') != -1:\n",
    "            name_only = remove_middle_initials(name)\n",
    "            if name_only != name:\n",
    "                extra_names.append(name_only)\n",
    "    return result + extra_names\n",
    "\n",
    "# Remove middle initial from a name\n",
    "def remove_middle_initials(my_str):\n",
    "    # count = 0\n",
    "    while True:\n",
    "        if my_str.find('.') != -1:\n",
    "            new_my_str = re.sub(r'(\\s)([A-Z].)(\\s)', r\"\\1\", my_str)\n",
    "            if new_my_str == my_str:\n",
    "                break\n",
    "            else:\n",
    "                my_str = new_my_str\n",
    "            # count += 1\n",
    "            # if count >= 10:\n",
    "            #     break\n",
    "        else:\n",
    "            break\n",
    "    return my_str\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Find a section of the call\n",
    "def get_section(ts, start_index, end_index):\n",
    "    result = ts[start_index+1:end_index]\n",
    "    result = [line for line in result if line not in ['\\x0c']]   # clean the transcript for unnecessary lines\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_MD(ts, names, start_index, end_index):\n",
    "\n",
    "    curr_speaker = \"\"\n",
    "    section_header = \"MD\"\n",
    "    \n",
    "    # Create an empty dict for comments by each manager\n",
    "    pts = {name: \"\" for name in names}\n",
    "\n",
    "    # Get the required section\n",
    "    section = get_section(ts, start_index, end_index)\n",
    "    \n",
    "    # Find the first instance of a co_parts speaker\n",
    "    start_section = 0\n",
    "    while True:\n",
    "        if section[start_section] not in names:\n",
    "            start_section += 1\n",
    "        else:\n",
    "            break\n",
    "        if start_section == len(section):\n",
    "            start_section = -1\n",
    "            break\n",
    "\n",
    "    if start_section == -1:\n",
    "        pts['No speaker found'] = section_header\n",
    "    else:\n",
    "        # Reduce MD Section to management speaking only\n",
    "        section = section[start_section:]\n",
    "        # populate comment dict\n",
    "        for line in section:\n",
    "            if line in names:\n",
    "                curr_speaker = line\n",
    "            elif len(line) != 0:\n",
    "                pts[curr_speaker] += line + \" \"\n",
    "\n",
    "    return pts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This procedure combines the raw Q&A section into pairs of questions and answers in a dictionary\n",
    "\n",
    "def get_QA(ts, start_index, end_index):\n",
    "\n",
    "    pts = {}\n",
    "    # get the Q&A section\n",
    "    qa_section = get_section(ts, start_index, end_index)\n",
    "\n",
    "    q_or_a = None\n",
    "    currQ = ''\n",
    "    currA = ''\n",
    "    \n",
    "    for line in qa_section:\n",
    "        line = remove_square_brackets(line)\n",
    "        if len(line) > 0:                                     # if line is '' then ignore otherwise process the line\n",
    "            if line == 'Operator':                            # if line is 'Operator' then set everything NULL and ignore\n",
    "                q_or_a = None\n",
    "                currQ = ''\n",
    "                currA = ''\n",
    "            if line[0] == \"<\":                                # if Q or A found do something\n",
    "                if line[0:2] == \"<Q\":\n",
    "                    if q_or_a == 'A':                         # if Q found and q_or_a is not NULL then add Q: A to the dictionary\n",
    "                        pts[currQ[:-1]] = currA[:-1]          # and reset the parameters to NULL\n",
    "                        currQ = ''\n",
    "                        currA = ''\n",
    "                        q_or_a = None    \n",
    "                    end_qa_tag = line.find(\">\")\n",
    "                    currQ += line[end_qa_tag + 3:] + \" \"      # Concatenate the string after the '>' to the previous string\n",
    "                    q_or_a = 'Q'                              # Given Q found set q_or_a = 'Q'\n",
    "                if line[0:2] == \"<A\":\n",
    "                    end_qa_tag = line.find(\">\")             \n",
    "                    currA += line[end_qa_tag + 3:] + \" \"      # Concatenate the string after the '>' to the previous string\n",
    "                    q_or_a = 'A'                              # Given Q found set q_or_a = 'Q'\n",
    "            else:                                             \n",
    "                if q_or_a is not None:                        # Other if currently a Q or A just concatenate the string \n",
    "                    if q_or_a == 'Q':\n",
    "                        currQ += line + \" \"\n",
    "                    else:\n",
    "                        currA += line + \" \"\n",
    "\n",
    "    if currQ != '' and currA != '':                           # Add last Q: A pair to the dictionary if necessary\n",
    "        pts[currQ[:-1]] = currA[:-1]\n",
    "\n",
    "    return pts\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Bespoke cleaning\n",
    "\n",
    "The following procedures deal with strings with words that have apostrophes, hyphens, slashes and unusual characters in them to help best isolate actual words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def short_form_replace(my_str):\n",
    "    \"\"\"Convert apostrophes in known short-forms in my_string to long-forms\"\"\"\n",
    "    my_str = replace_non_utf8_apostrophes(my_str)\n",
    "    my_str = re.sub(r'let\\'s', \"let us\", my_str)\n",
    "    my_str = re.sub(r'Let\\'s', \"let us\", my_str)\n",
    "    my_str = re.sub(r'won\\'t', \"will not\", my_str)\n",
    "    my_str = re.sub(r'can\\'t', \"cannot\", my_str)\n",
    "    my_str = re.sub(r'shan\\'t', \"shall not\", my_str)\n",
    "    my_str = re.sub(r'Won\\'t', \"Will not\", my_str)\n",
    "    my_str = re.sub(r'Can\\'t', \"Cannot\", my_str)\n",
    "    my_str = re.sub(r'Shan\\'t', \"Shall not\", my_str)\n",
    "    my_str = re.sub(r'n\\'t', \" not\", my_str)\n",
    "    my_str = re.sub(r'\\'ve', \" have\", my_str)\n",
    "    my_str = re.sub(r'\\'re', \" are\", my_str)\n",
    "    my_str = re.sub(r'\\'m', \" am\", my_str)\n",
    "    my_str = re.sub(r'\\'ll', \" will\", my_str)\n",
    "    my_str = re.sub(r'\\'d', \" would\", my_str)     # note could also be did or had as well\n",
    "    my_str = re.sub(r'it\\'s', \"it is\", my_str)\n",
    "    my_str = re.sub(r'he\\'s', \"he is\", my_str)\n",
    "    my_str = re.sub(r'she\\'s', \"she is\", my_str)\n",
    "    my_str = re.sub(r'that\\'s', \"that is\", my_str)\n",
    "    my_str = re.sub(r'what\\'s', \"what is\", my_str)\n",
    "    my_str = re.sub(r'here\\'s', \"here is\", my_str)\n",
    "    my_str = re.sub(r'there\\'s', \"there is\", my_str)\n",
    "    my_str = re.sub(r'who\\'s', \"who is\", my_str)\n",
    "    my_str = re.sub(r'It\\'s', \"It is\", my_str)\n",
    "    my_str = re.sub(r'He\\'s', \"He is\", my_str)\n",
    "    my_str = re.sub(r'She\\'s', \"She is\", my_str)\n",
    "    my_str = re.sub(r'Shat\\'s', \"That is\", my_str)\n",
    "    my_str = re.sub(r'What\\'s', \"What is\", my_str)\n",
    "    my_str = re.sub(r'Here\\'s', \"Here is\", my_str)\n",
    "    my_str = re.sub(r'There\\'s', \"There is\", my_str)\n",
    "    my_str = re.sub(r\"Who's\", \"Who is\", my_str)\n",
    "    return my_str\n",
    "\n",
    "\n",
    "def apostrophe_s_replace(my_str):\n",
    "    \"\"\"Remove 's at the end of words in my_string. Best to run this after short_form_replace()\"\"\"\n",
    "    my_str = re.sub(r\"([A-z])\\'s\", r\"\\1\", my_str)\n",
    "    return my_str\n",
    "\n",
    "\n",
    "def hyphen_replace(my_str):\n",
    "    \"\"\"Replace hyphens in hyphenated words with a space\"\"\"\n",
    "    my_str = re.sub(r\"([A-z])(\\-)([A-z])\", r\"\\1 \\3\", my_str)\n",
    "    my_str = re.sub(r\"([A-z])(\\-)(\\s)([A-z])\", r\"\\1 \\4\", my_str)\n",
    "    return my_str\n",
    "\n",
    "\n",
    "def forward_slash_replace(my_str):\n",
    "    \"\"\"Replace forward slashes in combined words with a space.\"\"\"\n",
    "    my_str = re.sub(r\"([A-z])(/)([A-z])\", r\"\\1 \\3\", my_str)\n",
    "    my_str = my_str.replace(')/', ' ')\n",
    "    my_str = my_str.replace('/(', ' ')\n",
    "    return my_str\n",
    "\n",
    "\n",
    "def replace_apostrophes(my_str):\n",
    "    \"\"\"Tidy up my_string for all apostrophe-related issues.\"\"\"\n",
    "    my_str = replace_non_utf8_apostrophes(my_str)\n",
    "    my_str = short_form_replace(my_str)\n",
    "    my_str = apostrophe_s_replace(my_str)\n",
    "    return my_str\n",
    "\n",
    "\n",
    "def clean_text(my_str):\n",
    "    \"\"\"Clean my_string for all known string issues to prepare for text analysis\"\"\"\n",
    "    my_str = replace_apostrophes(my_str)\n",
    "    my_str = hyphen_replace(my_str)\n",
    "    my_str = forward_slash_replace(my_str)\n",
    "    return my_str\n",
    "\n",
    "\n",
    "def replace_non_utf8_apostrophes(my_str):\n",
    "    \"\"\"Replace most common non-utf-8 apostrophes with utf-8 apostrophes\"\"\"\n",
    "    apostrophes = [str(b'\\xe2\\x80\\x98'), str(b'\\xe2\\x80\\x99')]\n",
    "    for i in range(len(my_str)):\n",
    "        if str(my_str[i].encode('utf-8')) in apostrophes:\n",
    "            my_str = my_str[:i] + \"'\" + my_str[i+1:]\n",
    "    return my_str\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "tokenizer = RegexpTokenizer(r'\\w+')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stop Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import stop words list\n",
    "stop_words = get_dictionary(LIBRARY_PATH,'stop_words.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/seddont/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create English stop words list from NLTK\n",
    "nltk_stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stop_words = sorted(list(set(stop_words + nltk_stop_words)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_filename_components(file_path, i):\n",
    "    file_name_and_ext = os.path.basename(file_path)\n",
    "    name_only = os.path.splitext(file_name_and_ext)[0]\n",
    "    date, file_num, ticker = name_only.split(\"_\")\n",
    "    \n",
    "    return (ticker, date, file_num)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LDA Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "http://rstudio-pubs-static.s3.amazonaws.com/79360_850b2a69980c4488b1db95987a24867a.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#!pip install --index-url=http://pypi.python.org/simple/ --trusted-host pypi.python.org gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!pip install --index-url=http://pypi.python.org/simple/ --trusted-host pypi.python.org smart_open"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def replace_number(token):\n",
    "    if token.isdigit():\n",
    "        return \"NUM\"\n",
    "    else:\n",
    "        return token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['okay', u'current', 'end', 'year', 'NUM']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_doc = ['okay', u'current', 'end', 'year', '2011']\n",
    "[replace_number(t) for t in test_doc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def testLDA_pre_process_document(doc):\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')  # This finds letters only and breaks things up at each non-letters character\n",
    "    porter_stemmer = PorterStemmer()\n",
    "    lower_doc = doc.lower()\n",
    "    clean_lower_doc = remove_square_brackets(lower_doc)\n",
    "    clean_doc = clean_text(clean_lower_doc)\n",
    "    tokens = tokenizer.tokenize(clean_doc)\n",
    "    stopped_tokens = [t for t in tokens if not t in stop_words]\n",
    "    stemmed_tokens = [porter_stemmer.stem(i) for i in stopped_tokens]\n",
    "    replaced_num_tokens = [replace_number(t) for t in stemmed_tokens]\n",
    "    return replaced_num_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learn topic model, apply to Q&A pairs and evaluate similarity of Qs and As"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_raw_qa(source_list, output_file):\n",
    "    '''Extract raw Q and A text from a list of files and put a structured dictionary\n",
    "       of the extracted Q & A pairs into an output file.\n",
    "       \n",
    "       Returns a dictionary of raw Q&A pairs'''\n",
    "    \n",
    "    rawtext_qa = defaultdict(dict)\n",
    "    i = 0\n",
    "    report_every = 500\n",
    "    start_time = time.time()\n",
    "    \n",
    "    for f in source_list:\n",
    "    \n",
    "        (ticker, date, file_num) = get_filename_components(f, i)\n",
    "\n",
    "        file_id = ticker+\"_\"+date\n",
    "\n",
    "        ts = read_transcript(f)\n",
    "\n",
    "        # Get Company Participants\n",
    "        start = find_full_string_index(ts, CO_PART_HEADERS)\n",
    "        end = find_full_string_index(ts, OTH_PART_HEADERS) - 1\n",
    "        if start != -1 and end != -2: \n",
    "            co_part_names = get_parts(ts, start, end)\n",
    "\n",
    "            # Get QA Section\n",
    "            start = find_full_string_index(ts, QA_SECTION_HEADERS)\n",
    "            end = find_disclaimer_index(ts, DISCLAIMER)\n",
    "            QA = get_QA(ts, start, end)\n",
    "\n",
    "            # get the QA pairs with a condition to ensure both of at least some length\n",
    "            q_number = 0\n",
    "            for question in QA:\n",
    "\n",
    "                # store indexed rawtext for easier inspection later\n",
    "                rawtext_qa[file_id][q_number] = (question, QA[question])\n",
    "                \n",
    "                q_number += 1\n",
    "\n",
    "        i += 1\n",
    "        if i % report_every == 0:\n",
    "            print \"Processed \", i, \"transcripts in \", time.time() - start_time, \"seconds\"\n",
    "            \n",
    "    # Also store the rawtext pairs, for easier inspection later\n",
    "    with open(output_file, \"w\") as f:\n",
    "        f.write(json.dumps(rawtext_qa))\n",
    "    \n",
    "    print \"Finished extracting q and a text from all\", i, \"transcripts in \", time.time() - start_time, \"seconds\"\n",
    "    \n",
    "    return rawtext_qa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def save_model_spec(model_spec):\n",
    "    '''Saves a model spec as a JSON in its specified directory'''\n",
    "    if not os.path.exists(LIBRARY_PATH + model_spec[\"model_directory\"]):\n",
    "        os.mkdir(LIBRARY_PATH + model_spec[\"model_directory\"])\n",
    "\n",
    "    # Store the processed tokens in qa_pairs\n",
    "    model_spec_path = LIBRARY_PATH+model_spec[\"model_directory\"]+\"/model_spec.txt\"\n",
    "    with open(model_spec_path, \"w\") as f:\n",
    "        f.write(json.dumps(model_spec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_raw_qa_pairs(rawtext_qa, model_spec):\n",
    "    '''Turns raw text q and a pairs into processed token sequences using prepro_func\n",
    "       passed to it.\n",
    "       \n",
    "       Returns a dictionary of processed q and a pairs.'''\n",
    "    \n",
    "    qa_pairs = defaultdict(dict)\n",
    "    start_time = time.time()\n",
    "    i = 0\n",
    "    report_every = 2500\n",
    "    \n",
    "    prepro_func = PREPRO_FUNCTIONS[model_spec[\"preprocessing_function\"]]\n",
    "    \n",
    "    # Assemble a unified training texts list from all the qualifying processed Q&A pairs found\n",
    "    for file_id in rawtext_qa:\n",
    "        for q_number in rawtext_qa[file_id]:\n",
    "            \n",
    "            procd_question = prepro_func(rawtext_qa[file_id][q_number][0])\n",
    "            procd_answer = prepro_func(rawtext_qa[file_id][q_number][1])\n",
    "            \n",
    "            qa_pairs[file_id][q_number] = (procd_question, procd_answer)\n",
    "            \n",
    "            i += 1\n",
    "            if i % report_every == 0:\n",
    "                print \"Processed \", i, \"pairs in \", time.time() - start_time, \"seconds\"\n",
    "                    \n",
    "    print \"Finished all\", i, \"raw q and a pairs in \", time.time() - start_time, \"seconds\"\n",
    "            \n",
    "    return qa_pairs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def select_texts(qa_pairs, model_spec):\n",
    "    '''Assembles a unified set of training texts, that conforms with the \n",
    "       model specification.'''\n",
    "    \n",
    "    # Assemble a unified training texts list from all the qualifying processed Q&A pairs found\n",
    "    texts = []\n",
    "    min_sequence_length = model_spec[\"min_sequence_length\"]\n",
    "    \n",
    "    count_accepted = 0\n",
    "    count_rejected = 0\n",
    "    \n",
    "    for file_id in qa_pairs:\n",
    "        for q_number in qa_pairs[file_id]:\n",
    "            question, answer = qa_pairs[file_id][q_number]\n",
    "            if (len(question) > min_sequence_length and\n",
    "                len(answer) > min_sequence_length):\n",
    "                texts.append(question)\n",
    "                texts.append(answer)\n",
    "                count_accepted += 1\n",
    "            else:\n",
    "                count_rejected +=1\n",
    "                \n",
    "    print count_accepted, \"pairs met minimum length.\"\n",
    "    print count_rejected, \"were rejected.\"\n",
    "                \n",
    "    return texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def learn_LDA_model(model_spec, texts, passes = 10, iterations = 50):\n",
    "    '''Learns an LDA model according to the model spec and stores the associated files'''\n",
    "    \n",
    "    model_dir = LIBRARY_PATH+model_spec[\"model_directory\"]\n",
    "    \n",
    "    # Set up logging to file for Gensim progress\n",
    "\n",
    "    # Clear any other logging handlers\n",
    "    for handler in logging.root.handlers[:]:\n",
    "        logging.root.removeHandler(handler)\n",
    "        \n",
    "    logging.basicConfig(filename=model_dir+'/lda_logfile.log', format='%(asctime)s : %(levelname)s : %(message)s', level=logging.DEBUG)\n",
    "   \n",
    "    # Convert the texts from all the Questions and Answers into integer form and save\n",
    "    dictionary = corpora.Dictionary(texts)\n",
    "    dictionary.save(model_dir+\"/dictionary.txt\")\n",
    "    \n",
    "    # Create and save corpus\n",
    "    corpus = [dictionary.doc2bow(text) for text in texts]\n",
    "    with open(model_dir+\"/corpus.txt\", \"w\") as f:\n",
    "        f.write(json.dumps(corpus))\n",
    "        \n",
    "    # Fit the LDA model\n",
    "\n",
    "    start_time = time.time()\n",
    "    print \"fitting model\"\n",
    "    # Fit LDA model\n",
    "    ldamodel = gensim.models.ldamodel.LdaModel(corpus = corpus,\n",
    "                                               num_topics=model_spec[\"num_topics\"],\n",
    "                                               id2word = dictionary,\n",
    "                                               passes=passes,\n",
    "                                               iterations = iterations,\n",
    "                                               eval_every = 10)\n",
    "    \n",
    "    print \"model fitting took\", time.time() - start_time, \"seconds\"\n",
    "    \n",
    "    # Remove logging handlers\n",
    "    for handler in logging.root.handlers[:]:\n",
    "        logging.root.removeHandler(handler)\n",
    "    \n",
    "    # Save the learned model to file\n",
    "    ldamodel.save(model_dir + \"/full_model\")\n",
    "    \n",
    "    # Save a UTC timestamp into the directory\n",
    "    model_run_at = str(datetime.datetime.utcnow())\n",
    "    with open(model_dir+\"/model_runtime.txt\", \"w\") as f:\n",
    "        f.write(model_run_at)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def calc_hellinger_sims(model_spec):\n",
    "    '''Calc hellinger similarities for a model and its data.'''\n",
    "\n",
    "    hellinger_sims = defaultdict(dict)\n",
    "    \n",
    "    model_dir = LIBRARY_PATH+model_spec[\"model_directory\"]\n",
    "    qa_dir = LIBRARY_PATH+model_spec[\"qa_pair_directory\"]\n",
    "    \n",
    "    with open(qa_dir+\"/qa_pairs.txt\", \"r\") as f:\n",
    "        qa_pairs = json.loads(f.read())\n",
    "        \n",
    "    ldamodel = gensim.models.ldamodel.LdaModel.load(model_dir+\"/full_model\")\n",
    "    dictionary = gensim.corpora.dictionary.Dictionary.load(model_dir+\"/dictionary.txt\")\n",
    "\n",
    "    start_time = time.time()\n",
    "    i = 0\n",
    "    report_every = 5000\n",
    "    \n",
    "    min_sequence_length = model_spec[\"min_sequence_length\"]\n",
    "\n",
    "    for file_id in qa_pairs:\n",
    "        for q_number in qa_pairs[file_id]:\n",
    "            question, answer = qa_pairs[file_id][q_number]\n",
    "            if (len(question) > min_sequence_length and\n",
    "                len(answer) > min_sequence_length):\n",
    "                q_bow = dictionary.doc2bow(question)\n",
    "                a_bow = dictionary.doc2bow(answer)\n",
    "                lda_q_bow = ldamodel[q_bow]\n",
    "                lda_a_bow = ldamodel[a_bow]\n",
    "                hellinger_sims[file_id][q_number] = hellinger(lda_q_bow, lda_a_bow)\n",
    "            i += 1\n",
    "            if i % report_every == 0:\n",
    "                print \"Processed \", i, \"pairs in\", time.time() - start_time\n",
    "    print \"Finished in\", time.time() - start_time\n",
    "    \n",
    "    # Store the corpus to file for recreating model later if wanted\n",
    "    with open(model_dir+\"/hell_sims.txt\", \"w\") as f:\n",
    "        f.write(json.dumps(hellinger_sims))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Restoring from a saved state\n",
    "\n",
    "Since training the models and processing the text is quite time consuming, it's useful to be able to restore a saved model.  Gensim makes saving and restoring a model easy, but we will often want to also be able to look at the data associated with that model.  This data may not always be the same, because we may apply different preprocessing to the raw transcript text to test the impact of that on the quality of the models.\n",
    "\n",
    "We also may want to generate multiple models from the same processed set of data with different LDA hyperparameters (e.g. number of topics) so the same inpiut data might be associated with multiple LDA models.\n",
    "\n",
    "To make this easy during experimentation this is a class that recovers a saved state from files on disk.  The state is specified by the model_spec dictionary of files so it is very easy to handle any combination of data and models (as long as we kept track in the first place of what data created what model)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Saved_state():\n",
    "    '''Represents a saved state that includes an LDA model and the data used to create it.\n",
    "    \n",
    "       Instantiated with a model_spec dictionary that locates the files to \n",
    "       recreate the saved state and includes a description.\n",
    "       \n",
    "       Dictionary needs to contain:\n",
    "       \n",
    "       model_files\n",
    "       qa_pairs_file\n",
    "       raw_qa_text_file\n",
    "       corpus_file\n",
    "       hellinger_file\n",
    "       '''\n",
    "    def __init__(self, model_spec):\n",
    "        \n",
    "        model_dir = LIBRARY_PATH+model_spec[\"model_directory\"]\n",
    "        qa_dir = LIBRARY_PATH+model_spec[\"qa_pair_directory\"]\n",
    "        \n",
    "        self.ldamodel = gensim.models.ldamodel.LdaModel.load(model_dir+\"/full_model\")\n",
    "        \n",
    "        self.dictionary = gensim.corpora.dictionary.Dictionary.load(model_dir+\"/dictionary.txt\")\n",
    "        \n",
    "        with open(qa_dir+\"/qa_pairs.txt\", \"r\") as f:\n",
    "            self.qa_pairs = json.loads(f.read())\n",
    "            \n",
    "        with open(LIBRARY_PATH + \"/raw_qa_data.txt\", \"r\") as f:\n",
    "            self.raw_qa_text = json.loads(f.read())\n",
    "            \n",
    "        with open(model_dir+\"/corpus.txt\", \"r\") as f:\n",
    "            self.corpus = json.loads(f.read())\n",
    "            \n",
    "        with open(model_dir+\"/hell_sims.txt\", \"r\") as f:\n",
    "            self.hellinger_sims = json.loads(f.read())\n",
    "            \n",
    "        with open(model_dir+\"/model_runtime.txt\", \"r\") as f:\n",
    "            self.model_runtime = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting information to inspect topics and errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Running with different parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_spec = {\"model_directory\": \"saved_models/topic10_minlength20_base\",\n",
    "              \"qa_pair_directory\": \"saved_models/standard_preproc\",\n",
    "              \"preprocessing_function\": \"testLDA_pre_process_document\",\n",
    "              \"min_sequence_length\": 20,\n",
    "              \"num_topics\": 10,\n",
    "              \"description\": \"Topics 10, Min Length 20, Standard preprocessing\"}\n",
    "\n",
    "# maps function specs to function object\n",
    "PREPRO_FUNCTIONS = {\"testLDA_pre_process_document\": testLDA_pre_process_document}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run a model with higher number of iterations to compare convergence performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'description': 'Topics 10, Min Length 10, base preprocessing, passes20, iterations100',\n",
       "  'iterations': 100,\n",
       "  'min_sequence_length': 10,\n",
       "  'model_directory': 'saved_models/top10_len10_prebase_ps20_it100',\n",
       "  'num_topics': 10,\n",
       "  'passes': 20,\n",
       "  'preprocessing_function': 'testLDA_pre_process_document',\n",
       "  'qa_pair_directory': 'saved_models/standard_preproc'},\n",
       " {'description': 'Topics 10, Min Length 20, base preprocessing, passes20, iterations100',\n",
       "  'iterations': 100,\n",
       "  'min_sequence_length': 20,\n",
       "  'model_directory': 'saved_models/top10_len20_prebase_ps20_it100',\n",
       "  'num_topics': 10,\n",
       "  'passes': 20,\n",
       "  'preprocessing_function': 'testLDA_pre_process_document',\n",
       "  'qa_pair_directory': 'saved_models/standard_preproc'},\n",
       " {'description': 'Topics 10, Min Length 40, base preprocessing, passes20, iterations100',\n",
       "  'iterations': 100,\n",
       "  'min_sequence_length': 40,\n",
       "  'model_directory': 'saved_models/top10_len40_prebase_ps20_it100',\n",
       "  'num_topics': 10,\n",
       "  'passes': 20,\n",
       "  'preprocessing_function': 'testLDA_pre_process_document',\n",
       "  'qa_pair_directory': 'saved_models/standard_preproc'},\n",
       " {'description': 'Topics 20, Min Length 10, base preprocessing, passes20, iterations100',\n",
       "  'iterations': 100,\n",
       "  'min_sequence_length': 10,\n",
       "  'model_directory': 'saved_models/top20_len10_prebase_ps20_it100',\n",
       "  'num_topics': 20,\n",
       "  'passes': 20,\n",
       "  'preprocessing_function': 'testLDA_pre_process_document',\n",
       "  'qa_pair_directory': 'saved_models/standard_preproc'},\n",
       " {'description': 'Topics 20, Min Length 20, base preprocessing, passes20, iterations100',\n",
       "  'iterations': 100,\n",
       "  'min_sequence_length': 20,\n",
       "  'model_directory': 'saved_models/top20_len20_prebase_ps20_it100',\n",
       "  'num_topics': 20,\n",
       "  'passes': 20,\n",
       "  'preprocessing_function': 'testLDA_pre_process_document',\n",
       "  'qa_pair_directory': 'saved_models/standard_preproc'},\n",
       " {'description': 'Topics 20, Min Length 40, base preprocessing, passes20, iterations100',\n",
       "  'iterations': 100,\n",
       "  'min_sequence_length': 40,\n",
       "  'model_directory': 'saved_models/top20_len40_prebase_ps20_it100',\n",
       "  'num_topics': 20,\n",
       "  'passes': 20,\n",
       "  'preprocessing_function': 'testLDA_pre_process_document',\n",
       "  'qa_pair_directory': 'saved_models/standard_preproc'},\n",
       " {'description': 'Topics 40, Min Length 10, base preprocessing, passes20, iterations100',\n",
       "  'iterations': 100,\n",
       "  'min_sequence_length': 10,\n",
       "  'model_directory': 'saved_models/top40_len10_prebase_ps20_it100',\n",
       "  'num_topics': 40,\n",
       "  'passes': 20,\n",
       "  'preprocessing_function': 'testLDA_pre_process_document',\n",
       "  'qa_pair_directory': 'saved_models/standard_preproc'},\n",
       " {'description': 'Topics 40, Min Length 20, base preprocessing, passes20, iterations100',\n",
       "  'iterations': 100,\n",
       "  'min_sequence_length': 20,\n",
       "  'model_directory': 'saved_models/top40_len20_prebase_ps20_it100',\n",
       "  'num_topics': 40,\n",
       "  'passes': 20,\n",
       "  'preprocessing_function': 'testLDA_pre_process_document',\n",
       "  'qa_pair_directory': 'saved_models/standard_preproc'},\n",
       " {'description': 'Topics 40, Min Length 40, base preprocessing, passes20, iterations100',\n",
       "  'iterations': 100,\n",
       "  'min_sequence_length': 40,\n",
       "  'model_directory': 'saved_models/top40_len40_prebase_ps20_it100',\n",
       "  'num_topics': 40,\n",
       "  'passes': 20,\n",
       "  'preprocessing_function': 'testLDA_pre_process_document',\n",
       "  'qa_pair_directory': 'saved_models/standard_preproc'}]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a list of model specs to run\n",
    "\n",
    "num_topics_list = [10, 20, 40]\n",
    "min_length_list = [10, 20, 40]\n",
    "pre_pro_list = [(\"base\", \"testLDA_pre_process_document\")]\n",
    "passes_list = [20]\n",
    "iterations_list = [100]\n",
    "\n",
    "model_spec_list = []\n",
    "\n",
    "for num_topics in num_topics_list:\n",
    "    for min_length in min_length_list:\n",
    "        for pre_pro in pre_pro_list:\n",
    "            for passes in passes_list:\n",
    "                for iterations in iterations_list:\n",
    "                \n",
    "                    dir_name = \"top\"+str(num_topics)+\\\n",
    "                               \"_len\"+str(min_length)+\\\n",
    "                               \"_pre\"+pre_pro[0]+\\\n",
    "                               \"_ps\"+str(passes)+\\\n",
    "                               \"_it\"+str(iterations)\n",
    "\n",
    "                    model_dir = \"saved_models/\"+dir_name\n",
    "\n",
    "                    model_spec = {\"model_directory\": model_dir,\n",
    "                  \"qa_pair_directory\": \"saved_models/standard_preproc\",\n",
    "                  \"preprocessing_function\": pre_pro[1],\n",
    "                  \"min_sequence_length\": min_length,\n",
    "                  \"num_topics\": num_topics,\n",
    "                  \"passes\": passes,\n",
    "                  \"iterations\": iterations,\n",
    "                  \"description\": \"Topics \"+str(num_topics)+\\\n",
    "                                  \", Min Length \"+str(min_length)+\\\n",
    "                                  \", \"+pre_pro[0]+\" preprocessing\"+\\\n",
    "                                  \", passes\"+str(passes)+\\\n",
    "                                  \", iterations\"+str(iterations)}\n",
    "\n",
    "                    model_spec_list.append(model_spec)\n",
    "\n",
    "model_spec_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50433 pairs met minimum length.\n",
      "34373 were rejected.\n",
      "fitting model\n",
      "model fitting took 2595.53394294 seconds\n",
      "Processed  5000 pairs in 6.21942782402\n",
      "Processed  10000 pairs in 12.4161520004\n",
      "Processed  15000 pairs in 18.8181989193\n",
      "Processed  20000 pairs in 24.906886816\n",
      "Processed  25000 pairs in 31.0879378319\n",
      "Processed  30000 pairs in 37.1491379738\n",
      "Processed  35000 pairs in 43.3238339424\n",
      "Processed  40000 pairs in 49.5357439518\n",
      "Processed  45000 pairs in 55.7631449699\n",
      "Processed  50000 pairs in 61.9721388817\n",
      "Processed  55000 pairs in 67.950168848\n",
      "Processed  60000 pairs in 74.2484929562\n",
      "Processed  65000 pairs in 80.2668848038\n",
      "Processed  70000 pairs in 86.1547529697\n",
      "Processed  75000 pairs in 92.6742429733\n",
      "Processed  80000 pairs in 98.6693148613\n",
      "Finished in 104.354513884\n",
      "37304 pairs met minimum length.\n",
      "47502 were rejected.\n",
      "fitting model\n",
      "model fitting took 2063.00563502 seconds\n",
      "Processed  5000 pairs in 5.23531413078\n",
      "Processed  10000 pairs in 10.4128570557\n",
      "Processed  15000 pairs in 15.6498150826\n",
      "Processed  20000 pairs in 20.6930520535\n",
      "Processed  25000 pairs in 25.9081370831\n",
      "Processed  30000 pairs in 31.0932319164\n",
      "Processed  35000 pairs in 36.1552429199\n",
      "Processed  40000 pairs in 41.2990789413\n",
      "Processed  45000 pairs in 46.4660229683\n",
      "Processed  50000 pairs in 51.7017090321\n",
      "Processed  55000 pairs in 56.761079073\n",
      "Processed  60000 pairs in 62.0466980934\n",
      "Processed  65000 pairs in 66.9072329998\n",
      "Processed  70000 pairs in 71.6966879368\n",
      "Processed  75000 pairs in 77.3222460747\n",
      "Processed  80000 pairs in 82.2785689831\n",
      "Finished in 86.948018074\n",
      "13245 pairs met minimum length.\n",
      "71561 were rejected.\n",
      "fitting model\n",
      "model fitting took 888.248628139 seconds\n",
      "Processed  5000 pairs in 2.13743019104\n",
      "Processed  10000 pairs in 4.53645014763\n",
      "Processed  15000 pairs in 6.83402609825\n",
      "Processed  20000 pairs in 8.85990905762\n",
      "Processed  25000 pairs in 11.032323122\n",
      "Processed  30000 pairs in 13.1037180424\n",
      "Processed  35000 pairs in 15.163506031\n",
      "Processed  40000 pairs in 17.3321681023\n",
      "Processed  45000 pairs in 19.4432611465\n",
      "Processed  50000 pairs in 21.6928582191\n",
      "Processed  55000 pairs in 23.5947132111\n",
      "Processed  60000 pairs in 25.7707362175\n",
      "Processed  65000 pairs in 27.8028390408\n",
      "Processed  70000 pairs in 29.7161240578\n",
      "Processed  75000 pairs in 32.2994081974\n",
      "Processed  80000 pairs in 34.3524332047\n",
      "Finished in 36.2475922108\n",
      "50433 pairs met minimum length.\n",
      "34373 were rejected.\n",
      "fitting model\n",
      "model fitting took 3145.14367414 seconds\n",
      "Processed  5000 pairs in 7.73156404495\n",
      "Processed  10000 pairs in 15.4376769066\n",
      "Processed  15000 pairs in 22.993694067\n",
      "Processed  20000 pairs in 30.5884940624\n",
      "Processed  25000 pairs in 38.3610579967\n",
      "Processed  30000 pairs in 46.1832480431\n",
      "Processed  35000 pairs in 53.8386650085\n",
      "Processed  40000 pairs in 61.5498459339\n",
      "Processed  45000 pairs in 69.3946199417\n",
      "Processed  50000 pairs in 77.2150609493\n",
      "Processed  55000 pairs in 84.7368929386\n",
      "Processed  60000 pairs in 92.6457369328\n",
      "Processed  65000 pairs in 100.186104059\n",
      "Processed  70000 pairs in 107.680947065\n",
      "Processed  75000 pairs in 115.798966885\n",
      "Processed  80000 pairs in 123.328660011\n",
      "Finished in 130.546846867\n",
      "37304 pairs met minimum length.\n",
      "47502 were rejected.\n",
      "fitting model\n",
      "model fitting took 2407.33565307 seconds\n",
      "Processed  5000 pairs in 6.09651303291\n",
      "Processed  10000 pairs in 12.1211121082\n",
      "Processed  15000 pairs in 18.1426329613\n",
      "Processed  20000 pairs in 24.0167479515\n",
      "Processed  25000 pairs in 30.0887751579\n",
      "Processed  30000 pairs in 36.0718250275\n",
      "Processed  35000 pairs in 42.0556759834\n",
      "Processed  40000 pairs in 48.0545501709\n",
      "Processed  45000 pairs in 54.2362799644\n",
      "Processed  50000 pairs in 60.3620779514\n",
      "Processed  55000 pairs in 66.3018980026\n",
      "Processed  60000 pairs in 72.5469560623\n",
      "Processed  65000 pairs in 78.2814331055\n",
      "Processed  70000 pairs in 83.9750900269\n",
      "Processed  75000 pairs in 90.4792439938\n",
      "Processed  80000 pairs in 96.3762590885\n",
      "Finished in 101.874655008\n",
      "13245 pairs met minimum length.\n",
      "71561 were rejected.\n",
      "fitting model\n",
      "model fitting took 991.696969032 seconds\n",
      "Processed  5000 pairs in 2.37878799438\n",
      "Processed  10000 pairs in 4.81040501595\n",
      "Processed  15000 pairs in 7.27025914192\n",
      "Processed  20000 pairs in 9.53438520432\n",
      "Processed  25000 pairs in 11.9755940437\n",
      "Processed  30000 pairs in 14.3339290619\n",
      "Processed  35000 pairs in 16.6808030605\n",
      "Processed  40000 pairs in 19.1045310497\n",
      "Processed  45000 pairs in 21.4900121689\n",
      "Processed  50000 pairs in 23.9992721081\n",
      "Processed  55000 pairs in 26.1905741692\n",
      "Processed  60000 pairs in 28.6672542095\n",
      "Processed  65000 pairs in 30.9192080498\n",
      "Processed  70000 pairs in 33.0760200024\n",
      "Processed  75000 pairs in 35.9251790047\n",
      "Processed  80000 pairs in 38.2395861149\n",
      "Finished in 40.2915670872\n",
      "50433 pairs met minimum length.\n",
      "34373 were rejected.\n",
      "fitting model\n",
      "model fitting took 4071.55094099 seconds\n",
      "Processed  5000 pairs in 10.2350108624\n",
      "Processed  10000 pairs in 20.4583849907\n",
      "Processed  15000 pairs in 30.4685919285\n",
      "Processed  20000 pairs in 40.6344988346\n",
      "Processed  25000 pairs in 50.9005019665\n",
      "Processed  30000 pairs in 61.0124208927\n",
      "Processed  35000 pairs in 71.0971338749\n",
      "Processed  40000 pairs in 81.4169318676\n",
      "Processed  45000 pairs in 91.7624688148\n",
      "Processed  50000 pairs in 102.114946842\n",
      "Processed  55000 pairs in 111.956408978\n",
      "Processed  60000 pairs in 122.435802937\n",
      "Processed  65000 pairs in 132.335182905\n",
      "Processed  70000 pairs in 142.085832834\n",
      "Processed  75000 pairs in 153.007804871\n",
      "Processed  80000 pairs in 162.932458878\n",
      "Finished in 172.333196878\n",
      "37304 pairs met minimum length.\n",
      "47502 were rejected.\n",
      "fitting model\n",
      "model fitting took 3063.25689816 seconds\n",
      "Processed  5000 pairs in 7.65300893784\n",
      "Processed  10000 pairs in 15.3066818714\n",
      "Processed  15000 pairs in 22.992980957\n",
      "Processed  20000 pairs in 30.4733929634\n",
      "Processed  25000 pairs in 38.4071669579\n",
      "Processed  30000 pairs in 46.2015838623\n",
      "Processed  35000 pairs in 53.8807280064\n",
      "Processed  40000 pairs in 61.7860798836\n",
      "Processed  45000 pairs in 69.6443948746\n",
      "Processed  50000 pairs in 77.6100330353\n",
      "Processed  55000 pairs in 85.2131419182\n",
      "Processed  60000 pairs in 93.3184409142\n",
      "Processed  65000 pairs in 100.807844877\n",
      "Processed  70000 pairs in 108.048925877\n",
      "Processed  75000 pairs in 116.529716969\n",
      "Processed  80000 pairs in 124.11239481\n",
      "Finished in 131.204653978\n",
      "13245 pairs met minimum length.\n",
      "71561 were rejected.\n",
      "fitting model\n",
      "model fitting took 1204.94921303 seconds\n",
      "Processed  5000 pairs in 2.96173286438\n",
      "Processed  10000 pairs in 6.03237199783\n",
      "Processed  15000 pairs in 9.17754602432\n",
      "Processed  20000 pairs in 11.9317550659\n",
      "Processed  25000 pairs in 14.9602229595\n",
      "Processed  30000 pairs in 17.8045899868\n",
      "Processed  35000 pairs in 20.7087578773\n",
      "Processed  40000 pairs in 23.6824200153\n",
      "Processed  45000 pairs in 26.6168458462\n",
      "Processed  50000 pairs in 29.719301939\n",
      "Processed  55000 pairs in 32.399518013\n",
      "Processed  60000 pairs in 35.451969862\n",
      "Processed  65000 pairs in 38.3270380497\n",
      "Processed  70000 pairs in 40.9507069588\n",
      "Processed  75000 pairs in 44.4812150002\n",
      "Processed  80000 pairs in 47.340597868\n",
      "Finished in 49.9357199669\n"
     ]
    }
   ],
   "source": [
    "# Can just load already preprocessed qa pairs as applying standard preprocessing\n",
    "qa_dir = LIBRARY_PATH+model_spec[\"qa_pair_directory\"]\n",
    "with open(qa_dir+\"/qa_pairs.txt\", \"r\") as f:\n",
    "    qa_pairs = json.loads(f.read())\n",
    "\n",
    "for model_spec in model_spec_list:\n",
    "    \n",
    "    save_model_spec(model_spec)\n",
    "\n",
    "    texts = select_texts(qa_pairs, model_spec)\n",
    "\n",
    "    learn_LDA_model(model_spec, texts, passes = model_spec[\"passes\"], iterations = model_spec[\"iterations\"])\n",
    "\n",
    "    calc_hellinger_sims(model_spec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse log file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_logfile(loglines):\n",
    "    '''Parses a gensim logfile to return a list of key information from each pass.\n",
    "       List contains\n",
    "       pass number\n",
    "       per word bound\n",
    "       perplexity\n",
    "       held out size\n",
    "       number converged\n",
    "       number out of which converged\n",
    "       '''\n",
    "\n",
    "    match_doc = re.compile(\"(-*\\d+) documents\")\n",
    "    match_perp = re.compile(\"(-*\\d+\\.\\d+) per-word .* (\\d+\\.\\d+) perplexity .* (\\d+) documents\")\n",
    "    match_pass = re.compile(\"pass (\\d+).*document #(\\d+)\")\n",
    "    match_converged = re.compile(\"(\\d+)\\/(\\d+) documents converged\")\n",
    "\n",
    "    perp_list = []\n",
    "\n",
    "    for i in range(len(loglines)):\n",
    "        if \"running online\" in loglines[i]:\n",
    "            # summary of data for the the model run\n",
    "            total_docs = match_doc.findall(loglines[i])[0]\n",
    "        if \"perplexity estimate\" in loglines[i]:\n",
    "            if \"PROGRESS\" in loglines[i+1]:\n",
    "                progress_data = match_pass.findall(loglines[i+1])\n",
    "                doc_num = progress_data[0][1]\n",
    "                # only add data for the end of each complete pass\n",
    "                if doc_num == total_docs:\n",
    "                    pass_num = progress_data[0][0]\n",
    "                    perp_data = match_perp.findall(loglines[i])\n",
    "                    word_bound = perp_data[0][0]\n",
    "                    perplexity = perp_data[0][1]\n",
    "                    held_out = perp_data[0][2]\n",
    "                    converged_data = match_converged.findall(loglines[i+3])\n",
    "                    converged = converged_data[0][0]\n",
    "                    out_of = converged_data[0][1]\n",
    "                    perp_list.append((pass_num, word_bound, perplexity, held_out, converged, out_of))\n",
    "                    \n",
    "    return perp_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('0', '-7.110', '138.2', '866', '848', '866'),\n",
       " ('1', '-7.087', '135.9', '866', '855', '866'),\n",
       " ('2', '-7.081', '135.4', '866', '854', '866'),\n",
       " ('3', '-7.079', '135.2', '866', '853', '866'),\n",
       " ('4', '-7.077', '135.1', '866', '854', '866'),\n",
       " ('5', '-7.076', '135.0', '866', '851', '866'),\n",
       " ('6', '-7.075', '134.8', '866', '855', '866'),\n",
       " ('7', '-7.074', '134.7', '866', '854', '866'),\n",
       " ('8', '-7.073', '134.7', '866', '859', '866'),\n",
       " ('9', '-7.073', '134.6', '866', '855', '866'),\n",
       " ('10', '-7.072', '134.5', '866', '855', '866'),\n",
       " ('11', '-7.072', '134.5', '866', '854', '866'),\n",
       " ('12', '-7.071', '134.4', '866', '856', '866'),\n",
       " ('13', '-7.070', '134.4', '866', '859', '866'),\n",
       " ('14', '-7.070', '134.4', '866', '859', '866'),\n",
       " ('15', '-7.069', '134.3', '866', '852', '866'),\n",
       " ('16', '-7.069', '134.3', '866', '856', '866'),\n",
       " ('17', '-7.068', '134.2', '866', '856', '866'),\n",
       " ('18', '-7.068', '134.1', '866', '858', '866'),\n",
       " ('19', '-7.067', '134.1', '866', '856', '866')]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dir = LIBRARY_PATH+\"saved_models/top20_len10_prebase_ps20_it100\"\n",
    "logfile = model_dir + \"/lda_logfile.log\"\n",
    "with open(logfile) as f:\n",
    "    loglines = f.readlines()\n",
    "\n",
    "parse_logfile(loglines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved_models/top10_len10_prebase_ps20_it100\n",
      "('19', '-7.002', '128.1', '866', '862', '866')\n",
      "saved_models/top10_len20_prebase_ps20_it100\n",
      "('19', '-6.986', '126.7', '608', '601', '608')\n",
      "saved_models/top10_len40_prebase_ps20_it100\n",
      "('19', '-6.907', '120.0', '490', '481', '490')\n",
      "saved_models/top20_len10_prebase_ps20_it100\n",
      "('19', '-7.067', '134.1', '866', '856', '866')\n",
      "saved_models/top20_len20_prebase_ps20_it100\n",
      "('19', '-7.021', '129.9', '608', '604', '608')\n",
      "saved_models/top20_len40_prebase_ps20_it100\n",
      "('19', '-6.912', '120.4', '490', '487', '490')\n",
      "saved_models/top40_len10_prebase_ps20_it100\n",
      "('19', '-7.166', '143.6', '866', '862', '866')\n",
      "saved_models/top40_len20_prebase_ps20_it100\n",
      "('19', '-7.123', '139.4', '608', '606', '608')\n",
      "saved_models/top40_len40_prebase_ps20_it100\n",
      "('19', '-6.967', '125.1', '490', '488', '490')\n"
     ]
    }
   ],
   "source": [
    "final_perp = dict()\n",
    "\n",
    "for model_spec in model_spec_list:\n",
    "    model_dir = model_spec[\"model_directory\"]\n",
    "    logfile = LIBRARY_PATH+model_dir+\"/lda_logfile.log\"\n",
    "    with open(logfile) as f:\n",
    "        loglines = f.readlines()\n",
    "    final_perp[model_dir] = parse_logfile(loglines)\n",
    "    print model_dir\n",
    "    print final_perp[model_dir][-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Changing the preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_highdf_words(qa_pairs, threshold):\n",
    "    '''Evaluate a list of qa_pairs, calculates a list of words\n",
    "       with a document frequency higher than the threshold and\n",
    "       returns the qa_pairs list with those words removed.'''\n",
    "    \n",
    "    docf = defaultdict(int)\n",
    "    total_docs = 0\n",
    "    for file_id in qa_pairs:\n",
    "        for q_num in qa_pairs[file_id]:\n",
    "            q_words = set(qa_pairs[file_id][q_num][0])\n",
    "            a_words = set(qa_pairs[file_id][q_num][1])\n",
    "            for word in q_words:\n",
    "                docf[word] += 1\n",
    "            for word in a_words:\n",
    "                docf[word] += 1\n",
    "            total_docs += 2\n",
    "\n",
    "    df_stopwords = [w for w in docf if docf[w]*1.0/total_docs > threshold]\n",
    "    \n",
    "    for file_id in qa_pairs:\n",
    "        for q_num in qa_pairs[file_id]:\n",
    "            q_words = qa_pairs[file_id][q_num][0]\n",
    "            a_words = qa_pairs[file_id][q_num][1]\n",
    "            q_words = [w for w in q_words if w not in df_stopwords]\n",
    "            a_words = [w for w in a_words if w not in df_stopwords]\n",
    "            qa_pairs[file_id][q_num] = (q_words, a_words)\n",
    "\n",
    "    return qa_pairs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model_spec = {'description': 'Topics 20, Min Length 20, base preprocessing, passes20, iterations100, df=0.1',\n",
    "#   'iterations': 100,\n",
    "#   'min_sequence_length': 20,\n",
    "#   'model_directory': 'saved_models/top20_len20_prebase_ps20_it100_df10',\n",
    "#   'num_topics': 20,\n",
    "#   'passes': 20,\n",
    "#   'preprocessing_function': 'testLDA_pre_process_document',\n",
    "#   'qa_pair_directory': 'saved_models/df_10'},"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not actually changing the previous pre-processing so can just load the qa pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "qa_dir = LIBRARY_PATH+\"saved_models/standard_preproc\"\n",
    "with open(qa_dir+\"/qa_pairs.txt\", \"r\") as f:\n",
    "    qa_pairs = json.loads(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for threshold in [0.05, 0.1, 0.2]:\n",
    "    \n",
    "    qa_dir = LIBRARY_PATH+\"saved_models/standard_preproc\"\n",
    "    with open(qa_dir+\"/qa_pairs.txt\", \"r\") as f:\n",
    "        qa_pairs = json.loads(f.read())\n",
    "\n",
    "    stopped_qa_pairs = remove_highdf_words(qa_pairs, threshold)\n",
    "    \n",
    "    qa_path = LIBRARY_PATH+\"saved_models/base_plus_df\"+str(int(threshold*100))+\"/qa_pairs.txt\"\n",
    "    with open(qa_path, \"w\") as f:\n",
    "        f.write(json.dumps(stopped_qa_pairs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check the removal of high df terms has worked as expected "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "169612\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(u'number', 0.09735160248095653),\n",
       " (u'product', 0.0961075867273542),\n",
       " (u'make', 0.09574204655330991),\n",
       " (u'give', 0.0934014102775747),\n",
       " (u'mayb', 0.09336603542202203),\n",
       " (u'said', 0.09211022804990213),\n",
       " (u'price', 0.0920630615758319),\n",
       " (u'way', 0.08928613541494705),\n",
       " (u'still', 0.08827795203169587),\n",
       " (u'got', 0.08794189090394547),\n",
       " (u'obvious', 0.08691012428365917),\n",
       " (u'rate', 0.08558946300969271),\n",
       " (u'chang', 0.08360257528948424),\n",
       " (u'two', 0.08155672947668798),\n",
       " (u'mean', 0.07972313279720775),\n",
       " (u'actual', 0.07664552036412518),\n",
       " (u'start', 0.07624460533452822),\n",
       " (u'work', 0.07567271183642667),\n",
       " (u'impact', 0.07550173336792208),\n",
       " (u'new', 0.07527769261608848),\n",
       " (u'cost', 0.07495931891611443),\n",
       " (u'around', 0.07491804825130298),\n",
       " (u'next', 0.07426361342357853),\n",
       " (u'second', 0.07329670070513879),\n",
       " (u'great', 0.07115062613494329),\n",
       " (u'guess', 0.0692757587906516),\n",
       " (u'pretti', 0.06898096832771267),\n",
       " (u'forward', 0.06878640662217296),\n",
       " (u'part', 0.06866849043699738),\n",
       " (u'sure', 0.06789613942409735),\n",
       " (u'coupl', 0.0674657453482065),\n",
       " (u'margin', 0.06735962078154847),\n",
       " (u'mention', 0.0671296842204561),\n",
       " (u'end', 0.06586208522981865),\n",
       " (u'ye', 0.0647006108058392),\n",
       " (u'opportun', 0.06441171615215904),\n",
       " (u'guy', 0.06421715444661934),\n",
       " (u'help', 0.06401669693182087),\n",
       " (u'increas', 0.06373959389665826),\n",
       " (u'follow', 0.06363346933000023),\n",
       " (u'move', 0.06352144895408343),\n",
       " (u'hi', 0.06261349432823149),\n",
       " (u'differ', 0.06199443435605971),\n",
       " (u'tri', 0.06097445935429097),\n",
       " (u'posit', 0.0602964412895314),\n",
       " (u'comment', 0.06014315024880315),\n",
       " (u'level', 0.0600724005376978),\n",
       " (u'invest', 0.05950050703959626),\n",
       " (u'better', 0.05797349244157253),\n",
       " (u'probabl', 0.057908638539725964),\n",
       " (u'base', 0.05775534749899771),\n",
       " (u'custom', 0.056806122208334316),\n",
       " (u'given', 0.05674126830648775),\n",
       " (u'improv', 0.05645826946206636),\n",
       " (u'million', 0.05542060703252128),\n",
       " (u'side', 0.0548310261066434),\n",
       " (u'sort', 0.05478975544183195),\n",
       " (u'line', 0.0546069853548098),\n",
       " (u'put', 0.05431809070112964),\n",
       " (u'someth', 0.05414711223262505),\n",
       " (u'even', 0.05398202957337924),\n",
       " (u'basi', 0.053640072636370065),\n",
       " (u'seen', 0.05339244864750135),\n",
       " (u'gener', 0.0533806570289838),\n",
       " (u'plan', 0.053150720467891426),\n",
       " (u'big', 0.0530740749475273),\n",
       " (u'share', 0.052991533617904395),\n",
       " (u'sale', 0.052372473645732616),\n",
       " (u'oper', 0.052095370610570006),\n",
       " (u'need', 0.05207768318279367),\n",
       " (u'compani', 0.05203641251798222),\n",
       " (u'call', 0.05063320991439285),\n",
       " (u'revenu', 0.050132066127396645),\n",
       " (u'let', 0.04957786005707143),\n",
       " (u'capit', 0.048793717425653846),\n",
       " (u'overal', 0.04828667782939886),\n",
       " (u'grow', 0.04806853288682405),\n",
       " (u'long', 0.04803905384053015),\n",
       " (u'certainli', 0.04685989198877438),\n",
       " (u'strong', 0.046653538664717116),\n",
       " (u'u', 0.04608754097587435),\n",
       " (u'specif', 0.0458222295592293),\n",
       " (u'higher', 0.04576916727590029),\n",
       " (u'versu', 0.045686625946277384),\n",
       " (u'feel', 0.04539773129259722),\n",
       " (u'half', 0.04527981510742164),\n",
       " (u'billion', 0.04516189892224607),\n",
       " (u'might', 0.044790462938942996),\n",
       " (u'happen', 0.04283305426502842),\n",
       " (u'guidanc', 0.04278588779095819),\n",
       " (u'peopl', 0.04273282550762918),\n",
       " (u'today', 0.042662075796523834),\n",
       " (u'done', 0.042573638657642146),\n",
       " (u'ask', 0.04256184703912459),\n",
       " (u'abl', 0.04198995354102304),\n",
       " (u'use', 0.041665684031790204),\n",
       " (u'drive', 0.04145343489847417),\n",
       " (u'hey', 0.04084616654481994),\n",
       " (u'wonder', 0.04081668749852605),\n",
       " (u'rel', 0.04080489588000849),\n",
       " (u'lower', 0.04080489588000849),\n",
       " (u'issu', 0.04078720845223215),\n",
       " (u'benefit', 0.040020753248590904),\n",
       " (u'relat', 0.039891045444897764),\n",
       " (u'high', 0.03984977478008631),\n",
       " (u'believ', 0.03984977478008631),\n",
       " (u'perform', 0.03980850411527486),\n",
       " (u'day', 0.03964931726528784),\n",
       " (u'run', 0.03925429804494965),\n",
       " (u'month', 0.03892413272645803),\n",
       " (u'volum', 0.03883569558757635),\n",
       " (u'area', 0.0387944249227649),\n",
       " (u'may', 0.038711883593141996),\n",
       " (u'thought', 0.038198948187628236),\n",
       " (u'manag', 0.03811640685800533),\n",
       " (u'saw', 0.037892366106171735),\n",
       " (u'three', 0.037674221163596915),\n",
       " (u'fact', 0.03760936726175035),\n",
       " (u'result', 0.037538617550645),\n",
       " (u'activ', 0.03743249298398698),\n",
       " (u'fourth', 0.03706105700068391),\n",
       " (u'sens', 0.0368134330118152),\n",
       " (u'whether', 0.036736787491451074),\n",
       " (u'across', 0.036689621017380845),\n",
       " (u'servic', 0.03660707968775794),\n",
       " (u'anyth', 0.036571704832205267),\n",
       " (u'balanc', 0.03637714312666557),\n",
       " (u'understand', 0.03612362332853807),\n",
       " (u'cash', 0.035722708298941114),\n",
       " (u'potenti', 0.03510954413602811),\n",
       " (u'signific', 0.03507416928047544),\n",
       " (u'process', 0.0350564818526991),\n",
       " (u'asset', 0.03495035728604108),\n",
       " (u'valu', 0.034797066245312834),\n",
       " (u'made', 0.03474400396198382),\n",
       " (u'provid', 0.034726316534207484),\n",
       " (u'third', 0.034667358441619694),\n",
       " (u'mix', 0.03433719312312808),\n",
       " (u'interest', 0.034119048180553266),\n",
       " (u'quit', 0.034007027804636464),\n",
       " (u'portfolio', 0.03398344456760135),\n",
       " (u'add', 0.03395396552130745),\n",
       " (u'place', 0.033582529538004384),\n",
       " (u'trend', 0.03351177982689904),\n",
       " (u'view', 0.03342334268801736),\n",
       " (u'import', 0.033317218121359335),\n",
       " (u'spend', 0.03330542650284178),\n",
       " (u'seem', 0.03316392708063109),\n",
       " (u'reason', 0.032975261184350166),\n",
       " (u'past', 0.03246822158809518),\n",
       " (u'program', 0.03243284673254251),\n",
       " (u'environ', 0.03236799283069594),\n",
       " (u'industri', 0.032255972454779146),\n",
       " (u'less', 0.0319906610381341),\n",
       " (u'clearli', 0.03184326580666462),\n",
       " (u'addit', 0.03182557837888829),\n",
       " (u'tell', 0.03156616277150202),\n",
       " (u'earlier', 0.031513100488173004),\n",
       " (u'cours', 0.03144235077706766),\n",
       " (u'build', 0.03138339268447987),\n",
       " (u'project', 0.031100393840058485),\n",
       " (u'consum', 0.030481333867886706),\n",
       " (u'rang', 0.03046364644011037),\n",
       " (u'alway', 0.030369313491969908),\n",
       " (u'within', 0.030292667971605784),\n",
       " (u'mani', 0.030210126641982877),\n",
       " (u'earli', 0.030180647595688986),\n",
       " (u'larg', 0.03008631464754852),\n",
       " (u'competit', 0.030021460745701955),\n",
       " (u'far', 0.02999198169940806),\n",
       " (u'expens', 0.029673607999434002),\n",
       " (u'perspect', 0.02948494210315308),\n",
       " (u'answer', 0.029101714501332452),\n",
       " (u'focus', 0.029089922882814895),\n",
       " (u'deal', 0.02900738155319199),\n",
       " (u'flow', 0.028877673749498855),\n",
       " (u'low', 0.028712591090253047),\n",
       " (u'quick', 0.028630049760630143),\n",
       " (u'current', 0.028512133575454568),\n",
       " (u'intern', 0.028370634153243875),\n",
       " (u'develop', 0.028176072447704172),\n",
       " (u'focu', 0.028022781406975922),\n",
       " (u'ago', 0.02787538617550645),\n",
       " (u'particularli', 0.027692616088484306),\n",
       " (u'color', 0.02768082446996675),\n",
       " (u'hope', 0.027321180105181236),\n",
       " (u'close', 0.027279909440369784),\n",
       " (u'return', 0.02679055727189114),\n",
       " (u'profit', 0.02674339079782091),\n",
       " (u'keep', 0.026566516520057544),\n",
       " (u'target', 0.02653114166450487),\n",
       " (u'anoth', 0.02648397519043464),\n",
       " (u'play', 0.026407329670070513),\n",
       " (u'includ', 0.02626583024785982),\n",
       " (u'alreadi', 0.02606537273306134),\n",
       " (u'earn', 0.026053581114543783),\n",
       " (u'real', 0.025788269697898734),\n",
       " (u'strategi', 0.02544041695163078),\n",
       " (u'futur', 0.02544041695163078),\n",
       " (u'assum', 0.025410937905336887),\n",
       " (u'order', 0.02533429238497276),\n",
       " (u'period', 0.025310709147937645),\n",
       " (u'total', 0.02482725278871778),\n",
       " (u'amount', 0.024603212036884183),\n",
       " (u'full', 0.02452656651652006),\n",
       " (u'demand', 0.024449920996155932),\n",
       " (u'effect', 0.024367379666533028),\n",
       " (u'confid', 0.023878027498054382),\n",
       " (u'europ', 0.02384265264250171),\n",
       " (u'case', 0.023718840648067355),\n",
       " (u'world', 0.023701153220291017),\n",
       " (u'discuss', 0.023648090936962008),\n",
       " (u'top', 0.02358913284437422),\n",
       " (u'risk', 0.02357144541659788),\n",
       " (u'progress', 0.023565549607339104),\n",
       " (u'declin', 0.023317925618470393),\n",
       " (u'digit', 0.023300238190694055),\n",
       " (u'type', 0.02327665495365894),\n",
       " (u'factor', 0.023034926774049006),\n",
       " (u'net', 0.02299955191849633),\n",
       " (u'everi', 0.022993656109237554),\n",
       " (u'best', 0.022875739924061975),\n",
       " (u'model', 0.022828573449991747),\n",
       " (u'outlook', 0.02281088602221541),\n",
       " (u'segment', 0.022539678796311583),\n",
       " (u'team', 0.022292054807442868),\n",
       " (u'basic', 0.02207980567412683),\n",
       " (u'normal', 0.021855764922293235),\n",
       " (u'longer', 0.021838077494516897),\n",
       " (u'unit', 0.021802702638964225),\n",
       " (u'data', 0.021702473881564984),\n",
       " (u'pressur', 0.021690682263047427),\n",
       " (u'exampl', 0.02157866188713063),\n",
       " (u'updat', 0.02156687026861307),\n",
       " (u'particular', 0.021454849892696273),\n",
       " (u'bring', 0.021448954083437492),\n",
       " (u'yet', 0.021395891800108483),\n",
       " (u'contract', 0.02120133009456878),\n",
       " (u'tax', 0.021059830672358087),\n",
       " (u'north', 0.020983185151993964),\n",
       " (u'sell', 0.020818102492748156),\n",
       " (u'abil', 0.02079451925571304),\n",
       " (u'set', 0.020658915642761125),\n",
       " (u'least', 0.020582270122397),\n",
       " (u'sever', 0.02048204136499776),\n",
       " (u'america', 0.020399500035374857),\n",
       " (u'john', 0.020340541942787067),\n",
       " (u'regard', 0.020258000613164164),\n",
       " (u'show', 0.020157771855764922),\n",
       " (u'categori', 0.020157771855764922),\n",
       " (u'fair', 0.020098813763177133),\n",
       " (u'initi', 0.020069334716883238),\n",
       " (u'capac', 0.020039855670589347),\n",
       " (u'clear', 0.02000448081503667),\n",
       " (u'major', 0.019986793387260334),\n",
       " (u'brand', 0.019969105959484),\n",
       " (u'hard', 0.01991014786689621),\n",
       " (u'increment', 0.019880668820602316),\n",
       " (u'book', 0.019845293965049644),\n",
       " (u'acquisit', 0.019774544253944298),\n",
       " (u'gain', 0.019768648444685517),\n",
       " (u'state', 0.019467962172487797),\n",
       " (u'structur', 0.01945027474471146),\n",
       " (u'effici', 0.01944437893545268),\n",
       " (u'technolog', 0.019426691507676345),\n",
       " (u'system', 0.019414899889158788),\n",
       " (u'credit', 0.019314671131759546),\n",
       " (u'front', 0.01907294295214961),\n",
       " (u'though', 0.019067047142890835),\n",
       " (u'toward', 0.019049359715114497),\n",
       " (u'retail', 0.018960922576232813),\n",
       " (u'inventori', 0.018890172865127466),\n",
       " (u'shift', 0.018890172865127466),\n",
       " (u'hear', 0.018872485437351132),\n",
       " (u'pleas', 0.01886069381883357),\n",
       " (u'piec', 0.018837110581798457),\n",
       " (u'ahead', 0.0188253189632809),\n",
       " (u'adjust', 0.018807631535504563),\n",
       " (u'remain', 0.0187132985873641),\n",
       " (u'complet', 0.01867792373181143),\n",
       " (u'recent', 0.018595382402188526),\n",
       " (u'season', 0.01857769497441219),\n",
       " (u'curiou', 0.018483362026271728),\n",
       " (u'core', 0.01841261231516638),\n",
       " (u'launch', 0.0184067165059076),\n",
       " (u'final', 0.018389029078131263),\n",
       " (u'ga', 0.018383133268872486),\n",
       " (u'begin', 0.01837134165035493),\n",
       " (u'indic', 0.01835365422257859),\n",
       " (u'either', 0.018324175176284697),\n",
       " (u'week', 0.01820036318185034),\n",
       " (u'driver', 0.018170884135556446),\n",
       " (u'ad', 0.01814140508926255),\n",
       " (u'challeng', 0.01801169728556942),\n",
       " (u'acceler', 0.01799990566705186),\n",
       " (u'detail', 0.01799400985779308),\n",
       " (u'respect', 0.017846614626323608),\n",
       " (u'whole', 0.01777586491521826),\n",
       " (u'decis', 0.01777586491521826),\n",
       " (u'consist', 0.01777586491521826),\n",
       " (u'driven', 0.01774638586892437),\n",
       " (u'leverag', 0.017722802631889252),\n",
       " (u'compar', 0.01758719901893734),\n",
       " (u'combin', 0.017522345117090773),\n",
       " (u'step', 0.01741622055043275),\n",
       " (u'commerci', 0.017369054076362522),\n",
       " (u'flat', 0.017315991793033513),\n",
       " (u'network', 0.01726882531896328),\n",
       " (u'bank', 0.017251137891186943),\n",
       " (u'success', 0.017245242081928167),\n",
       " (u'standpoint', 0.017239346272669386),\n",
       " (u'four', 0.01722755465415183),\n",
       " (u'item', 0.01712143008749381),\n",
       " (u'singl', 0.017044784567129684),\n",
       " (u'dollar', 0.017003513902318232),\n",
       " (u'sorri', 0.016974034856024337),\n",
       " (u'small', 0.016920972572695328),\n",
       " (u'correct', 0.016920972572695328),\n",
       " (u'gross', 0.01690918095417777),\n",
       " (u'econom', 0.016891493526401433),\n",
       " (u'comp', 0.016873806098625096),\n",
       " (u'exactli', 0.016856118670848762),\n",
       " (u'buy', 0.016826639624554867),\n",
       " (u'incom', 0.016761785722708297),\n",
       " (u'per', 0.01674999410419074),\n",
       " (u'china', 0.016726410867155626),\n",
       " (u'direct', 0.01666155696530906),\n",
       " (u'marketplac', 0.01666155696530906),\n",
       " (u'organ', 0.016626182109756384),\n",
       " (u'sinc', 0.016614390491238827),\n",
       " (u'beyond', 0.016573119826427375),\n",
       " (u'depend', 0.016525953352357143),\n",
       " (u'key', 0.01649057849680447),\n",
       " (u'hold', 0.01648468268754569),\n",
       " (u'offset', 0.01644930783199302),\n",
       " (u'rememb', 0.01644341202273424),\n",
       " (u'announc', 0.016431620404216682),\n",
       " (u'execut', 0.01639624554866401),\n",
       " (u'stay', 0.016384453930146453),\n",
       " (u'five', 0.016366766502370116),\n",
       " (u'anticip', 0.016360870693111335),\n",
       " (u'transact', 0.01635497488385256),\n",
       " (u'averag', 0.01635497488385256),\n",
       " (u'creat', 0.016343183265335),\n",
       " (u'store', 0.01633728745607622),\n",
       " (u'materi', 0.016195788033865528),\n",
       " (u'deliv', 0.01618399641534797),\n",
       " (u'nice', 0.016113246704242624),\n",
       " (u'els', 0.016113246704242624),\n",
       " (u'offer', 0.016107350894983847),\n",
       " (u'size', 0.016095559276466286),\n",
       " (u'mid', 0.01597764309129071),\n",
       " (u'pay', 0.015959955663514373),\n",
       " (u'cycl', 0.015871518524632693),\n",
       " (u'space', 0.015865622715373912),\n",
       " (u'suppli', 0.01583024785982124),\n",
       " (u'neg', 0.01577128976723345),\n",
       " (u'goe', 0.01576539395797467),\n",
       " (u'hit', 0.015753602339457114),\n",
       " (u'global', 0.015735914911680776),\n",
       " (u'togeth', 0.01572412329316322),\n",
       " (u'non', 0.015712331674645662),\n",
       " (u'ratio', 0.01567695681909299),\n",
       " (u'rest', 0.015641581963540315),\n",
       " (u'becom', 0.01562389453576398),\n",
       " (u'account', 0.01561210291724642),\n",
       " (u'countri', 0.015594415489470085),\n",
       " (u'approach', 0.015553144824658633),\n",
       " (u'report', 0.015535457396882297),\n",
       " (u'fairli', 0.015500082541329624),\n",
       " (u'speak', 0.015494186732070843),\n",
       " (u'david', 0.015470603495035729),\n",
       " (u'perhap', 0.01546470768577695),\n",
       " (u'open', 0.01546470768577695),\n",
       " (u'turn', 0.015399853783930382),\n",
       " (u'loan', 0.0153114166450487),\n",
       " (u'reduct', 0.015181708841355564),\n",
       " (u'plu', 0.015087375893215103),\n",
       " (u'competitor', 0.015040209419144872),\n",
       " (u'job', 0.014904605806192957),\n",
       " (u'pick', 0.014863335141381506),\n",
       " (u'sheet', 0.014857439332122727),\n",
       " (u'allow', 0.014839751904346391),\n",
       " (u'support', 0.014833856095087613),\n",
       " (u'investor', 0.014780793811758602),\n",
       " (u'possibl', 0.014733627337688371),\n",
       " (u'reduc', 0.014710044100653255),\n",
       " (u'oil', 0.014698252482135698),\n",
       " (u'similar', 0.014680565054359362),\n",
       " (u'natur', 0.014674669245100582),\n",
       " (u'sound', 0.01463929438954791),\n",
       " (u'client', 0.014609815343254015),\n",
       " (u'everyth', 0.014603919533995237),\n",
       " (u'absolut', 0.01458033629696012),\n",
       " (u'short', 0.014450628493266986),\n",
       " (u'came', 0.014450628493266986),\n",
       " (u'money', 0.014415253637714313),\n",
       " (u'strateg', 0.014350399735867745),\n",
       " (u'percentag', 0.014090984128481475),\n",
       " (u'everyon', 0.014079192509963917),\n",
       " (u'histor', 0.01400844279885857),\n",
       " (u'financi', 0.013978963752564678),\n",
       " (u'equiti', 0.013967172134047119),\n",
       " (u'prepar', 0.01396127632478834),\n",
       " (u'certain', 0.01396127632478834),\n",
       " (u'enough', 0.013943588897012004),\n",
       " (u'care', 0.013931797278494445),\n",
       " (u'platform', 0.01391410985071811),\n",
       " (u'quickli', 0.01391410985071811),\n",
       " (u'capex', 0.013878734995165436),\n",
       " (u'steve', 0.013849255948871542),\n",
       " (u'frankli', 0.013837464330353984),\n",
       " (u'everybodi', 0.013819776902577649),\n",
       " (u'slightli', 0.013778506237766195),\n",
       " (u'ramp', 0.013713652335919629),\n",
       " (u'power', 0.013642902624814282),\n",
       " (u'expand', 0.013619319387779166),\n",
       " (u'pipelin', 0.013607527769261609),\n",
       " (u'strength', 0.013589840341485273),\n",
       " (u'along', 0.013548569676673821),\n",
       " (u'went', 0.013548569676673821),\n",
       " (u'head', 0.01349550739334481),\n",
       " (u'dynam', 0.013460132537792137),\n",
       " (u'trade', 0.013460132537792137),\n",
       " (u'bill', 0.013436549300757022),\n",
       " (u'find', 0.01338938282668679),\n",
       " (u'util', 0.013336320543357781),\n",
       " (u'bigger', 0.013277362450769993),\n",
       " (u'loss', 0.013224300167440983),\n",
       " (u'debt', 0.013224300167440983),\n",
       " (u'exist', 0.013171237884111973),\n",
       " (u'capabl', 0.013147654647076857),\n",
       " (u'away', 0.0131358630285593),\n",
       " (u'fund', 0.013124071410041743),\n",
       " (u'contribut', 0.013106383982265405),\n",
       " (u'afternoon', 0.013100488173006627),\n",
       " (u'noth', 0.013023842652642502),\n",
       " (u'roughli', 0.013017946843383723),\n",
       " (u'requir', 0.01298257198783105),\n",
       " (u'doubl', 0.012970780369313492),\n",
       " (u'meet', 0.012935405513760819),\n",
       " (u'advantag', 0.012935405513760819),\n",
       " (u'reflect', 0.01292950970450204),\n",
       " (u'consid', 0.012923613895243262),\n",
       " (u'track', 0.012923613895243262),\n",
       " (u'other', 0.012900030658208146),\n",
       " (u'date', 0.012858759993396694),\n",
       " (u'commit', 0.012858759993396694),\n",
       " (u'experi', 0.012852864184137915),\n",
       " (u'mind', 0.012852864184137915),\n",
       " (u'comfort', 0.012846968374879137),\n",
       " (u'sustain', 0.012835176756361578),\n",
       " (u'lead', 0.012788010282291347),\n",
       " (u'concern', 0.012782114473032569),\n",
       " (u'situat', 0.012758531235997453),\n",
       " (u'sequenti', 0.012717260571186),\n",
       " (u'gave', 0.012687781524892106),\n",
       " (u'roll', 0.01267009409711577),\n",
       " (u'stuff', 0.012593448576751645),\n",
       " (u'especi', 0.012593448576751645),\n",
       " (u'forecast', 0.012546282102681414),\n",
       " (u'count', 0.01251680305638752),\n",
       " (u'appreci', 0.01251680305638752),\n",
       " (u'convers', 0.012510907247128741),\n",
       " (u'six', 0.012505011437869962),\n",
       " (u'remark', 0.012428365917505837),\n",
       " (u'region', 0.012398886871211942),\n",
       " (u'board', 0.01236351201565927),\n",
       " (u'mark', 0.01236351201565927),\n",
       " (u'save', 0.012292762304553922),\n",
       " (u'almost', 0.012145367073084452),\n",
       " (u'dividend', 0.012145367073084452),\n",
       " (u'headwind', 0.012068721552720327),\n",
       " (u'address', 0.01199797184161498),\n",
       " (u'expans', 0.011992076032356202),\n",
       " (u'outsid', 0.011968492795321086),\n",
       " (u'slow', 0.01189184727495696),\n",
       " (u'effort', 0.011885951465698182),\n",
       " (u'action', 0.011868264037921844),\n",
       " (u'q4', 0.011856472419404287),\n",
       " (u'due', 0.011850576610145509),\n",
       " (u'heard', 0.01184468080088673),\n",
       " (u'push', 0.011838784991627951),\n",
       " (u'prior', 0.0117975143268165),\n",
       " (u'excit', 0.011779826899040162),\n",
       " (u'integr', 0.011750347852746267),\n",
       " (u'group', 0.011714972997193596),\n",
       " (u'mike', 0.011697285569417258),\n",
       " (u'extent', 0.01169138976015848),\n",
       " (u'economi', 0.01158526519350046),\n",
       " (u'qualiti', 0.011543994528689008),\n",
       " (u'typic', 0.01153220291017145),\n",
       " (u'channel', 0.011508619673136334),\n",
       " (u'estim', 0.011490932245359999),\n",
       " (u'behind', 0.01148503643610122),\n",
       " (u'taken', 0.011461453199066104),\n",
       " (u'sharehold', 0.011431974152772209),\n",
       " (u'significantli', 0.011373016060184421),\n",
       " (u'associ', 0.011373016060184421),\n",
       " (u'avail', 0.011343537013890527),\n",
       " (u'innov', 0.011302266349079075),\n",
       " (u'partner', 0.01127278730278518),\n",
       " (u'currenc', 0.01122562082871495),\n",
       " (u'difficult', 0.011184350163903498),\n",
       " (u'ultim', 0.011078225597245478),\n",
       " (u'near', 0.011078225597245478),\n",
       " (u'relationship', 0.011042850741692804),\n",
       " (u'aggress', 0.010948517793552343),\n",
       " (u'without', 0.010924934556517227),\n",
       " (u'essenti', 0.010924934556517227),\n",
       " (u'jeff', 0.01086597646392944),\n",
       " (u'underli', 0.01085418484541188),\n",
       " (u'biggest', 0.010836497417635545),\n",
       " (u'drill', 0.010836497417635545),\n",
       " (u'maintain', 0.010836497417635545),\n",
       " (u'definit', 0.010812914180600429),\n",
       " (u'distribut', 0.010789330943565314),\n",
       " (u'took', 0.010783435134306536),\n",
       " (u'throughout', 0.010765747706530198),\n",
       " (u'q1', 0.01075395608801264),\n",
       " (u'somewhat', 0.01075395608801264),\n",
       " (u'later', 0.010742164469495084),\n",
       " (u'commod', 0.010694997995424851),\n",
       " (u'dave', 0.010683206376907294),\n",
       " (u'pull', 0.0106537273306134),\n",
       " (u'achiev', 0.010647831521354621),\n",
       " (u'restructur', 0.01060066504728439),\n",
       " (u'reserv', 0.010565290191731717),\n",
       " (u'tend', 0.010518123717661487),\n",
       " (u'goal', 0.010512227908402708),\n",
       " (u'bottom', 0.010500436289885149),\n",
       " (u'appropri', 0.010435582388038583),\n",
       " (u'sign', 0.010435582388038583),\n",
       " (u'energi', 0.010429686578779804),\n",
       " (u'resourc', 0.010423790769521024),\n",
       " (u'secondli', 0.010423790769521024),\n",
       " (u'origin', 0.010417894960262245),\n",
       " (u'suggest', 0.010411999151003467),\n",
       " (u'emerg', 0.010406103341744688),\n",
       " (u'charg', 0.010376624295450793),\n",
       " (u'separ', 0.010311770393604227),\n",
       " (u'fee', 0.010305874584345447),\n",
       " (u'et', 0.010146687734358418),\n",
       " (u'cetera', 0.010146687734358418),\n",
       " (u'compon', 0.01013489611584086),\n",
       " (u'stronger', 0.010099521260288187),\n",
       " (u'rule', 0.010093625451029408),\n",
       " (u'necessarili', 0.010075938023253071),\n",
       " (u'card', 0.010046458976959178),\n",
       " (u'regulatori', 0.0100405631677004),\n",
       " (u'secur', 0.010034667358441619),\n",
       " (u'surpris', 0.010022875739924062),\n",
       " (u'releas', 0.010011084121406505),\n",
       " (u'realiz', 0.00987548050845459),\n",
       " (u'respons', 0.009857793080678254),\n",
       " (u'volatil', 0.009851897271419476),\n",
       " (u'middl', 0.009733981086243898),\n",
       " (u'fulli', 0.009680918802914888),\n",
       " (u'whatev', 0.009657335565879773),\n",
       " (u'pace', 0.009639648138103436),\n",
       " (u'govern', 0.009598377473291984),\n",
       " (u'fix', 0.009586585854774426),\n",
       " (u'stock', 0.009545315189962975),\n",
       " (u'corpor', 0.009527627762186637),\n",
       " (u'primarili', 0.009521731952927858),\n",
       " (u'attract', 0.009509940334410301),\n",
       " (u'gone', 0.009509940334410301),\n",
       " (u'regul', 0.009498148715892744),\n",
       " (u'built', 0.009498148715892744),\n",
       " (u'remind', 0.00946277386034007),\n",
       " (u'assumpt', 0.009450982241822512),\n",
       " (u'control', 0.009403815767752281),\n",
       " (u'yield', 0.009368440912199608),\n",
       " (u'rig', 0.009344857675164494),\n",
       " (u'stage', 0.00930948281961182),\n",
       " (u'function', 0.009303587010353042),\n",
       " (u'liquid', 0.009280003773317926),\n",
       " (u'slide', 0.00925642053628281),\n",
       " (u'occur', 0.00925052472702403),\n",
       " (u'bob', 0.009238733108506474),\n",
       " (u'inform', 0.009197462443695022),\n",
       " (u'home', 0.009191566634436243),\n",
       " (u'encourag', 0.009150295969624791),\n",
       " (u'tough', 0.009150295969624791),\n",
       " (u'substanti', 0.009144400160366013),\n",
       " (u'approv', 0.009120816923330896),\n",
       " (u'plant', 0.009091337877037002),\n",
       " (u'idea', 0.009061858830743107),\n",
       " (u'scale', 0.00905006721222555),\n",
       " (u'test', 0.009044171402966771),\n",
       " (u'refer', 0.009026483975190435),\n",
       " (u'note', 0.009026483975190435),\n",
       " (u'hand', 0.009014692356672876),\n",
       " (u'context', 0.008991109119637762),\n",
       " (u'q2', 0.008967525882602646),\n",
       " (u'meaning', 0.008961630073343867),\n",
       " (u'free', 0.008938046836308751),\n",
       " (u'smaller', 0.008914463599273637),\n",
       " (u'wait', 0.008902671980756078),\n",
       " (u'promot', 0.0088967761714973),\n",
       " (u'rather', 0.008884984552979742),\n",
       " (u'larger', 0.008879088743720964),\n",
       " (u'ongo', 0.008879088743720964),\n",
       " (u'q3', 0.008879088743720964),\n",
       " (u'matter', 0.008855505506685847),\n",
       " (u'fiscal', 0.008855505506685847),\n",
       " (u'affect', 0.008849609697427069),\n",
       " (u'huge', 0.008837818078909512),\n",
       " (u'clarifi', 0.008831922269650733),\n",
       " (u'produc', 0.008820130651133174),\n",
       " (u'brian', 0.00879654741409806),\n",
       " (u'asia', 0.008772964177062944),\n",
       " (u'highlight', 0.008767068367804165),\n",
       " (u'construct', 0.008749380940027827),\n",
       " (u'entir', 0.008731693512251492),\n",
       " (u'mortgag', 0.008702214465957597),\n",
       " (u'recoveri', 0.008666839610404924),\n",
       " (u'describ', 0.008666839610404924),\n",
       " (u'figur', 0.008649152182628588),\n",
       " (u'news', 0.00863736056411103),\n",
       " (u'recogn', 0.00863736056411103),\n",
       " (u'greater', 0.00863146475485225),\n",
       " (u'faster', 0.008625568945593472),\n",
       " (u'tom', 0.008625568945593472),\n",
       " (u'e', 0.00858429828078202),\n",
       " (u'momentum', 0.00853123599745301),\n",
       " (u'flexibl', 0.00853123599745301),\n",
       " (u'cut', 0.008525340188194232),\n",
       " (u'win', 0.008513548569676673),\n",
       " (u'drop', 0.008501756951159116),\n",
       " (u'broad', 0.008495861141900337),\n",
       " (u'stabil', 0.008495861141900337),\n",
       " (u'present', 0.008472277904865221),\n",
       " (u'read', 0.008454590477088885),\n",
       " (u'never', 0.00842511143079499),\n",
       " (u'stand', 0.00842511143079499),\n",
       " (u'late', 0.008389736575242317),\n",
       " (u'infrastructur', 0.008389736575242317),\n",
       " (u'p', 0.008360257528948423),\n",
       " (u'weather', 0.008342570101172087),\n",
       " (u'buyback', 0.00833077848265453),\n",
       " (u'portion', 0.008324882673395751),\n",
       " (u'option', 0.008301299436360635),\n",
       " (u'deploy', 0.008295403627101856),\n",
       " (u'weak', 0.008254132962290404),\n",
       " (u'hedg', 0.008248237153031626),\n",
       " (u'domest', 0.008242341343772846),\n",
       " (u'inflat', 0.008242341343772846),\n",
       " (u'recal', 0.008236445534514067),\n",
       " (u'chain', 0.008212862297478953),\n",
       " (u'favor', 0.008206966488220174),\n",
       " (u'upon', 0.008201070678961394),\n",
       " (u'happi', 0.00817748744192628),\n",
       " (u'fall', 0.00817748744192628),\n",
       " (u'word', 0.00817748744192628),\n",
       " (u'watch', 0.008142112586373606),\n",
       " (u'variou', 0.008106737730820933),\n",
       " (u'franchis', 0.008100841921562154),\n",
       " (u'serv', 0.008100841921562154),\n",
       " (u'break', 0.008100841921562154),\n",
       " (u'coal', 0.008094946112303375),\n",
       " (u'extrem', 0.008077258684527038),\n",
       " (u'broadli', 0.008059571256750702),\n",
       " (u'although', 0.008053675447491923),\n",
       " (u'fundament', 0.008047779638233143),\n",
       " (u'predict', 0.008041883828974365),\n",
       " (u'purchas', 0.008035988019715586),\n",
       " (u'patient', 0.007982925736386577),\n",
       " (u'sit', 0.007953446690092682),\n",
       " (u'equip', 0.007947550880833903),\n",
       " (u'measur', 0.007935759262316346),\n",
       " (u'learn', 0.007923967643798787),\n",
       " (u'transit', 0.007906280216022452),\n",
       " (u'guid', 0.007894488597504894),\n",
       " (u'jim', 0.007882696978987335),\n",
       " (u'optim', 0.00785321793269344),\n",
       " (u'profil', 0.007835530504917105),\n",
       " (u'event', 0.007835530504917105),\n",
       " (u'sometim', 0.00781194726788199),\n",
       " (u'advertis', 0.00781194726788199),\n",
       " (u'review', 0.00780605145862321),\n",
       " (u'premium', 0.007800155649364432),\n",
       " (u'metric', 0.007794259840105653),\n",
       " (u'center', 0.007776572412329316),\n",
       " (u'upsid', 0.007723510129000306),\n",
       " (u'ever', 0.007699926891965191),\n",
       " (u'commentari', 0.007688135273447633),\n",
       " (u'matt', 0.007688135273447633),\n",
       " (u'spread', 0.007646864608636181),\n",
       " (u'element', 0.007623281371601066),\n",
       " (u'decemb', 0.007617385562342287),\n",
       " (u'dramat', 0.007593802325307172),\n",
       " (u'januari', 0.007552531660495719),\n",
       " (u'hous', 0.007546635851236941),\n",
       " (u'rais', 0.007546635851236941),\n",
       " (u'engin', 0.007546635851236941),\n",
       " (u'budget', 0.007505365186425489),\n",
       " (u'macro', 0.007505365186425489),\n",
       " (u'onlin', 0.00749946937716671),\n",
       " (u'japan', 0.007487677758649152),\n",
       " (u'paul', 0.0074817819493903735),\n",
       " (u'analyst', 0.007452302903096479),\n",
       " (u'phase', 0.0074464070938377),\n",
       " (u'commun', 0.0074405112845789215),\n",
       " (u'limit', 0.007434615475320142),\n",
       " (u'stabl', 0.00739924061976747),\n",
       " (u'alloc', 0.00739334481050869),\n",
       " (u'broader', 0.0073756573827323535),\n",
       " (u'manufactur', 0.007363865764214796),\n",
       " (u'previous', 0.007357969954956017),\n",
       " (u'r', 0.00734617833643846),\n",
       " (u'caus', 0.007328490908662123),\n",
       " (u'agreement', 0.007322595099403344),\n",
       " (u'mobil', 0.007322595099403344),\n",
       " (u'true', 0.007322595099403344),\n",
       " (u'annual', 0.007304907671627008),\n",
       " (u'impli', 0.007251845388297998),\n",
       " (u'stori', 0.007245949579039219),\n",
       " (u'touch', 0.007245949579039219),\n",
       " (u'solut', 0.0072282621512628825),\n",
       " (u'solid', 0.007216470532745324),\n",
       " (u'evalu', 0.007210574723486546),\n",
       " (u'compet', 0.007204678914227767),\n",
       " (u'somewher', 0.0071869914864514306),\n",
       " (u'readi', 0.007163408249416315),\n",
       " (u'closer', 0.007157512440157536),\n",
       " (u'design', 0.007145720821639979),\n",
       " (u'backlog', 0.007139825012381199),\n",
       " (u'deposit', 0.007116241775346084),\n",
       " (u'miss', 0.007104450156828526),\n",
       " (u'folk', 0.007051387873499517),\n",
       " (u'cover', 0.007021908827205622),\n",
       " (u'quantifi', 0.006986533971652949),\n",
       " (u'devic', 0.00698063816239417),\n",
       " (u'tradit', 0.0069747423531353915),\n",
       " (u'disciplin', 0.006951159116100276),\n",
       " (u'problem', 0.006862721977218593),\n",
       " (u'multipl', 0.006856826167959814),\n",
       " (u'therefor', 0.006850930358701035),\n",
       " (u'dan', 0.006850930358701035),\n",
       " (u'uniqu', 0.006821451312407141),\n",
       " (u'chri', 0.0068155555031483624),\n",
       " (u'brazil', 0.006809659693889583),\n",
       " (u'post', 0.006703535127231564),\n",
       " (u'ep', 0.006691743508714006),\n",
       " (u'lastli', 0.006691743508714006),\n",
       " (u'differenti', 0.006685847699455227),\n",
       " (u'reach', 0.006674056080937669),\n",
       " (u'implement', 0.006650472843902554),\n",
       " (u'walk', 0.006650472843902554),\n",
       " (u'timefram', 0.006644577034643775),\n",
       " (u'file', 0.006597410560573544),\n",
       " (u'peer', 0.006556139895762092),\n",
       " (u'facil', 0.006544348277244535),\n",
       " (u'modest', 0.006538452467985755),\n",
       " (u'fx', 0.0065207650402094195),\n",
       " (u'curv', 0.00651486923095064),\n",
       " (u'packag', 0.0065089734216918615),\n",
       " (u'sold', 0.006497181803174303),\n",
       " (u'exposur', 0.006491285993915525),\n",
       " (u'tremend', 0.006473598566139188),\n",
       " (u'decid', 0.006473598566139188),\n",
       " (u'light', 0.006473598566139188),\n",
       " (u'face', 0.0064677027568804096),\n",
       " (u'life', 0.0064559111383628515),\n",
       " (u'local', 0.006450015329104073),\n",
       " (u'access', 0.006426432092068958),\n",
       " (u'payment', 0.006426432092068958),\n",
       " (u'gotten', 0.006426432092068958),\n",
       " (u'renew', 0.0064146404735514),\n",
       " (u'forth', 0.0064028488550338415),\n",
       " (u'record', 0.006391057236516284),\n",
       " (u'march', 0.006373369808739948),\n",
       " (u'optimist', 0.00636157819022239),\n",
       " (u'load', 0.006332099143928496),\n",
       " (u'leav', 0.006326203334669717),\n",
       " (u'oppos', 0.006320307525410938),\n",
       " (u'schedul', 0.0063085159068933805),\n",
       " (u'engag', 0.006302620097634601),\n",
       " (u'repres', 0.006302620097634601),\n",
       " (u'repurchas', 0.006290828479117044),\n",
       " (u'financ', 0.006284932669858264),\n",
       " (u'european', 0.006284932669858264),\n",
       " (u'pictur', 0.006273141051340707),\n",
       " (u'standard', 0.006273141051340707),\n",
       " (u'canada', 0.006267245242081929),\n",
       " (u'particip', 0.006261349432823149),\n",
       " (u'math', 0.006214182958752919),\n",
       " (u'previou', 0.0062023913402353605),\n",
       " (u'robust', 0.006184703912459024),\n",
       " (u'primari', 0.006172912293941467),\n",
       " (u'mexico', 0.00615522486616513),\n",
       " (u'health', 0.0061493290569063505),\n",
       " (u'consolid', 0.006143433247647572),\n",
       " (u'moment', 0.006131641629130015),\n",
       " (u'properti', 0.006119850010612457),\n",
       " (u'advanc', 0.006119850010612457),\n",
       " (u'deliveri', 0.006113954201353678),\n",
       " (u'form', 0.006108058392094899),\n",
       " (u'individu', 0.006084475155059783),\n",
       " (u'sourc', 0.006084475155059783),\n",
       " (u'parti', 0.006072683536542226),\n",
       " (u'simpli', 0.006066787727283447),\n",
       " (u'penetr', 0.006060891918024668),\n",
       " (u'condit', 0.00604910029950711),\n",
       " (u'footprint', 0.0060432044902483315),\n",
       " (u'fuel', 0.006019621253213216),\n",
       " (u'extend', 0.0060019338254368795),\n",
       " (u'excess', 0.0060019338254368795),\n",
       " (u'room', 0.0059901422069193215),\n",
       " (u'movement', 0.005972454779142985),\n",
       " (u'exclud', 0.005960663160625428),\n",
       " (u'receiv', 0.005954767351366649),\n",
       " (u'public', 0.005937079923590312),\n",
       " (u'agre', 0.005937079923590312),\n",
       " (u'evolv', 0.005931184114331533),\n",
       " (u'variabl', 0.005931184114331533),\n",
       " (u'greg', 0.005919392495813976),\n",
       " (u'prioriti', 0.005913496686555196),\n",
       " (u'degre', 0.005872226021743744),\n",
       " (u'american', 0.005860434403226187),\n",
       " (u'matur', 0.005860434403226187),\n",
       " (u'statement', 0.005848642784708629),\n",
       " (u'clarif', 0.005819163738414735),\n",
       " (u'field', 0.0058014763106383985),\n",
       " (u'export', 0.00574251821805061),\n",
       " (u'peak', 0.0057366224087918305),\n",
       " (u'pre', 0.005707143362497937),\n",
       " (u'doug', 0.005701247553239157),\n",
       " (u'c', 0.005695351743980379),\n",
       " (u'pass', 0.005683560125462821),\n",
       " (u'mostli', 0.005677664316204042),\n",
       " (u'ship', 0.005677664316204042),\n",
       " (u'path', 0.005671768506945263),\n",
       " (u'handl', 0.005665872697686485),\n",
       " (u'fit', 0.005648185269910148),\n",
       " (u'l', 0.005642289460651369),\n",
       " (u'enterpris', 0.005642289460651369),\n",
       " (u'healthi', 0.00563639365139259),\n",
       " (u'visibl', 0.005618706223616253),\n",
       " (u'love', 0.005618706223616253),\n",
       " (u'firm', 0.005618706223616253),\n",
       " (u'conserv', 0.005601018795839917),\n",
       " (u'scott', 0.005595122986581138),\n",
       " (u'oh', 0.005595122986581138),\n",
       " (u'exit', 0.005595122986581138),\n",
       " (u'congratul', 0.005595122986581138),\n",
       " (u'acquir', 0.005595122986581138),\n",
       " (u'left', 0.0055892271773223595),\n",
       " (u'pension', 0.00558333136806358),\n",
       " (u'larri', 0.0055243732754757914),\n",
       " (u'applic', 0.005518477466217013),\n",
       " (u'notic', 0.005500790038440676),\n",
       " (u'delay', 0.0054831026106643395),\n",
       " (u'consider', 0.0054831026106643395),\n",
       " (u'weight', 0.005477206801405561),\n",
       " (u'trajectori', 0.005477206801405561),\n",
       " (u'critic', 0.005465415182888003),\n",
       " (u'despit', 0.005465415182888003),\n",
       " (u'content', 0.005465415182888003),\n",
       " (u'involv', 0.005453623564370446),\n",
       " (u'traffic', 0.005435936136594109),\n",
       " (u'jump', 0.00543004032733533),\n",
       " (u'percent', 0.00543004032733533),\n",
       " (u'usual', 0.005418248708817772),\n",
       " (u'connect', 0.005418248708817772),\n",
       " (u'live', 0.005412352899558994),\n",
       " (u'outcom', 0.005400561281041436),\n",
       " (u'shape', 0.005382873853265099),\n",
       " (u'tie', 0.005382873853265099),\n",
       " (u'press', 0.005371082234747542),\n",
       " (u'negoti', 0.005365186425488762),\n",
       " (u'enhanc', 0.005353394806971205),\n",
       " (u'forc', 0.005353394806971205),\n",
       " (u'studi', 0.005347498997712426),\n",
       " (u'bad', 0.005341603188453647),\n",
       " (u'gap', 0.005341603188453647),\n",
       " (u'accret', 0.005329811569936089),\n",
       " (u'finish', 0.005329811569936089),\n",
       " (u'respond', 0.0053239157606773104),\n",
       " (u'comparison', 0.0053239157606773104),\n",
       " (u'geographi', 0.005300332523642195),\n",
       " (u'discount', 0.005300332523642195),\n",
       " (u'character', 0.005288540905124637),\n",
       " (u'laid', 0.00527674928660708),\n",
       " (u'awar', 0.005264957668089522),\n",
       " (u'enter', 0.005259061858830743),\n",
       " (u'howev', 0.005247270240313185),\n",
       " (u'player', 0.005235478621795628),\n",
       " (u'switch', 0.005235478621795628),\n",
       " (u'polici', 0.0052295828125368485),\n",
       " (u'south', 0.0052295828125368485),\n",
       " (u'replac', 0.00522368700327807),\n",
       " (u'synergi', 0.005217791194019291),\n",
       " (u'grew', 0.005211895384760512),\n",
       " (u'rob', 0.005211895384760512),\n",
       " (u'exchang', 0.005205999575501733),\n",
       " (u'privat', 0.0051765205292078394),\n",
       " (u'captur', 0.005158833101431503),\n",
       " (u'magnitud', 0.005147041482913945),\n",
       " (u'largest', 0.005135249864396387),\n",
       " (u'sg', 0.005135249864396387),\n",
       " (u'richard', 0.005135249864396387),\n",
       " (u'land', 0.005129354055137608),\n",
       " (u'fast', 0.005117562436620051),\n",
       " (u'rise', 0.005111666627361271),\n",
       " (u'steadi', 0.005099875008843714),\n",
       " (u'spent', 0.005099875008843714),\n",
       " (u'michael', 0.005088083390326156),\n",
       " (u'sensit', 0.005088083390326156),\n",
       " (u'aspect', 0.0050821875810673775),\n",
       " (u'barrel', 0.005046812725514704),\n",
       " (u'will', 0.005046812725514704),\n",
       " (u'appli', 0.005035021106997146),\n",
       " (u'determin', 0.0050291252977383676),\n",
       " (u'carri', 0.005023229488479589),\n",
       " (u'explain', 0.005023229488479589),\n",
       " (u'moder', 0.005011437869962031),\n",
       " (u'fine', 0.004993750442185694),\n",
       " (u'spot', 0.004987854632926916),\n",
       " (u'experienc', 0.004987854632926916),\n",
       " (u'calcul', 0.004976063014409358),\n",
       " (u'protect', 0.004976063014409358),\n",
       " (u'uncertainti', 0.004970167205150579),\n",
       " (u'except', 0.004970167205150579),\n",
       " (u'june', 0.004970167205150579),\n",
       " (u'offic', 0.0049642713958918),\n",
       " (u'locat', 0.004952479777374242),\n",
       " (u'game', 0.004946583968115464),\n",
       " (u'disclos', 0.004940688158856684),\n",
       " (u'importantli', 0.004934792349597906),\n",
       " (u'object', 0.004928896540339127),\n",
       " (u'scenario', 0.004917104921821569),\n",
       " (u'septemb', 0.00491120911256279),\n",
       " (u'understood', 0.00491120911256279),\n",
       " (u'train', 0.004899417494045232),\n",
       " (u'person', 0.004893521684786454),\n",
       " (u'assess', 0.004893521684786454),\n",
       " (u'food', 0.004887625875527675),\n",
       " (u'up', 0.0048699384477513385),\n",
       " (u'role', 0.00486404263849256),\n",
       " (u'prospect', 0.00486404263849256),\n",
       " (u'repeat', 0.004852251019975002),\n",
       " (u'iii', 0.004846355210716223),\n",
       " (u'unusu', 0.004840459401457444),\n",
       " (u'incent', 0.0048168761644223285),\n",
       " (u'latin', 0.00481098035516355),\n",
       " (u'paid', 0.004805084545904771),\n",
       " (u'histori', 0.004805084545904771),\n",
       " (u'simpl', 0.004799188736645992),\n",
       " (u'quarterli', 0.004799188736645992),\n",
       " (u'legaci', 0.004787397118128435),\n",
       " (u'felt', 0.004752022262575761),\n",
       " (u'soon', 0.004752022262575761),\n",
       " (u'reinvest', 0.004746126453316982),\n",
       " (u'ex', 0.004734334834799425),\n",
       " (u'wind', 0.004722543216281867),\n",
       " (u'pursu', 0.004722543216281867),\n",
       " (u'prefer', 0.004722543216281867),\n",
       " (u'east', 0.00470485578850553),\n",
       " (u'labor', 0.004693064169987973),\n",
       " (u'clariti', 0.004675376742211636),\n",
       " (u'lose', 0.004663585123694078),\n",
       " (u'joe', 0.004657689314435299),\n",
       " (u'upgrad', 0.004651793505176521),\n",
       " (u'list', 0.004610522840365069),\n",
       " (u'healthcar', 0.004610522840365069),\n",
       " (u'tier', 0.004610522840365069),\n",
       " (u'imagin', 0.0046046270311062894),\n",
       " (u'permian', 0.004598731221847511),\n",
       " (u'brought', 0.004598731221847511),\n",
       " (u'lift', 0.004592835412588732),\n",
       " (u'russia', 0.004586939603329953),\n",
       " (u'confer', 0.004581043794071174),\n",
       " (u'main', 0.004569252175553616),\n",
       " (u'proposit', 0.0045633563662948375),\n",
       " (u'southern', 0.004557460557036059),\n",
       " (u'drag', 0.004557460557036059),\n",
       " (u'mainten', 0.004533877320000944),\n",
       " (u'k', 0.004522085701483386),\n",
       " (u'partnership', 0.004522085701483386),\n",
       " (u'leas', 0.004522085701483386),\n",
       " (u'identifi', 0.004516189892224607),\n",
       " (u'geograph', 0.004504398273707049),\n",
       " (u'estat', 0.00449850246444827),\n",
       " (u'altern', 0.004492606655189491),\n",
       " (u'lend', 0.004492606655189491),\n",
       " (u'insid', 0.004486710845930712),\n",
       " (u'analysi', 0.004474919227413155),\n",
       " (u'multi', 0.004474919227413155),\n",
       " (u'mine', 0.004469023418154376),\n",
       " (u'enabl', 0.004469023418154376),\n",
       " (u'excel', 0.004457231799636818),\n",
       " (u'worth', 0.00444544018111926),\n",
       " (u'cloud', 0.00444544018111926),\n",
       " (u'slower', 0.00444544018111926),\n",
       " (u'basel', 0.004439544371860482),\n",
       " (u'rich', 0.004433648562601702),\n",
       " (u'sub', 0.004433648562601702),\n",
       " (u'member', 0.004433648562601702),\n",
       " ...]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa_dir = LIBRARY_PATH+\"saved_models/base_plus_df10\"\n",
    "with open(qa_dir+\"/qa_pairs.txt\", \"r\") as f:\n",
    "    qa_pairs = json.loads(f.read())\n",
    "\n",
    "docf = defaultdict(int)\n",
    "total_docs = 0\n",
    "for file_id in qa_pairs:\n",
    "    for q_num in qa_pairs[file_id]:\n",
    "        q_words = set(qa_pairs[file_id][q_num][0])\n",
    "        a_words = set(qa_pairs[file_id][q_num][1])\n",
    "        for word in q_words:\n",
    "            docf[word] += 1\n",
    "        for word in a_words:\n",
    "            docf[word] += 1\n",
    "        total_docs += 2\n",
    "        \n",
    "print total_docs\n",
    "             \n",
    "doc_freqs = [(w, docf[w]*1.0/total_docs) for w in docf]\n",
    "doc_freqs = sorted(doc_freqs, key = lambda w: w[1], reverse = True)\n",
    "doc_freqs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learn new models using the qa pairs with high df words removed\n",
    "\n",
    "Just going to run one set of topics/min length for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_spec_list = [\n",
    "    {'description': 'Topics 20, Min Length 20, base plus df 0.05 threshold',\n",
    "  'iterations': 100,\n",
    "  'min_sequence_length': 20,\n",
    "  'model_directory': 'saved_models/top20_len20_prebase_df5',\n",
    "  'num_topics': 20,\n",
    "  'passes': 20,\n",
    "  'preprocessing_function': 'testLDA_pre_process_document',\n",
    "  'qa_pair_directory': 'saved_models/base_plus_df5'},\n",
    "    {'description': 'Topics 20, Min Length 20, base plus df 0.10 threshold',\n",
    "  'iterations': 100,\n",
    "  'min_sequence_length': 20,\n",
    "  'model_directory': 'saved_models/top20_len20_prebase_df10',\n",
    "  'num_topics': 20,\n",
    "  'passes': 20,\n",
    "  'preprocessing_function': 'testLDA_pre_process_document',\n",
    "  'qa_pair_directory': 'saved_models/base_plus_df10'},\n",
    "    {'description': 'Topics 20, Min Length 20, base plus df 0.20 threshold',\n",
    "  'iterations': 100,\n",
    "  'min_sequence_length': 20,\n",
    "  'model_directory': 'saved_models/top20_len20_prebase_df20',\n",
    "  'num_topics': 20,\n",
    "  'passes': 20,\n",
    "  'preprocessing_function': 'testLDA_pre_process_document',\n",
    "  'qa_pair_directory': 'saved_models/base_plus_df20'}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15640 pairs met minimum length.\n",
      "69166 were rejected.\n",
      "fitting model\n",
      "model fitting took 931.181818008 seconds\n",
      "Processed  5000 pairs in 2.64878702164\n",
      "Processed  10000 pairs in 4.90529704094\n",
      "Processed  15000 pairs in 7.08386707306\n",
      "Processed  20000 pairs in 9.15109395981\n",
      "Processed  25000 pairs in 11.4138550758\n",
      "Processed  30000 pairs in 13.5412130356\n",
      "Processed  35000 pairs in 15.7022058964\n",
      "Processed  40000 pairs in 17.811396122\n",
      "Processed  45000 pairs in 20.0527279377\n",
      "Processed  50000 pairs in 22.2290399075\n",
      "Processed  55000 pairs in 24.2675149441\n",
      "Processed  60000 pairs in 26.498748064\n",
      "Processed  65000 pairs in 28.5355629921\n",
      "Processed  70000 pairs in 30.5012960434\n",
      "Processed  75000 pairs in 32.8700919151\n",
      "Processed  80000 pairs in 34.9338350296\n",
      "Finished in 36.8963549137\n",
      "26275 pairs met minimum length.\n",
      "58531 were rejected.\n",
      "fitting model\n",
      "model fitting took 1681.23539281 seconds\n",
      "Processed  5000 pairs in 4.25869202614\n",
      "Processed  10000 pairs in 8.44302487373\n",
      "Processed  15000 pairs in 12.8299229145\n",
      "Processed  20000 pairs in 16.8022348881\n",
      "Processed  25000 pairs in 21.391520977\n",
      "Processed  30000 pairs in 25.5087819099\n",
      "Processed  35000 pairs in 29.9980478287\n",
      "Processed  40000 pairs in 34.1277358532\n",
      "Processed  45000 pairs in 38.5878698826\n",
      "Processed  50000 pairs in 42.8441798687\n",
      "Processed  55000 pairs in 46.7261259556\n",
      "Processed  60000 pairs in 51.0402588844\n",
      "Processed  65000 pairs in 55.3023679256\n",
      "Processed  70000 pairs in 59.1828148365\n",
      "Processed  75000 pairs in 63.9862759113\n",
      "Processed  80000 pairs in 68.7022910118\n",
      "Finished in 72.6470348835\n",
      "34424 pairs met minimum length.\n",
      "50382 were rejected.\n",
      "fitting model\n",
      "model fitting took 2569.84483194 seconds\n",
      "Processed  5000 pairs in 6.15197896957\n",
      "Processed  10000 pairs in 12.036646843\n",
      "Processed  15000 pairs in 17.7431848049\n",
      "Processed  20000 pairs in 23.3346378803\n",
      "Processed  25000 pairs in 29.2382919788\n",
      "Processed  30000 pairs in 34.8972268105\n",
      "Processed  35000 pairs in 40.8439548016\n",
      "Processed  40000 pairs in 46.6271297932\n",
      "Processed  45000 pairs in 53.3072228432\n",
      "Processed  50000 pairs in 59.9962918758\n",
      "Processed  55000 pairs in 67.4086098671\n",
      "Processed  60000 pairs in 74.2878558636\n",
      "Processed  65000 pairs in 79.7217729092\n",
      "Processed  70000 pairs in 85.2138879299\n",
      "Processed  75000 pairs in 91.858757019\n",
      "Processed  80000 pairs in 97.960878849\n",
      "Finished in 103.300694942\n"
     ]
    }
   ],
   "source": [
    "# Need to reload new qa_pairs for each model now, as preprocessing varies\n",
    "\n",
    "for model_spec in model_spec_list:\n",
    "    \n",
    "    qa_dir = LIBRARY_PATH+model_spec[\"qa_pair_directory\"]\n",
    "    with open(qa_dir+\"/qa_pairs.txt\", \"r\") as f:\n",
    "        qa_pairs = json.loads(f.read())\n",
    "    \n",
    "    save_model_spec(model_spec)\n",
    "\n",
    "    texts = select_texts(qa_pairs, model_spec)\n",
    "\n",
    "    learn_LDA_model(model_spec, texts, passes = model_spec[\"passes\"], iterations = model_spec[\"iterations\"])\n",
    "\n",
    "    calc_hellinger_sims(model_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved_models/top20_len20_prebase_df5\n",
      "('19', '-7.704', '208.6', '1280', '1278', '1280')\n",
      "saved_models/top20_len20_prebase_df10\n",
      "('19', '-7.423', '171.7', '550', '549', '550')\n",
      "saved_models/top20_len20_prebase_df20\n",
      "('19', '-7.209', '147.9', '848', '839', '848')\n"
     ]
    }
   ],
   "source": [
    "final_perp = dict()\n",
    "\n",
    "for model_spec in model_spec_list:\n",
    "    model_dir = model_spec[\"model_directory\"]\n",
    "    logfile = LIBRARY_PATH+model_dir+\"/lda_logfile.log\"\n",
    "    with open(logfile) as f:\n",
    "        loglines = f.readlines()\n",
    "    final_perp[model_dir] = parse_logfile(loglines)\n",
    "    print model_dir\n",
    "    print final_perp[model_dir][-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Going to learn new models around 40/40 as it gave good portfolio results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'description': 'Topics 30, Min Length 30, base preprocessing, passes20, iterations100',\n",
       "  'iterations': 100,\n",
       "  'min_sequence_length': 30,\n",
       "  'model_directory': 'saved_models/1216_top30_len30_prebase',\n",
       "  'num_topics': 30,\n",
       "  'passes': 20,\n",
       "  'preprocessing_function': 'testLDA_pre_process_document',\n",
       "  'qa_pair_directory': 'saved_models/standard_preproc'},\n",
       " {'description': 'Topics 30, Min Length 40, base preprocessing, passes20, iterations100',\n",
       "  'iterations': 100,\n",
       "  'min_sequence_length': 40,\n",
       "  'model_directory': 'saved_models/1216_top30_len40_prebase',\n",
       "  'num_topics': 30,\n",
       "  'passes': 20,\n",
       "  'preprocessing_function': 'testLDA_pre_process_document',\n",
       "  'qa_pair_directory': 'saved_models/standard_preproc'},\n",
       " {'description': 'Topics 30, Min Length 50, base preprocessing, passes20, iterations100',\n",
       "  'iterations': 100,\n",
       "  'min_sequence_length': 50,\n",
       "  'model_directory': 'saved_models/1216_top30_len50_prebase',\n",
       "  'num_topics': 30,\n",
       "  'passes': 20,\n",
       "  'preprocessing_function': 'testLDA_pre_process_document',\n",
       "  'qa_pair_directory': 'saved_models/standard_preproc'},\n",
       " {'description': 'Topics 40, Min Length 30, base preprocessing, passes20, iterations100',\n",
       "  'iterations': 100,\n",
       "  'min_sequence_length': 30,\n",
       "  'model_directory': 'saved_models/1216_top40_len30_prebase',\n",
       "  'num_topics': 40,\n",
       "  'passes': 20,\n",
       "  'preprocessing_function': 'testLDA_pre_process_document',\n",
       "  'qa_pair_directory': 'saved_models/standard_preproc'},\n",
       " {'description': 'Topics 40, Min Length 40, base preprocessing, passes20, iterations100',\n",
       "  'iterations': 100,\n",
       "  'min_sequence_length': 40,\n",
       "  'model_directory': 'saved_models/1216_top40_len40_prebase',\n",
       "  'num_topics': 40,\n",
       "  'passes': 20,\n",
       "  'preprocessing_function': 'testLDA_pre_process_document',\n",
       "  'qa_pair_directory': 'saved_models/standard_preproc'},\n",
       " {'description': 'Topics 40, Min Length 50, base preprocessing, passes20, iterations100',\n",
       "  'iterations': 100,\n",
       "  'min_sequence_length': 50,\n",
       "  'model_directory': 'saved_models/1216_top40_len50_prebase',\n",
       "  'num_topics': 40,\n",
       "  'passes': 20,\n",
       "  'preprocessing_function': 'testLDA_pre_process_document',\n",
       "  'qa_pair_directory': 'saved_models/standard_preproc'},\n",
       " {'description': 'Topics 50, Min Length 30, base preprocessing, passes20, iterations100',\n",
       "  'iterations': 100,\n",
       "  'min_sequence_length': 30,\n",
       "  'model_directory': 'saved_models/1216_top50_len30_prebase',\n",
       "  'num_topics': 50,\n",
       "  'passes': 20,\n",
       "  'preprocessing_function': 'testLDA_pre_process_document',\n",
       "  'qa_pair_directory': 'saved_models/standard_preproc'},\n",
       " {'description': 'Topics 50, Min Length 40, base preprocessing, passes20, iterations100',\n",
       "  'iterations': 100,\n",
       "  'min_sequence_length': 40,\n",
       "  'model_directory': 'saved_models/1216_top50_len40_prebase',\n",
       "  'num_topics': 50,\n",
       "  'passes': 20,\n",
       "  'preprocessing_function': 'testLDA_pre_process_document',\n",
       "  'qa_pair_directory': 'saved_models/standard_preproc'},\n",
       " {'description': 'Topics 50, Min Length 50, base preprocessing, passes20, iterations100',\n",
       "  'iterations': 100,\n",
       "  'min_sequence_length': 50,\n",
       "  'model_directory': 'saved_models/1216_top50_len50_prebase',\n",
       "  'num_topics': 50,\n",
       "  'passes': 20,\n",
       "  'preprocessing_function': 'testLDA_pre_process_document',\n",
       "  'qa_pair_directory': 'saved_models/standard_preproc'}]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a list of model specs to run\n",
    "\n",
    "num_topics_list = [30, 40, 50]\n",
    "min_length_list = [30, 40, 50]\n",
    "pre_pro_list = [(\"base\", \"testLDA_pre_process_document\")]\n",
    "passes_list = [20]\n",
    "iterations_list = [100]\n",
    "\n",
    "model_spec_list = []\n",
    "\n",
    "for num_topics in num_topics_list:\n",
    "    for min_length in min_length_list:\n",
    "        for pre_pro in pre_pro_list:\n",
    "            for passes in passes_list:\n",
    "                for iterations in iterations_list:\n",
    "                \n",
    "                    dir_name = \"1216_top\"+str(num_topics)+\\\n",
    "                               \"_len\"+str(min_length)+\\\n",
    "                               \"_pre\"+pre_pro[0]\\\n",
    "\n",
    "\n",
    "                    model_dir = \"saved_models/\"+dir_name\n",
    "\n",
    "                    model_spec = {\"model_directory\": model_dir,\n",
    "                  \"qa_pair_directory\": \"saved_models/standard_preproc\",\n",
    "                  \"preprocessing_function\": pre_pro[1],\n",
    "                  \"min_sequence_length\": min_length,\n",
    "                  \"num_topics\": num_topics,\n",
    "                  \"passes\": passes,\n",
    "                  \"iterations\": iterations,\n",
    "                  \"description\": \"Topics \"+str(num_topics)+\\\n",
    "                                  \", Min Length \"+str(min_length)+\\\n",
    "                                  \", \"+pre_pro[0]+\" preprocessing\"+\\\n",
    "                                  \", passes\"+str(passes)+\\\n",
    "                                  \", iterations\"+str(iterations)}\n",
    "\n",
    "                    model_spec_list.append(model_spec)\n",
    "\n",
    "model_spec_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23983 pairs met minimum length.\n",
      "60823 were rejected.\n",
      "fitting model\n",
      "model fitting took 2177.52697301 seconds\n",
      "Processed  5000 pairs in 4.66460490227\n",
      "Processed  10000 pairs in 9.61262893677\n",
      "Processed  15000 pairs in 14.3877160549\n",
      "Processed  20000 pairs in 18.8593599796\n",
      "Processed  25000 pairs in 23.7596209049\n",
      "Processed  30000 pairs in 28.4057168961\n",
      "Processed  35000 pairs in 33.0510339737\n",
      "Processed  40000 pairs in 37.7700738907\n",
      "Processed  45000 pairs in 42.4985659122\n",
      "Processed  50000 pairs in 47.3980169296\n",
      "Processed  55000 pairs in 52.2415890694\n",
      "Processed  60000 pairs in 57.2489650249\n",
      "Processed  65000 pairs in 61.8114099503\n",
      "Processed  70000 pairs in 66.2170388699\n",
      "Processed  75000 pairs in 71.5379519463\n",
      "Processed  80000 pairs in 75.9677929878\n",
      "Finished in 80.264359951\n",
      "13245 pairs met minimum length.\n",
      "71561 were rejected.\n",
      "fitting model\n",
      "model fitting took 1137.70855904 seconds\n",
      "Processed  5000 pairs in 2.94407510757\n",
      "Processed  10000 pairs in 5.97144293785\n",
      "Processed  15000 pairs in 8.95537400246\n",
      "Processed  20000 pairs in 11.6034331322\n",
      "Processed  25000 pairs in 14.5869860649\n",
      "Processed  30000 pairs in 17.1779301167\n",
      "Processed  35000 pairs in 19.8747329712\n",
      "Processed  40000 pairs in 22.6002860069\n",
      "Processed  45000 pairs in 25.6435830593\n",
      "Processed  50000 pairs in 28.4848561287\n",
      "Processed  55000 pairs in 30.9663100243\n",
      "Processed  60000 pairs in 33.7984240055\n",
      "Processed  65000 pairs in 36.4556179047\n",
      "Processed  70000 pairs in 38.9339270592\n",
      "Processed  75000 pairs in 42.14980793\n",
      "Processed  80000 pairs in 44.7940280437\n",
      "Finished in 47.1381089687\n",
      "6667 pairs met minimum length.\n",
      "78139 were rejected.\n",
      "fitting model\n",
      "model fitting took 616.367420912 seconds\n",
      "Processed  5000 pairs in 1.51783204079\n",
      "Processed  10000 pairs in 2.98557710648\n",
      "Processed  15000 pairs in 4.4965031147\n",
      "Processed  20000 pairs in 5.81537508965\n",
      "Processed  25000 pairs in 7.2907910347\n",
      "Processed  30000 pairs in 8.75239396095\n",
      "Processed  35000 pairs in 10.1968669891\n",
      "Processed  40000 pairs in 11.5781519413\n",
      "Processed  45000 pairs in 13.0675649643\n",
      "Processed  50000 pairs in 14.6505861282\n",
      "Processed  55000 pairs in 16.0362761021\n",
      "Processed  60000 pairs in 17.5748729706\n",
      "Processed  65000 pairs in 18.9608709812\n",
      "Processed  70000 pairs in 20.2395100594\n",
      "Processed  75000 pairs in 22.1000430584\n",
      "Processed  80000 pairs in 23.4706449509\n",
      "Finished in 24.6399509907\n",
      "23983 pairs met minimum length.\n",
      "60823 were rejected.\n",
      "fitting model\n",
      "model fitting took 2243.5430429 seconds\n",
      "Processed  5000 pairs in 5.19036006927\n",
      "Processed  10000 pairs in 10.7540841103\n",
      "Processed  15000 pairs in 16.0903871059\n",
      "Processed  20000 pairs in 21.0450839996\n",
      "Processed  25000 pairs in 26.3115339279\n",
      "Processed  30000 pairs in 31.5372231007\n",
      "Processed  35000 pairs in 36.9170939922\n",
      "Processed  40000 pairs in 42.3924770355\n",
      "Processed  45000 pairs in 47.8519530296\n",
      "Processed  50000 pairs in 53.3746159077\n",
      "Processed  55000 pairs in 58.4314899445\n",
      "Processed  60000 pairs in 63.9392850399\n",
      "Processed  65000 pairs in 69.0491790771\n",
      "Processed  70000 pairs in 74.2393450737\n",
      "Processed  75000 pairs in 80.4164760113\n",
      "Processed  80000 pairs in 85.5831799507\n",
      "Finished in 90.3593020439\n",
      "13245 pairs met minimum length.\n",
      "71561 were rejected.\n",
      "fitting model\n",
      "model fitting took 1257.8627789 seconds\n",
      "Processed  5000 pairs in 3.10950994492\n",
      "Processed  10000 pairs in 6.74392199516\n",
      "Processed  15000 pairs in 10.0386879444\n",
      "Processed  20000 pairs in 12.9758899212\n",
      "Processed  25000 pairs in 16.2894809246\n",
      "Processed  30000 pairs in 19.4637539387\n",
      "Processed  35000 pairs in 22.6056599617\n",
      "Processed  40000 pairs in 25.7424349785\n",
      "Processed  45000 pairs in 28.9607410431\n",
      "Processed  50000 pairs in 32.3353331089\n",
      "Processed  55000 pairs in 35.2127320766\n",
      "Processed  60000 pairs in 38.5833311081\n",
      "Processed  65000 pairs in 41.6401119232\n",
      "Processed  70000 pairs in 44.498169899\n",
      "Processed  75000 pairs in 48.3123309612\n",
      "Processed  80000 pairs in 51.4222989082\n",
      "Finished in 54.2021329403\n",
      "6667 pairs met minimum length.\n",
      "78139 were rejected.\n",
      "fitting model\n",
      "model fitting took 729.761101961 seconds\n",
      "Processed  5000 pairs in 1.75727391243\n",
      "Processed  10000 pairs in 3.43860602379\n",
      "Processed  15000 pairs in 5.21055197716\n",
      "Processed  20000 pairs in 6.69615793228\n",
      "Processed  25000 pairs in 8.38105988503\n",
      "Processed  30000 pairs in 9.98232984543\n",
      "Processed  35000 pairs in 11.570912838\n",
      "Processed  40000 pairs in 13.1308858395\n",
      "Processed  45000 pairs in 14.7840209007\n",
      "Processed  50000 pairs in 16.5123009682\n",
      "Processed  55000 pairs in 18.0198750496\n",
      "Processed  60000 pairs in 19.7017128468\n",
      "Processed  65000 pairs in 21.23137784\n",
      "Processed  70000 pairs in 22.6214249134\n",
      "Processed  75000 pairs in 24.6029019356\n",
      "Processed  80000 pairs in 26.1176419258\n",
      "Finished in 27.4733798504\n",
      "23983 pairs met minimum length.\n",
      "60823 were rejected.\n",
      "fitting model\n",
      "model fitting took 2444.11125398 seconds\n",
      "Processed  5000 pairs in 5.86936712265\n",
      "Processed  10000 pairs in 11.9996201992\n",
      "Processed  15000 pairs in 17.860491991\n",
      "Processed  20000 pairs in 23.7202110291\n",
      "Processed  25000 pairs in 30.1063001156\n",
      "Processed  30000 pairs in 35.8912391663\n",
      "Processed  35000 pairs in 41.7231960297\n",
      "Processed  40000 pairs in 47.6072192192\n",
      "Processed  45000 pairs in 53.6028192043\n",
      "Processed  50000 pairs in 59.8251590729\n",
      "Processed  55000 pairs in 65.3911170959\n",
      "Processed  60000 pairs in 71.5852789879\n",
      "Processed  65000 pairs in 77.1838331223\n",
      "Processed  70000 pairs in 82.7125461102\n",
      "Processed  75000 pairs in 89.5249111652\n",
      "Processed  80000 pairs in 95.1189072132\n",
      "Finished in 100.400844097\n",
      "13245 pairs met minimum length.\n",
      "71561 were rejected.\n",
      "fitting model\n",
      "model fitting took 1414.60847092 seconds\n",
      "Processed  5000 pairs in 3.37780284882\n",
      "Processed  10000 pairs in 6.88326692581\n",
      "Processed  15000 pairs in 10.4345958233\n",
      "Processed  20000 pairs in 13.6345529556\n",
      "Processed  25000 pairs in 17.1533420086\n",
      "Processed  30000 pairs in 20.552891016\n",
      "Processed  35000 pairs in 23.9596037865\n",
      "Processed  40000 pairs in 27.4695208073\n",
      "Processed  45000 pairs in 30.9210247993\n",
      "Processed  50000 pairs in 34.6097259521\n",
      "Processed  55000 pairs in 37.7544469833\n",
      "Processed  60000 pairs in 41.4714488983\n",
      "Processed  65000 pairs in 44.8608570099\n",
      "Processed  70000 pairs in 48.0100238323\n",
      "Processed  75000 pairs in 52.1919898987\n",
      "Processed  80000 pairs in 55.5670089722\n",
      "Finished in 58.5443329811\n",
      "6667 pairs met minimum length.\n",
      "78139 were rejected.\n",
      "fitting model\n",
      "model fitting took 736.166646004 seconds\n",
      "Processed  5000 pairs in 1.69891214371\n",
      "Processed  10000 pairs in 3.42787504196\n",
      "Processed  15000 pairs in 5.2073841095\n",
      "Processed  20000 pairs in 6.7616519928\n",
      "Processed  25000 pairs in 8.56890392303\n",
      "Processed  30000 pairs in 10.3456721306\n",
      "Processed  35000 pairs in 12.0634269714\n",
      "Processed  40000 pairs in 13.7179141045\n",
      "Processed  45000 pairs in 15.490167141\n",
      "Processed  50000 pairs in 17.4135460854\n",
      "Processed  55000 pairs in 19.0348110199\n",
      "Processed  60000 pairs in 20.8323640823\n",
      "Processed  65000 pairs in 22.5402920246\n",
      "Processed  70000 pairs in 24.0269539356\n",
      "Processed  75000 pairs in 26.198923111\n",
      "Processed  80000 pairs in 27.81854105\n",
      "Finished in 29.2355120182\n"
     ]
    }
   ],
   "source": [
    "# Can just load already preprocessed qa pairs as applying standard preprocessing\n",
    "qa_dir = LIBRARY_PATH+model_spec[\"qa_pair_directory\"]\n",
    "with open(qa_dir+\"/qa_pairs.txt\", \"r\") as f:\n",
    "    qa_pairs = json.loads(f.read())\n",
    "\n",
    "for model_spec in model_spec_list:\n",
    "    \n",
    "    save_model_spec(model_spec)\n",
    "\n",
    "    texts = select_texts(qa_pairs, model_spec)\n",
    "\n",
    "    learn_LDA_model(model_spec, texts, passes = model_spec[\"passes\"], iterations = model_spec[\"iterations\"])\n",
    "\n",
    "    calc_hellinger_sims(model_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'description': 'Topics 40, Min Length 40, base preprocessing, passes20, iterations100',\n",
       "  'iterations': 100,\n",
       "  'min_sequence_length': 40,\n",
       "  'model_directory': 'saved_models/Check_top40_len40_prebase',\n",
       "  'num_topics': 40,\n",
       "  'passes': 20,\n",
       "  'preprocessing_function': 'testLDA_pre_process_document',\n",
       "  'qa_pair_directory': 'saved_models/standard_preproc'}]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a list of model specs to run\n",
    "\n",
    "num_topics_list = [40]\n",
    "min_length_list = [40]\n",
    "pre_pro_list = [(\"base\", \"testLDA_pre_process_document\")]\n",
    "passes_list = [20]\n",
    "iterations_list = [100]\n",
    "\n",
    "model_spec_list = []\n",
    "\n",
    "for num_topics in num_topics_list:\n",
    "    for min_length in min_length_list:\n",
    "        for pre_pro in pre_pro_list:\n",
    "            for passes in passes_list:\n",
    "                for iterations in iterations_list:\n",
    "                \n",
    "                    dir_name = \"Check_top\"+str(num_topics)+\\\n",
    "                               \"_len\"+str(min_length)+\\\n",
    "                               \"_pre\"+pre_pro[0]\\\n",
    "\n",
    "\n",
    "                    model_dir = \"saved_models/\"+dir_name\n",
    "\n",
    "                    model_spec = {\"model_directory\": model_dir,\n",
    "                  \"qa_pair_directory\": \"saved_models/standard_preproc\",\n",
    "                  \"preprocessing_function\": pre_pro[1],\n",
    "                  \"min_sequence_length\": min_length,\n",
    "                  \"num_topics\": num_topics,\n",
    "                  \"passes\": passes,\n",
    "                  \"iterations\": iterations,\n",
    "                  \"description\": \"Topics \"+str(num_topics)+\\\n",
    "                                  \", Min Length \"+str(min_length)+\\\n",
    "                                  \", \"+pre_pro[0]+\" preprocessing\"+\\\n",
    "                                  \", passes\"+str(passes)+\\\n",
    "                                  \", iterations\"+str(iterations)}\n",
    "\n",
    "                    model_spec_list.append(model_spec)\n",
    "\n",
    "model_spec_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13245 pairs met minimum length.\n",
      "71561 were rejected.\n",
      "fitting model\n",
      "model fitting took 1469.67936301 seconds\n",
      "Processed  5000 pairs in 3.51755189896\n",
      "Processed  10000 pairs in 6.99314188957\n",
      "Processed  15000 pairs in 10.2356739044\n",
      "Processed  20000 pairs in 13.4941048622\n",
      "Processed  25000 pairs in 16.8167388439\n",
      "Processed  30000 pairs in 20.0403490067\n",
      "Processed  35000 pairs in 23.1365590096\n",
      "Processed  40000 pairs in 26.3454458714\n",
      "Processed  45000 pairs in 29.439814806\n",
      "Processed  50000 pairs in 32.7577548027\n",
      "Processed  55000 pairs in 35.8159527779\n",
      "Processed  60000 pairs in 39.4921519756\n",
      "Processed  65000 pairs in 42.5750889778\n",
      "Processed  70000 pairs in 45.3758888245\n",
      "Processed  75000 pairs in 49.4534049034\n",
      "Processed  80000 pairs in 52.7547068596\n",
      "Finished in 55.5137557983\n"
     ]
    }
   ],
   "source": [
    "# Can just load already preprocessed qa pairs as applying standard preprocessing\n",
    "qa_dir = LIBRARY_PATH+model_spec[\"qa_pair_directory\"]\n",
    "with open(qa_dir+\"/qa_pairs.txt\", \"r\") as f:\n",
    "    qa_pairs = json.loads(f.read())\n",
    "\n",
    "for model_spec in model_spec_list:\n",
    "    \n",
    "    save_model_spec(model_spec)\n",
    "\n",
    "    texts = select_texts(qa_pairs, model_spec)\n",
    "\n",
    "    learn_LDA_model(model_spec, texts, passes = model_spec[\"passes\"], iterations = model_spec[\"iterations\"])\n",
    "\n",
    "    calc_hellinger_sims(model_spec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Going to experiment with df limits on topics around 40/40 model, as that seems to give some useful results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_spec_list = [\n",
    "    {'description': 'Topics 40, Min Length 40, base plus df 0.05 threshold',\n",
    "  'iterations': 100,\n",
    "  'min_sequence_length': 40,\n",
    "  'model_directory': 'saved_models/top40_len40_prebase_df5',\n",
    "  'num_topics': 40,\n",
    "  'passes': 20,\n",
    "  'preprocessing_function': 'testLDA_pre_process_document',\n",
    "  'qa_pair_directory': 'saved_models/base_plus_df5'},\n",
    "    {'description': 'Topics 40, Min Length 40, base plus df 0.10 threshold',\n",
    "  'iterations': 100,\n",
    "  'min_sequence_length': 40,\n",
    "  'model_directory': 'saved_models/top40_len40_prebase_df10',\n",
    "  'num_topics': 40,\n",
    "  'passes': 20,\n",
    "  'preprocessing_function': 'testLDA_pre_process_document',\n",
    "  'qa_pair_directory': 'saved_models/base_plus_df10'},\n",
    "    {'description': 'Topics 40, Min Length 40, base plus df 0.20 threshold',\n",
    "  'iterations': 100,\n",
    "  'min_sequence_length': 40,\n",
    "  'model_directory': 'saved_models/top40_len40_prebase_df20',\n",
    "  'num_topics': 40,\n",
    "  'passes': 20,\n",
    "  'preprocessing_function': 'testLDA_pre_process_document',\n",
    "  'qa_pair_directory': 'saved_models/base_plus_df20'}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1297 pairs met minimum length.\n",
      "83509 were rejected.\n",
      "fitting model\n",
      "model fitting took 127.421066046 seconds\n",
      "Processed  5000 pairs in 0.262289047241\n",
      "Processed  10000 pairs in 0.528314113617\n",
      "Processed  15000 pairs in 0.798123121262\n",
      "Processed  20000 pairs in 1.04767608643\n",
      "Processed  25000 pairs in 1.32647109032\n",
      "Processed  30000 pairs in 1.60794305801\n",
      "Processed  35000 pairs in 1.97310805321\n",
      "Processed  40000 pairs in 2.16442012787\n",
      "Processed  45000 pairs in 2.50990819931\n",
      "Processed  50000 pairs in 2.82957816124\n",
      "Processed  55000 pairs in 3.1357049942\n",
      "Processed  60000 pairs in 3.37325310707\n",
      "Processed  65000 pairs in 3.60541510582\n",
      "Processed  70000 pairs in 3.7563970089\n",
      "Processed  75000 pairs in 3.98931717873\n",
      "Processed  80000 pairs in 4.17177915573\n",
      "Finished in 4.33896613121\n",
      "4581 pairs met minimum length.\n",
      "80225 were rejected.\n",
      "fitting model\n",
      "model fitting took 421.059894085 seconds\n",
      "Processed  5000 pairs in 1.11442780495\n",
      "Processed  10000 pairs in 2.21771383286\n",
      "Processed  15000 pairs in 3.34345197678\n",
      "Processed  20000 pairs in 4.77447891235\n",
      "Processed  25000 pairs in 5.87979698181\n",
      "Processed  30000 pairs in 6.9984228611\n",
      "Processed  35000 pairs in 8.24795389175\n",
      "Processed  40000 pairs in 9.26230192184\n",
      "Processed  45000 pairs in 10.2240138054\n",
      "Processed  50000 pairs in 11.1916527748\n",
      "Processed  55000 pairs in 12.0314049721\n",
      "Processed  60000 pairs in 12.9931428432\n",
      "Processed  65000 pairs in 13.8693788052\n",
      "Processed  70000 pairs in 14.6863207817\n",
      "Processed  75000 pairs in 15.8324358463\n",
      "Processed  80000 pairs in 16.6393637657\n",
      "Finished in 17.4370088577\n",
      "10350 pairs met minimum length.\n",
      "74456 were rejected.\n",
      "fitting model\n",
      "model fitting took 1057.25953007 seconds\n",
      "Processed  5000 pairs in 2.67486906052\n",
      "Processed  10000 pairs in 5.19858694077\n",
      "Processed  15000 pairs in 7.72188901901\n",
      "Processed  20000 pairs in 10.1282131672\n",
      "Processed  25000 pairs in 12.8298361301\n",
      "Processed  30000 pairs in 15.1093630791\n",
      "Processed  35000 pairs in 17.4368751049\n",
      "Processed  40000 pairs in 19.6024010181\n",
      "Processed  45000 pairs in 22.0789000988\n",
      "Processed  50000 pairs in 24.6509900093\n",
      "Processed  55000 pairs in 26.9387199879\n",
      "Processed  60000 pairs in 29.4214761257\n",
      "Processed  65000 pairs in 31.7769610882\n",
      "Processed  70000 pairs in 33.9874770641\n",
      "Processed  75000 pairs in 37.0411379337\n",
      "Processed  80000 pairs in 39.3761820793\n",
      "Finished in 41.3451271057\n"
     ]
    }
   ],
   "source": [
    "# Need to reload new qa_pairs for each model now, as preprocessing varies\n",
    "\n",
    "for model_spec in model_spec_list:\n",
    "    \n",
    "    qa_dir = LIBRARY_PATH+model_spec[\"qa_pair_directory\"]\n",
    "    with open(qa_dir+\"/qa_pairs.txt\", \"r\") as f:\n",
    "        qa_pairs = json.loads(f.read())\n",
    "    \n",
    "    save_model_spec(model_spec)\n",
    "\n",
    "    texts = select_texts(qa_pairs, model_spec)\n",
    "\n",
    "    learn_LDA_model(model_spec, texts, passes = model_spec[\"passes\"], iterations = model_spec[\"iterations\"])\n",
    "\n",
    "    calc_hellinger_sims(model_spec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating and displaying some basic stats about the corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Going to visualize some simple stats about the corpus with standard preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "qa_dir = LIBRARY_PATH+\"saved_models/standard_preproc\"\n",
    "with open(qa_dir+\"/qa_pairs.txt\", \"r\") as f:\n",
    "    qa_pairs = json.loads(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of transcripts 3088\n",
      "Total number of q/a pairs 84806\n",
      "\n",
      "Mean number of q/a pairs in transcript 27.4630829016\n",
      "Median number of q/a pairs in transcript 25.0\n",
      "SD number of q/a pairs in transcript 18.1410866744\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEWCAYAAAB42tAoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nojAzs1JOFGZmVsqJwszMSv0PrSQcCQnJ8zcAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10e8cc8d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total token count 6583595\n",
      "Mean text token length 38.8156203571\n",
      "Median text token length 25.0\n",
      "SD text token length 47.1266417718\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZcAAAEWCAYAAACqitpwAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nA1XSrc1WgmYCAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x13275ed50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_questions = []\n",
    "procd_lengths = []\n",
    "\n",
    "for file_id in qa_pairs:\n",
    "    num_questions.append(len(qa_pairs[file_id]))\n",
    "    for q_num in qa_pairs[file_id]:\n",
    "        procd_lengths.append(len(qa_pairs[file_id][q_num][0]))\n",
    "        procd_lengths.append(len(qa_pairs[file_id][q_num][1]))\n",
    "        \n",
    "print \"Total number of transcripts\", len(qa_pairs.keys())\n",
    "print \"Total number of q/a pairs\", len(procd_lengths) / 2\n",
    "print \n",
    "\n",
    "\n",
    "print \"Mean number of q/a pairs in transcript\", np.mean(num_questions)\n",
    "print \"Median number of q/a pairs in transcript\", np.median(num_questions)\n",
    "print \"SD number of q/a pairs in transcript\", np.std(num_questions)\n",
    "\n",
    "plt.hist(num_questions, bins = 20)\n",
    "# plt.hist(procd_lengths, bins = 20)\n",
    "plt.xlabel(\"Number of q/a pairs in transcript\")\n",
    "plt.ylabel(\"Count of transcripts\")\n",
    "plt.title(\"Histogram of number of q/a pairs in transcript\")\n",
    "plt.show()\n",
    "\n",
    "print 'Total token count', np.sum(procd_lengths)\n",
    "print \"Mean text token length\", np.mean(procd_lengths)\n",
    "print \"Median text token length\", np.median(procd_lengths)\n",
    "print \"SD text token length\", np.std(procd_lengths)\n",
    "\n",
    "plt.hist(procd_lengths, bins = [1,2,4,8,16,32,64,128,256])\n",
    "# plt.hist(procd_lengths, bins = 20)\n",
    "plt.xlabel(\"Number of tokens in processed Q or A text\")\n",
    "plt.ylabel(\"Count of texts\")\n",
    "plt.title(\"Histogram of lengths of tokenized processed Q or A texts\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rawtext_dir = LIBRARY_PATH+\"saved_models/standard_preproc\"\n",
    "with open(LIBRARY_PATH+\"/raw_qa_data.txt\", \"r\") as f:\n",
    "    rawtext_qa = json.loads(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Find qa pairs of median length for examples to include\n",
    "median_length = 25\n",
    "poss_example = []\n",
    "poss_pair = []\n",
    "\n",
    "for file_id in rawtext_qa:\n",
    "    for q_num in rawtext_qa[file_id]:\n",
    "        if len(qa_pairs[file_id][q_num][0]) == 25 and len(qa_pairs[file_id][q_num][1]) == 25:\n",
    "            poss_example.append(rawtext_qa[file_id][q_num])\n",
    "            poss_pair.append((file_id, q_num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Okay. And then I just wanted to verify, it sounded like from SCANA that one factor that drove their decision was the decision of Santee Cooper to not go forward. I just want to verify that your partners are pretty much, they're all together in terms of where you're at on the decision-making process there.\n",
      "Yeah, we work very hard, Georgia Power works very hard as a co-owner. We've had a relationship with these folks for decades and we have a terrific relationship, among and between Oglethorpe and Miag and Dalton, and we work very hard to stay together on these issues and I feel confident we will.\n",
      "\n",
      "[u'okay', u'want', u'verifi', u'sound', u'like', u'scana', u'one', u'factor', u'drove', u'decis', u'decis', u'sante', u'cooper', u'go', u'forward', u'want', u'verifi', u'partner', u'pretti', u'much', u'togeth', u'term', u'decis', u'make', u'process']\n",
      "[u'yeah', u'work', u'hard', u'georgia', u'power', u'work', u'hard', u'co', u'owner', u'relationship', u'folk', u'decad', u'terrif', u'relationship', u'among', u'oglethorp', u'miag', u'dalton', u'work', u'hard', u'stay', u'togeth', u'issu', u'feel', u'confid']\n",
      "\n",
      "--------------------------------------------------\n",
      "Okay. And then I guess finally, when you look out into January, is there any either with your individual customers or small business customer, do you think the  as best as you can tell, do you think the cliff, has it created any change in behavior to date? Do you think it will or it's pretty much a non-event for you?\n",
      "Well, I think  again, we're a little jaded here because our numbers  particularly our frequencies and are comps have been pretty darn good. I think we like everybody have a little of cautious optimism that they're going to do at least a compromise and  or they better. So we're not really focusing a lot on it right now.\n",
      "\n",
      "[u'okay', u'guess', u'final', u'look', u'januari', u'either', u'individu', u'custom', u'small', u'busi', u'custom', u'think', u'best', u'tell', u'think', u'cliff', u'creat', u'chang', u'behavior', u'date', u'think', u'pretti', u'much', u'non', u'event']\n",
      "[u'well', u'think', u'littl', u'jade', u'number', u'particularli', u'frequenc', u'comp', u'pretti', u'darn', u'good', u'think', u'like', u'everybodi', u'littl', u'cautiou', u'optim', u'go', u'least', u'compromis', u'better', u'realli', u'focus', u'lot', u'right']\n",
      "\n",
      "--------------------------------------------------\n",
      "Because you'd be predicting the export market, I understand that. If I could jump to my follow-up question, in terms of the personal injury rates, obviously, it crept up a little bit and there is a negative comparison in 4Q that you mentioned. When is the next actuarial study on the personal injury rate?\n",
      "We do those quarterly. So each quarter, we evaluate those personal injuries, and as Mark said, when we look at the creep of the injury rate going up slightly, but as Mark mentioned in his comments, the severity has not crept up. The serious injuries have not changed, so that gives us comfort about our accruals.\n",
      "\n",
      "[u'predict', u'export', u'market', u'understand', u'jump', u'follow', u'question', u'term', u'person', u'injuri', u'rate', u'obvious', u'crept', u'littl', u'bit', u'neg', u'comparison', u'4q', u'mention', u'next', u'actuari', u'studi', u'person', u'injuri', u'rate']\n",
      "[u'quarterli', u'quarter', u'evalu', u'person', u'injuri', u'mark', u'said', u'look', u'creep', u'injuri', u'rate', u'go', u'slightli', u'mark', u'mention', u'comment', u'sever', u'crept', u'seriou', u'injuri', u'chang', u'give', u'us', u'comfort', u'accrual']\n",
      "\n",
      "--------------------------------------------------\n",
      "So  appreciate that. I just had a follow-up on the same line of thinking. It also seems that the asset productivity is important to you guys and it does seem even though there's margin pressure that the outflow of money into assets doesn't have to be huge and so we could get some continued increase in ROIC, do you agree with that as well?\n",
      "I do. I do. I think if you look at what we're trying to do here is as we gain dispensing share, that dispensing share we can essentially leverage the fixed asset infrastructure of our business both at the Retail segment as well as in the PBM space. And that really allows us to accelerate our returns profile.\n",
      "\n",
      "[u'appreci', u'follow', u'line', u'think', u'also', u'seem', u'asset', u'product', u'import', u'guy', u'seem', u'even', u'though', u'margin', u'pressur', u'outflow', u'money', u'asset', u'huge', u'get', u'continu', u'increas', u'roic', u'agre', u'well']\n",
      "[u'think', u'look', u'tri', u'gain', u'dispens', u'share', u'dispens', u'share', u'essenti', u'leverag', u'fix', u'asset', u'infrastructur', u'busi', u'retail', u'segment', u'well', u'pbm', u'space', u'realli', u'allow', u'us', u'acceler', u'return', u'profil']\n",
      "\n",
      "--------------------------------------------------\n",
      "That's helpful, and maybe one other, if I could. Just on CapEx, I know there was a timing delta here between Q3 and Q4, but I just wanted to step back. If you think about your CapEx plans ex-LinkedIn as you came into the year and how you think you'll end up, are you going to be about on plan, or do you think you'll be above or below? Thanks.\n",
      "Thanks. In general, for the full fiscal year, we'll be right at or a little below where I thought we would have been, and so that's why the full-year perspective that growth will slow is still on track. And for simplicity, I generally would think about all the delta from Q3. I would encourage you just to move it into Q4 as you think about what to expect.\n",
      "\n",
      "[u'help', u'mayb', u'one', u'capex', u'know', u'time', u'delta', u'q3', u'q4', u'want', u'step', u'back', u'think', u'capex', u'plan', u'ex', u'linkedin', u'came', u'year', u'think', u'end', u'go', u'plan', u'think', u'thank']\n",
      "[u'thank', u'gener', u'full', u'fiscal', u'year', u'right', u'littl', u'thought', u'full', u'year', u'perspect', u'growth', u'slow', u'still', u'track', u'simplic', u'gener', u'think', u'delta', u'q3', u'encourag', u'move', u'q4', u'think', u'expect']\n",
      "\n",
      "--------------------------------------------------\n",
      "Quick question on the long-term debt. You guys reduced it about $85 billion last year. It has certainly been helpful to the margin. With OLA or anything else like that, do you see that slowing this year? What's your outlook on long-term debt?\n",
      "Yes, we'll give a little bit more perspective on that when we do the fixed income call next week. But I think you can already see some slowdown. I believe end-of-period long-term debt only came down about $5 billion or so quarter on quarter.\n",
      "\n",
      "[u'quick', u'question', u'long', u'term', u'debt', u'guy', u'reduc', u'NUM', u'billion', u'last', u'year', u'certainli', u'help', u'margin', u'ola', u'anyth', u'els', u'like', u'see', u'slow', u'year', u'outlook', u'long', u'term', u'debt']\n",
      "[u'ye', u'give', u'littl', u'bit', u'perspect', u'fix', u'incom', u'call', u'next', u'week', u'think', u'alreadi', u'see', u'slowdown', u'believ', u'end', u'period', u'long', u'term', u'debt', u'came', u'NUM', u'billion', u'quarter', u'quarter']\n",
      "\n",
      "--------------------------------------------------\n",
      "I understand. Yes, it's on sales and then obviously net, there's been a negative basically from Libya but all the other movements. From here forward, are we looking again back to the 5% to 8% if we ask you again in a year's time, are we going to be in the 5% to 8% volume growth range that you've talked about in the past?\n",
      "At least that, because I think the domestic businesses are going to surprise, but I could be wrong. But I think the 3,000 to 4,000 a month for the domestic business is pretty solid for a while, and maybe we'll do a little better, but I think that's a good risked number for us.\n",
      "\n",
      "[u'understand', u'ye', u'sale', u'obvious', u'net', u'neg', u'basic', u'libya', u'movement', u'forward', u'look', u'back', u'NUM', u'NUM', u'ask', u'year', u'time', u'go', u'NUM', u'NUM', u'volum', u'growth', u'rang', u'talk', u'past']\n",
      "[u'least', u'think', u'domest', u'busi', u'go', u'surpris', u'wrong', u'think', u'NUM', u'NUM', u'NUM', u'NUM', u'month', u'domest', u'busi', u'pretti', u'solid', u'mayb', u'littl', u'better', u'think', u'good', u'risk', u'number', u'us']\n",
      "\n",
      "--------------------------------------------------\n",
      "Thanks. Good afternoon. I guess the inverse of Peter's question, as employees start to come on line and get trained and then they become active, at what point in that kind of life of the employee do you start to see the comp per employee increase?\n",
      "I'm not quite sure we understand your question, Ed. In terms of the way the contract employees are paid, there are  it's a four-year step process, where they start at 80% and then reach 100% of the contract rate. Once they've been here four years, they're paid at 100% of their rate.\n",
      "\n",
      "[u'thank', u'good', u'afternoon', u'guess', u'invers', u'peter', u'question', u'employe', u'start', u'come', u'line', u'get', u'train', u'becom', u'activ', u'point', u'kind', u'life', u'employe', u'start', u'see', u'comp', u'per', u'employe', u'increas']\n",
      "[u'quit', u'sure', u'understand', u'question', u'ed', u'term', u'way', u'contract', u'employe', u'paid', u'four', u'year', u'step', u'process', u'start', u'NUM', u'reach', u'NUM', u'contract', u'rate', u'four', u'year', u'paid', u'NUM', u'rate']\n",
      "\n",
      "--------------------------------------------------\n",
      "So I guess that was the thrust of my question that it seems in 2017, you obviously you'll be moving away from the target, and then it only comes down a little bit by 2021. So, how should we think about the 34% is  within  do you consider that to be in the target range or is it more sort of backend of the decade that you can  you get further back down towards it?\n",
      "Well, as Lynn said, our target is in the low-30%s, and we're a bit above that as we work through this transition of our portfolio. But we'll be looking to move the HoldCo debt into our target range. And we're making progress to our five-year plan. And we'll continue to strive to get it to that point.\n",
      "\n",
      "[u'guess', u'thrust', u'question', u'seem', u'NUM', u'obvious', u'move', u'away', u'target', u'come', u'littl', u'bit', u'NUM', u'think', u'NUM', u'within', u'consid', u'target', u'rang', u'sort', u'backend', u'decad', u'get', u'back', u'toward']\n",
      "[u'well', u'lynn', u'said', u'target', u'low', u'NUM', u'bit', u'work', u'transit', u'portfolio', u'look', u'move', u'holdco', u'debt', u'target', u'rang', u'make', u'progress', u'five', u'year', u'plan', u'continu', u'strive', u'get', u'point']\n",
      "\n",
      "--------------------------------------------------\n",
      "Thanks a lot. Good morning. Just a couple follow-up questions here. You spoke in your prepared remarks about FEP and the renewal of the contract that you cycled in September. Any residual impact going forward on the PBM gross margin associated with the FEP deal?\n",
      "One thing you should be aware of, that we have spoken about in the past, is that the renewal of FEP 2012 and beyond, like the other contracts with federal government employees and retirees, are being restructured to be essentially a cost-plus or a pass-through type of arrangement, so there will be some margin compression associated with that.\n",
      "\n",
      "[u'thank', u'lot', u'good', u'morn', u'coupl', u'follow', u'question', u'spoke', u'prepar', u'remark', u'fep', u'renew', u'contract', u'cycl', u'septemb', u'residu', u'impact', u'go', u'forward', u'pbm', u'gross', u'margin', u'associ', u'fep', u'deal']\n",
      "[u'one', u'thing', u'awar', u'spoken', u'past', u'renew', u'fep', u'NUM', u'beyond', u'like', u'contract', u'feder', u'govern', u'employe', u'retire', u'restructur', u'essenti', u'cost', u'plu', u'pass', u'type', u'arrang', u'margin', u'compress', u'associ']\n",
      "\n",
      "--------------------------------------------------\n",
      "Now that's relative to 2011 I'm asking, not 2012, because you've provided the pro forma numbers in the 8-K that you disclosed a couple of weeks ago and that showed $0.50 accretion in 2011 on the pro forma. So I was asking for the comparison 2011 to 2013.\n",
      "We're just looking here. Yeah. Yeah, George, I think we're going to have to get back to you on that. I have not gone back into these pro formas. I haven't focused on 2011 really much since last year. But we can go back and take a look and get an answer for you.\n",
      "\n",
      "[u'rel', u'NUM', u'ask', u'NUM', u'provid', u'pro', u'forma', u'number', u'NUM', u'k', u'disclos', u'coupl', u'week', u'ago', u'show', u'NUM', u'NUM', u'accret', u'NUM', u'pro', u'forma', u'ask', u'comparison', u'NUM', u'NUM']\n",
      "[u'look', u'yeah', u'yeah', u'georg', u'think', u'go', u'get', u'back', u'gone', u'back', u'pro', u'forma', u'focus', u'NUM', u'realli', u'much', u'sinc', u'last', u'year', u'go', u'back', u'take', u'look', u'get', u'answer']\n",
      "\n",
      "--------------------------------------------------\n",
      "So the follow up to that is, in theory, if this were included in a submission, you have a derisked balance sheet from a TDR perspective as these are sold, but not just that, the cushion for your PP&R should also improve under stress because of the administrative costs that go away? Is that the right take away to assume if it was in the submission?\n",
      "That's right. The cost to carry these are punitive in all of our  whether it be your base or your two adverse runs. So being able to strip that cost out and have the assets, the proceeds reinvested in assets that don't attract as much capital and generate more PP&R is what we tried to do and we think we accomplished that.\n",
      "\n",
      "[u'follow', u'theori', u'includ', u'submiss', u'derisk', u'balanc', u'sheet', u'tdr', u'perspect', u'sold', u'cushion', u'pp', u'r', u'also', u'improv', u'stress', u'administr', u'cost', u'go', u'away', u'right', u'take', u'away', u'assum', u'submiss']\n",
      "[u'right', u'cost', u'carri', u'punit', u'whether', u'base', u'two', u'advers', u'run', u'abl', u'strip', u'cost', u'asset', u'proce', u'reinvest', u'asset', u'attract', u'much', u'capit', u'gener', u'pp', u'r', u'tri', u'think', u'accomplish']\n",
      "\n",
      "--------------------------------------------------\n",
      "Good morning. A couple of questions. Just following on that last question, lower grade moly at Bagdad and Sierrita in 2013, does that continue like for three or four years or what sort of time horizon should we think of that, because obviously that will affect the cost there.\n",
      "It's down for a couple of years, I think at Sierrita and then it picks back up again in, I believe in 2014 Red? Yeah, 2014. 2014 we see a pick-up again. So it's just the sequencing of the mines in those two places. Bagdad's a little more stable on their throughput where we see more variability at Sierrita.\n",
      "\n",
      "[u'good', u'morn', u'coupl', u'question', u'follow', u'last', u'question', u'lower', u'grade', u'moli', u'bagdad', u'sierrita', u'NUM', u'continu', u'like', u'three', u'four', u'year', u'sort', u'time', u'horizon', u'think', u'obvious', u'affect', u'cost']\n",
      "[u'coupl', u'year', u'think', u'sierrita', u'pick', u'back', u'believ', u'NUM', u'red', u'yeah', u'NUM', u'NUM', u'see', u'pick', u'sequenc', u'mine', u'two', u'place', u'bagdad', u'littl', u'stabl', u'throughput', u'see', u'variabl', u'sierrita']\n",
      "\n",
      "--------------------------------------------------\n",
      "Hi. Thanks. Just a couple. So, Google introduced a fourth link to mobile search results in the third quarter and they also made some tweaks to the algo for organic. Can you talk about any kind of impact you might have seen on the business as a result of that? And then I have a follow-up.\n",
      "With respect to the organic, again, I think you can see in our results that we've had a good quarter and so I think it's safe to assume from that that whatever changes they made in organic have not had a substantial effect on the momentum for our growth. I'm sorry but I didn't catch the first one. The fourth paid link.\n",
      "\n",
      "[u'hi', u'thank', u'coupl', u'googl', u'introduc', u'fourth', u'link', u'mobil', u'search', u'result', u'third', u'quarter', u'also', u'made', u'tweak', u'algo', u'organ', u'talk', u'kind', u'impact', u'might', u'seen', u'busi', u'result', u'follow']\n",
      "[u'respect', u'organ', u'think', u'see', u'result', u'good', u'quarter', u'think', u'safe', u'assum', u'whatev', u'chang', u'made', u'organ', u'substanti', u'effect', u'momentum', u'growth', u'sorri', u'catch', u'first', u'one', u'fourth', u'paid', u'link']\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-e05a6e20c233>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0;34m\"-\"\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mfile_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mposs_pair\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mq_num\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mposs_pair\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0mrawtext_qa\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfile_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mq_num\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "for p in range(20):\n",
    "    print \"-\"*50\n",
    "    file_id = poss_pair[p][0]\n",
    "    q_num = poss_pair[p][1]\n",
    "    print rawtext_qa[file_id][q_num][0]\n",
    "    print rawtext_qa[file_id][q_num][1]\n",
    "    print\n",
    "    print qa_pairs[file_id][q_num][0]\n",
    "    print qa_pairs[file_id][q_num][1]\n",
    "    print\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [py27]",
   "language": "python",
   "name": "Python [py27]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
